\chapter{Combined ABCD Rules and Dermoscopic Structures using Bayesian Network}

\section{Introduction}
This chapter is about automating ABCD rules using statistical models and preparing the data for processing with support vector machines (SVM). This section includes comparisons and small contributions to knowledge.

\section{Model}
The proposed CAD framework described in Figure \ref{model} automates the ABCD rules using statistical algorithms to extract features ($f$) from asymmetry, border, colour, and dermoscopic structures. Each feature has an associated SVM model trained using these extracted features. Next, Bayesian fusion, a probabilistic approach, combines multiple independent classifiers to diagnose melanoma. One benefit of Bayesian fusion is its higher accuracy in classifying skin lesions as compared to a standalone classifier \cite{Takruri2017}.  Javier LÃ³pez-Labraca, et al describe a similar method using dermoscopic structures, and colour \cite{Lopez-Labraca2018}. Other benefits are estimating the relevance of individual classifiers and classifying them with incomplete data, making it an interpretable and robust method. In addition, some feature extraction techniques generate graphics that might be suitable as an explanation for the diagnosis. Finally, the PH$^2$ dataset validates the rules, and once combined into a diagnosis, more extensive datasets, including ISIC 2019, can measure its accuracy.

\begin{figure}
\begin{tikzpicture}[]

	%Image Acqusition
	\node (inp) [img] at (0, 3) {\includegraphics[scale=0.12]{lesion.png}};
	
	%Pre-processing
	\node (aug) [box, minimum height=1cm, node distance=3.6cm, right of=inp] {Augmentation};
	\node (seg) [box, minimum height=1cm, node distance=3.6cm, right of=aug] {Segmentation};
	
\node[draw=white] at ($(aug.north west)+(1.3,0.5)$) {\textbf{Pre-processing}};

\draw[thick, dotted] ($(aug.north west)+(-0.3,0.3)$) rectangle ($(seg.south east)+(0.3, -0.3)$);		

    %Feature extraction
    \node (asy) [box, right of=seg] at (0.0, 0.4) {Asymmetry};
    \node (bor) [box, right of=seg] at (0.0, -0.8) {Border};
    \node (col) [box, right of=seg] at (0.0, -2.0) {Colour};
    
    \node (asy2) [box, minimum width=1cm, right of=asy] {$f_a$};
	\node (bor2) [box, minimum width=1cm, right of=bor] {$f_b$};
    \node (col2) [box, minimum width=1cm, right of=col] {$f_c$};

		\node[draw=white] at ($(asy.north west)+(1.9,0.5)$) {\textbf{Feature Extraction}};    
    
    \draw[thick, dotted] ($(asy.north west)+(-0.3,0.3)$) rectangle ($(col2.south east)+(0.3, -0.3)$);
    
    %Classification
    \node (asy3) [box, right of=asy2] {SVM$_a$};
	\node (bor3) [box, right of=bor2] {SVM$_b$};
    \node (col3) [box, right of=col2] {SVM$_c$};

	\node[draw=white] at ($(asy3.north west)+(1.3,0.5)$) {\textbf{Classification}};    
    
    \node (fus) [box, minimum height=3cm, minimum width=1.7cm, text width=2cm] at (10.56, -0.8) {Bayesian \\ Fusion};
    
    \draw[thick, dotted] ($(asy3.north west)+(-0.3,0.3)$) rectangle ($(fus.south east)+(0.3, -0.3)$);
      
    \node (out) [box, right of=fus, node distance=2.7cm, minimum height=1.9cm, minimum width=1.9cm, text width=2cm] {Benign or \\ Malignant};
    
	\draw[->]
			(aug) edge (seg)
			(asy) edge (asy2)
			(bor) edge (bor2)  
			(col) edge (col2)  
			(asy2) edge (asy3)
			(bor2) edge (bor3)  
			(col2) edge (col3)  
			  
;
	\draw[->] (bor3)
	-|	($(fus.west)+(-0.5, 0)$)
 	|- (fus)
;

	\draw[-] (asy3)
	-|	($(bor3.east)+(0.5, 0)$)
;

	\draw[-] (col3)
	-| ($(fus.west)+(-0.5, 0)$)
;

 	\draw[->] (inp) edge (aug)
 			(asy2) edge (asy3)
			(bor2) edge (bor3)  
			(col2) edge (col3)  
 			(fus) edge (out)
 				(seg) -| ($(seg.east)+(0.7, 0)$)
 					  |- ($(seg.east)+(0, -1.2)$)
 					  -| ($(asy.west)+(-0.8, 0)$)
 					  |- (asy)
;

 	\draw[->] ($(asy.west)+(-0.8, 0)$) 
 		  |- (bor)
;

	\draw[->] ($(asy.west)+(-0.8, -1.2)$) 
 		  |- (col)
; 
    
\end{tikzpicture}
\caption{Proposed CAD framework describing the segmentation, feature extraction  and classification process.} \label{model}
\end{figure}

ABCD rules describe the classification process for each rule and demonstrate the process behind reaching diagnoses. The objective is to visualise important features that GPs might need to support their diagnostic procedure. Hopefully, this will instantiate trust when automating skin lesion identification within clinical environments. Another advantage would be the automatic labelling of skin lesions, making it easier for dermatologists to identify later.

The CAD framework in figure \ref{model} describes a model of pre-processing, feature extraction, and classification stages. After segmentation, statistical algorithms extract features ($f$), representing a different rule. Next, SVM models individually process the extracted features and combine them into a final result between benign and malignant using bayesian fusion.

