@article{patil2021,
   abstract = {Skin disease is found in different sorts, for example, basal, squamous cell carcinoma and melanoma among which melanoma is one that is very difficult to predict. Finding melanoma at an early stage is crucial. Melanomas come in many forms and may display none of the typical warning signs. Early detection can vastly increase chances for the cure. Computer vision can assume significant part in Medical Image Diagnosis and it has been demonstrated by numerous existing frameworks. Here, we represent computer aided strategy for identification of type of melanoma utilizing the transfer learning techniques. The proposed model utilized pre-trained and transfer learning model to image net. The proposed model successfully classified three melanoma types, namely, Nodular melanoma, Lentigo maligna melanoma and Superficial spreading melanoma. Additionally, exact identification of irregular borders from melanoma skin lesions is clinically significant. A main challenge is deciding the specific lesion border. For resolving the issue, we have executed another technique to identify the border of an affected or cancerous area. A dataset consists of 2475 dermoscopic images to train and test algorithms. Performance of a proposed system gave very good results as far as sensitivity, accuracy, specificity, recall, fscore, and precision. At last, we have compared performance of different transfer learning techniques.},
   author = {Rashmi Patil and Sreepathi Bellary},
   doi = {10.18280/ria.350203},
   issn = {19585748},
   issue = {2},
   journal = {Revue d'Intelligence Artificielle},
   title = {Transfer learning based system for melanoma type detection},
   volume = {35},
   year = {2021},
}
@article{yu2017,
   abstract = {Automated melanoma recognition in dermoscopy images is a very challenging task due to the low contrast of skin lesions, the huge intraclass variation of melanomas, the high degree of visual similarity between melanoma and non-melanoma lesions, and the existence of many artifacts in the image. In order to meet these challenges, we propose a novel method for melanoma recognition by leveraging very deep convolutional neural networks (CNNs). Compared with existing methods employing either low-level hand-crafted features or CNNs with shallower architectures, our substantially deeper networks (more than 50 layers) can acquire richer and more discriminative features for more accurate recognition. To take full advantage of very deep networks, we propose a set of schemes to ensure effective training and learning under limited training data. First, we apply the residual learning to cope with the degradation and overfitting problems when a network goes deeper. This technique can ensure that our networks benefit from the performance gains achieved by increasing network depth. Then, we construct a fully convolutional residual network (FCRN) for accurate skin lesion segmentation, and further enhance its capability by incorporating a multi-scale contextual information integration scheme. Finally, we seamlessly integrate the proposed FCRN (for segmentation) and other very deep residual networks (for classification) to form a two-stage framework. This framework enables the classification network to extract more representative and specific features based on segmented results instead of the whole dermoscopy images, further alleviating the insufficiency of training data. The proposed framework is extensively evaluated on ISBI 2016 Skin Lesion Analysis Towards Melanoma Detection Challenge dataset. Experimental results demonstrate the significant performance gains of the proposed framework, ranking the first in classification and the second in segmentation among 25 teams and 28 teams, respectively. This study corroborates that very deep CNNs with effective training mechanisms can be employed to solve complicated medical image analysis tasks, even with limited training data.},
   author = {Lequan Yu and Hao Chen and Qi Dou and Jing Qin and Pheng Ann Heng},
   doi = {10.1109/TMI.2016.2642839},
   issn = {1558254X},
   issue = {4},
   journal = {IEEE Transactions on Medical Imaging},
   title = {Automated Melanoma Recognition in Dermoscopy Images via Very Deep Residual Networks},
   volume = {36},
   year = {2017},
}
@article{albani2020,
   abstract = {Melanoma is the skin cancer caused by the ultraviolet radiation from the Sun and has only 15-20% of survival rate. Late diagnosis of melanoma leads to the severe malignancy of disease, and metastasis expands to the other body organs i.e. liver, lungs and brain. The dermatologists analyze the pigmented lesions over the skin to discriminate melanoma from other skin diseases. However, the imprecise analysis results in the form of a series of biopsies and it complicates the treatment. Meanwhile, the process of melanoma detection can be expedited through computer vision methods by analyzing the dermoscopic images automatically. However, the visual similarity between the normal and infected skin regions, and arti-facts like gel bubbles, hair and clinical marks indicate low accuracy rates for these approaches. To overcome these challenges, in this article, a melanoma detection and segmentation approach is presented that brings significant improvement in terms of accuracy against state-of-the-art approaches. As a first step, the artifacts like hairs, gel bubbles, and clinical marks are removed from the dermoscopic images by applying the morphological operations, and image regions are sharpen. Afterwards, for infected region detection, we used YOLOv4 object detector by tuning it for melanoma detection to discriminate the highly correlated infected and non-infected regions. Once the bounding boxes against the melanoma regions are obtained, the infected melanoma regions are extracted by applying the active contour segmentation approach. For performance evaluation, the proposed approach is evaluated on ISIC2018 and ISIC2016 datasets and results are compared against state-of-the-art melanoma detection, and segmentation techniques. Our proposed approach achieves average dice score as 1 and Jaccard coefficient as 0.989. The segmentation result validates the practical bearing of our method in development of clinical decision support system for melanoma diagnosis in contrast to state-of-the-art methods. The YOLOv4 detector is capable to detect multiple skin diseases of same patient and multiple diseases of various patients.},
   author = {Saleh Albahli and Nudrat Nida and Aun Irtaza and Muhammad Haroon Yousaf and Muhammad Tariq Mahmood},
   doi = {10.1109/ACCESS.2020.3035345},
   issn = {21693536},
   journal = {IEEE Access},
   title = {Melanoma Lesion Detection and Segmentation Using YOLOv4-DarkNet and Active Contour},
   volume = {8},
   year = {2020},
}
@article{xu2022,
   abstract = {As an extension of Dempster-Shafer (D-S) theory, the evidential reasoning (ER) rule can be used as a combination strategy in ensemble learning to deeply mine classifier information through decision-making reasoning. The weight of evidence is an important parameter in the ER rule, which has a significant effect on the result of ensemble learning. However, current research results on the weight of evidence are not ideal, leveraging expert knowledge to assign weights leads to the excessive subjectivity, and using sample statistical methods to assign weights relies too heavily on the samples, so the determined weights sometimes differ greatly from the actual importance of the attributes. Therefore, to solve the problem of excessive subjectivity and objectivity of the weights of evidence, and further improve the accuracy of ensemble learning based on the ER rule, we propose a novel combination weighting method to determine the weight of evidence. The combined weights are calculated by leveraging our proposed method to combine subjective and objective weights of evidence. The regularization of these weights is studied. Then, the evidential reasoning rule is used to integrate different classifiers. Five case studies of image classification datasets have been conducted to demonstrate the effectiveness of the combination weighting method.},
   author = {Cong Xu and Yun Yi Zhang and Wei Zhang and Hong Quan Zu and Yi Zhe Zhang and Wei He},
   doi = {10.1155/2022/1156748},
   issn = {16875273},
   journal = {Computational Intelligence and Neuroscience},
   title = {An Ensemble Learning Method Based on an Evidential Reasoning Rule considering Combination Weighting},
   volume = {2022},
   year = {2022},
}
@inproceedings{rafferty2022,
   abstract = {Explainable Artificial Intelligence (XAI) is the field of AI dedicated to promoting trust in machine learning models by helping us to understand how they make their decisions. For example, image explanations show us which pixels or segments were deemed most important by a model for a particular classification decision. This research focuses on image explanations generated by LIME, RISE and SHAP for a model which classifies breast mammograms as either benign or malignant. We assess these XAI techniques based on (1) the extent to which they agree with each other, as decided by One-Way ANOVA, Kendall’s Tau and RBO statistical tests, and (2) their agreement with the diagnostically important areas as identified by a radiologist on a small subset of mammograms. The main contribution of this research is the discovery that the 3 techniques consistently disagree both with each other and with the medical truth. We argue that using these off-shelf techniques in a medical context is not a feasible approach, and discuss possible causes of this problem, as well as some potential solutions.},
   author = {Amy Rafferty and Rudolf Nenutil and Ajitha Rajan},
   doi = {10.1007/978-3-031-17976-1_10},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Explainable Artificial Intelligence for Breast Tumour Classification: Helpful or Harmful},
   volume = {13611 LNCS},
   year = {2022},
}
@inproceedings{duell2021,
   abstract = {eXplainable Artificial Intelligence (XAI) aims to provide intelligible explanations to users. XAI algorithms such as SHAP, LIME and Scoped Rules compute feature importance for machine learning predictions. Although XAI has attracted much research attention, applying XAI techniques in healthcare to inform clinical decision making is challenging. In this paper, we provide a comparison of explanations given by XAI methods as a tertiary extension in analysing complex Electronic Health Records (EHRs). With a large-scale EHR dataset, we compare features of EHRs in terms of their prediction importance estimated by XAI models. Our experimental results show that the studied XAI methods circumstantially generate different top features; their aberrations in shared feature importance merit further exploration from domain-experts to evaluate human trust towards XAI.},
   author = {Jamie Duell and Xiuyi Fan and Bruce Burnett and Gert Aarts and Shang Ming Zhou},
   doi = {10.1109/BHI50953.2021.9508618},
   journal = {BHI 2021 - 2021 IEEE EMBS International Conference on Biomedical and Health Informatics, Proceedings},
   title = {A comparison of explanations given by explainable artificial intelligence methods on analysing electronic health records},
   year = {2021},
}
@article{rizvi2022,
   abstract = {Minorities, particularly non-White minorities, often encounter implicit biases from healthcare professionals that may impact their standard of care and quality of life. The study of dermatology has long been based on Whites, unintentionally affecting the treatment of non-White patients. Melanoma, although mostly curable, can become fatal in those presenting with advanced stages at diagnosis. Despite being rare in racial minorities, melanoma is associated with a worse prognosis among them compared to White populations. In light of this, the objective of this study was to determine the role of education in preventing biases and improving the diagnosis and treatment of melanoma in minority groups to improve patient outcomes. This study was designed as a scoping review to gather evidence on the impact of implicit bias and lack of education on the treatment of melanoma in people of color. Following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we searched for peer-reviewed studies involving melanoma, education, and treatment bias in people of color on the databases PubMed, Medline EBSCO, CINAHL, and Cochrane. The data were extracted pertaining to the following main aspects: (1) risk factors, (2) surveys of current knowledge, and 3) educational interventions. This scoping review identified socioeconomic factors, bias, and lack of education in minority populations as causes of increased mortality rates in melanoma. Moreover, because preventative dermatology is largely based on White skin types, incorporating darker skin tones into education will help dispel implicit bias. Additionally, there is evidence to indicate that current patient knowledge and understanding of skin cancer is inaccurate among many and can be significantly improved through educational interventions, such as brochures and videos. Further educational interventions may be beneficial to increase understanding of melanoma in populations of color to address health disparities in dermatological care.},
   author = {Zehra Rizvi and Viktor Kunder and Hanna Stewart and Paola Torres and Sana Moon and Nimisha Lingappa and Mallory Kazaleh and Varshini Mallireddigari and Julian Perez and Nigel John and Anika Sedani and Robin J Jacobs},
   doi = {10.7759/cureus.31669},
   journal = {Cureus},
   title = {The Bias of Physicians and Lack of Education in Patients of Color With Melanoma as Causes of Increased Mortality: A Scoping Review},
   year = {2022},
}
@article{wachter2017,
   author = {Sandra Wachter and Brent Mittelstadt and Luciano Floridi},
   doi = {10.1126/scirobotics.aan6080},
   issn = {24709476},
   issue = {6},
   journal = {Science Robotics},
   title = {Transparent, explainable, and accountable AI for robotics},
   volume = {2},
   year = {2017},
}
@article{ploug2021,
   abstract = {Background: Certain types of artificial intelligence (AI), that is, deep learning models, can outperform health care professionals in particular domains. Such models hold considerable promise for improved diagnostics, treatment, and prevention, as well as more cost-efficient health care. They are, however, opaque in the sense that their exact reasoning cannot be fully explicated. Different stakeholders have emphasized the importance of the transparency/explainability of AI decision making. Transparency/explainability may come at the cost of performance. There is need for a public policy regulating the use of AI in health care that balances the societal interests in high performance as well as in transparency/explainability. A public policy should consider the wider public's interests in such features of AI. Objective: This study elicited the public's preferences for the performance and explainability of AI decision making in health care and determined whether these preferences depend on respondent characteristics, including trust in health and technology and fears and hopes regarding AI. Methods: We conducted a choice-based conjoint survey of public preferences for attributes of AI decision making in health care in a representative sample of the adult Danish population. Initial focus group interviews yielded 6 attributes playing a role in the respondents' views on the use of AI decision support in health care: (1) type of AI decision, (2) level of explanation, (3) performance/accuracy, (4) responsibility for the final decision, (5) possibility of discrimination, and (6) severity of the disease to which the AI is applied. In total, 100 unique choice sets were developed using fractional factorial design. In a 12-task survey, respondents were asked about their preference for AI system use in hospitals in relation to 3 different scenarios. Results: Of the 1678 potential respondents, 1027 (61.2%) participated. The respondents consider the physician having the final responsibility for treatment decisions the most important attribute, with 46.8% of the total weight of attributes, followed by explainability of the decision (27.3%) and whether the system has been tested for discrimination (14.8%). Other factors, such as gender, age, level of education, whether respondents live rurally or in towns, respondents' trust in health and technology, and respondents' fears and hopes regarding AI, do not play a significant role in the majority of cases. Conclusions: The 3 factors that are most important to the public are, in descending order of importance, (1) that physicians are ultimately responsible for diagnostics and treatment planning, (2) that the AI decision support is explainable, and (3) that the AI system has been tested for discrimination. Public policy on AI system use in health care should give priority to such AI system use and ensure that patients are provided with information.},
   author = {Thomas Ploug and Anna Sundby and Thomas B. Moeslund and Søren Holm},
   doi = {10.2196/26611},
   issn = {14388871},
   issue = {12},
   journal = {Journal of Medical Internet Research},
   title = {Population Preferences for Performance and Explainability of Artificial Intelligence in Health Care: Choice-Based Conjoint Survey},
   volume = {23},
   year = {2021},
}
@misc{Dennehy2023,
   author = {Denis Dennehy and Anastasia Griva and Nancy Pouloudi and Yogesh K. Dwivedi and Matti Mäntymäki and Ilias O. Pappas},
   doi = {10.1007/s10796-022-10365-3},
   issn = {15729419},
   issue = {1},
   journal = {Information Systems Frontiers},
   title = {Artificial Intelligence (AI) and Information Systems: Perspectives to Responsible AI},
   volume = {25},
   year = {2023},
}
@article{hemphill2023,
   abstract = {Aim To synthesise research on the view of the public and patients of the use of artificial intelligence (AI) in radiology investigations.
Methods A literature review of narrative synthesis of qualitative and quantitative studies that reported views of the public and patients toward the use of AI in radiology.
Results Only seven studies related to patient and public views were retrieved, suggesting that this is an underexplored area of research. Two broad themes, of confidence in the capabilities of AI, and the accountability and transparency of AI, were identified.
Conclusions Both optimism and concerns were expressed by participants. Transparency in the implementation of AI, scientific validation, clear regulation and accountability were expected. Combined human and AI interpretation of imaging was strongly favoured over AI acting autonomously. The review highlights the limited engagement of the public in the adoption of AI in a radiology setting. Successful implementation of AI in this field will require demonstrating not only adequate accuracy of the technology, but also its acceptance by patients.},
   author = {Scott Hemphill and Katherine Jackson and Stephen Bradley and Bobby Bhartia},
   doi = {10.7861/fhj.2022-0097},
   issn = {2514-6645},
   issue = {1},
   journal = {Future Healthcare Journal},
   title = {The implementation of artificial intelligence in radiology: a narrative review of patient perspectives},
   volume = {10},
   year = {2023},
}
@article{amann2020,
   abstract = {Background: Explainability is one of the most heavily debated topics when it comes to the application of artificial intelligence (AI) in healthcare. Even though AI-driven systems have been shown to outperform humans in certain analytical tasks, the lack of explainability continues to spark criticism. Yet, explainability is not a purely technological issue, instead it invokes a host of medical, legal, ethical, and societal questions that require thorough exploration. This paper provides a comprehensive assessment of the role of explainability in medical AI and makes an ethical evaluation of what explainability means for the adoption of AI-driven tools into clinical practice. Methods: Taking AI-based clinical decision support systems as a case in point, we adopted a multidisciplinary approach to analyze the relevance of explainability for medical AI from the technological, legal, medical, and patient perspectives. Drawing on the findings of this conceptual analysis, we then conducted an ethical assessment using the “Principles of Biomedical Ethics” by Beauchamp and Childress (autonomy, beneficence, nonmaleficence, and justice) as an analytical framework to determine the need for explainability in medical AI. Results: Each of the domains highlights a different set of core considerations and values that are relevant for understanding the role of explainability in clinical practice. From the technological point of view, explainability has to be considered both in terms how it can be achieved and what is beneficial from a development perspective. When looking at the legal perspective we identified informed consent, certification and approval as medical devices, and liability as core touchpoints for explainability. Both the medical and patient perspectives emphasize the importance of considering the interplay between human actors and medical AI. We conclude that omitting explainability in clinical decision support systems poses a threat to core ethical values in medicine and may have detrimental consequences for individual and public health. Conclusions: To ensure that medical AI lives up to its promises, there is a need to sensitize developers, healthcare professionals, and legislators to the challenges and limitations of opaque algorithms in medical AI and to foster multidisciplinary collaboration moving forward.},
   author = {Julia Amann and Alessandro Blasimme and Effy Vayena and Dietmar Frey and Vince I. Madai},
   doi = {10.1186/s12911-020-01332-6},
   issn = {14726947},
   issue = {1},
   journal = {BMC Medical Informatics and Decision Making},
   title = {Explainability for artificial intelligence in healthcare: a multidisciplinary perspective},
   volume = {20},
   year = {2020},
}
@article{khan2022,
   abstract = {Despite their commonly accepted usefulness, Artiﬁcial Intelligence (AI) technologies are concerned with ethical unreliability. Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies bring ethical well-being. However, the implications of AI ethics principles and guidelines are still being debated. To further explore the signiﬁcance of AI ethics principles and relevant challenges, we conducted an empirical survey of 99 AI practitioners and lawmakers from twenty countries across ﬁve continents. Study ﬁndings conﬁrm that transparency , accountability , and privacy are the most critical AI ethics principles. On the other hand, lack of ethical knowledge , no legal frameworks , and lacking monitoring bodies are found the most common AI ethics challenges. The impact analysis of the challenges across AI ethics principles reveals that conﬂict in practice is a highly severe challenge. Our ﬁndings stimulate further research, epically empowering existing capability maturity models to support the quality assessment of ethics-aware AI systems.},
   author = {A Khan and M Akbar and M Waseem and M Fahmideh and Aakash Ahmad and Peng Liang and M Niazi and P Abrahamsson},
   journal = {ArXiv},
   title = {AI Ethics: Software Practitioners and Lawmakers Points of View},
   volume = {abs/2207.0},
   year = {2022},
}
@misc{mohammadpour2019,
   abstract = {Melanoma is known as an aggressive tumor which shows an increasing incidence and poor prognosis in the metastatic phase. Hence, it seems that diagnosis and effective management (including early diagnosis, choosing of the effective therapeutic platform, caring, and training of patients for early detection) are major aspects of melanoma therapy. Early detection of melanoma is a key point for melanoma therapy. There are various diagnosis options such as assessing of biopsy, imaging techniques, and biomarkers (i.e., several proteins, polymorphism, and liquid biopsy). Among the various biomarkers, assessing circulating tumor cells, cell-free DNAs, cell-free RNAs, and microRNAs (miRNAs) have emerged as powerful diagnosis tools for melanoma patients. Deregulations of these molecules are associated with melanoma pathogenesis. After detection of melanoma, choosing of effective therapeutic regimen is a key step for recovery of melanoma patients. Several studies indicated that various therapeutic approaches including surgery, immunotherapy, systematic therapy, radiation therapy and antibodies therapy could be used as potential therapeutic candidates for melanoma therapy. Caring for melanoma patients is one of the important components of melanoma therapy. Caring and training for melanoma patients could contribute to better monitoring of patients in response to various therapeutic options. Here, we summarized various diagnosis approaches such as assessing biopsy, imaging techniques, and utilization of various biomarkers (i.e., proteins, CTCs, cfDNAs, and miRNAs) as a diagnostic biomarker for detection and monitoring patients with melanoma. Moreover, we highlighted various therapeutic options and caring aspects in patients with melanoma.},
   author = {Ali Mohammadpour and Maryam Derakhshan and Hassan Darabi and Pegah Hedayat and Mohammad Momeni},
   doi = {10.1002/jcp.27286},
   issn = {10974652},
   issue = {4},
   journal = {Journal of Cellular Physiology},
   title = {Melanoma: Where we are and where we go},
   volume = {234},
   year = {2019},
}
@article{skar2017,
   abstract = {Aim: The aim of this paper was to discuss the importance of ethical aspects when implementing eHealth services in health care. Background: Challenges in healthcare today include a growing older population and, as a consequence, an increased need for healthcare services. One possible solution is the use of eHealth services. Design: Discussion paper. Data sources: Research literature published from 2000–2017 in CINAHL, PubMed and Scopus. Implications for nursing: Implementing eHealth services in health care involves ethical challenges where different technologies can solve different problems in different ways. eHealth services should therefore be developed and implemented based on the patient's specific needs and conditions for use and in accordance with the healthcare professionals' presumption to provide high-quality care. Conclusion: To preserve patients' integrity, dignity and autonomy, healthcare professionals must include ethical aspects when implementing and using eHealth services in health care. Healthcare professionals have to take responsibility for the eHealth services introduced, explaining why and how they are implemented based on a person-centred approach. More knowledge is needed about ethical aspects when implementing eHealth services to improve the quality of care.},
   author = {Lisa Skär and Siv Söderberg},
   doi = {10.1111/jan.13493},
   issn = {13652648},
   issue = {5},
   journal = {Journal of Advanced Nursing},
   title = {The importance of ethical aspects when implementing eHealth services in healthcare: A discussion paper},
   volume = {74},
   year = {2018},
}
@article{Aas2021,
   abstract = {Explaining complex or seemingly simple machine learning models is an important practical problem. We want to explain individual predictions from such models by learning simple, interpretable explanations. Shapley value is a game theoretic concept that can be used for this purpose. The Shapley value framework has a series of desirable theoretical properties, and can in principle handle any predictive model. Kernel SHAP is a computationally efficient approximation to Shapley values in higher dimensions. Like several other existing methods, this approach assumes that the features are independent. Since Shapley values currently suffer from inclusion of unrealistic data instances when features are correlated, the explanations may be very misleading. This is the case even if a simple linear model is used for predictions. In this paper, we extend the Kernel SHAP method to handle dependent features. We provide several examples of linear and non-linear models with various degrees of feature dependence, where our method gives more accurate approximations to the true Shapley values.},
   author = {Kjersti Aas and Martin Jullum and Anders Løland},
   doi = {10.1016/j.artint.2021.103502},
   issn = {00043702},
   journal = {Artificial Intelligence},
   title = {Explaining individual predictions when features are dependent: More accurate approximations to Shapley values},
   volume = {298},
   year = {2021},
}
@article{Hamburger1996,
   abstract = {The fractal properties of models of randomly placed [Formula Presented]-dimensional spheres ([Formula Presented]) are studied using standard techniques for calculating fractal dimensions in empirical data (the box counting and Minkowski-sausage techniques). Using analytical and numerical calculations it is shown that in the regime of low volume fraction occupied by the spheres, apparent fractal behavior is observed for a range of scales between physically relevant cutoffs. The width of this range, typically spanning between one and two orders of magnitude, is in very good agreement with the typical range observed in experimental measurements of fractals. The dimensions are not universal and depend on density. These observations are applicable to spatial, temporal, and spectral random structures. Polydispersivity in sphere radii and impenetrability of the spheres (resulting in short range correlations) are also introduced and are found to have little effect on the scaling properties. We thus propose that apparent fractal behavior observed experimentally over a limited range may often have its origin in underlying randomness. © 1996 The American Physical Society.},
   author = {Daniel Hamburger and Ofer Biham and David Avnir},
   doi = {10.1103/PhysRevE.53.3342},
   issn = {1063651X},
   issue = {4},
   journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
   title = {Apparent fractality emerging from models of random distributions},
   volume = {53},
   year = {1996},
}
@article{Shen2009,
   abstract = {For dielectric inhomogeneous objects, the perceived reflections are the linear combinations of diffuse and specular reflection components. Specular reflection plays an important role in the fields of image analysis, pattern recognition, and scene synthesis. Several methods for the separation of the diffuse and the specular reflection components have been presented based on image segmentation or local interaction of neighboring pixels. We propose a simple and effective method for specularity removal in a single image on the level of each individual pixel. The chromaticity of diffuse reflection is approximately estimated by employing the concept of modified specular-free image, and the specular component is adjusted according to the criterion of smooth color transition along the boundary of diffuse and specular regions. Experimental results indicate that the proposed method is promising when compared with other state-of-the-art techniques, in both separation accuracy and running speed. © 2009 Optical Society of America.},
   author = {Hui Liang Shen and Qing Yuan Cai},
   doi = {10.1364/AO.48.002711},
   issn = {15394522},
   issue = {14},
   journal = {Applied Optics},
   title = {Simple and efficient method for specularity removal in an image},
   volume = {48},
   year = {2009},
}
@article{Lee2020,
   abstract = {A typical diagnosis of malignant melanoma involves three major steps: segmentation of a lesion from the input color image, feature extraction from the separated lesion, and classification to distinguish malignant from benign melanomas based on features obtained. We suggest new methods for segmentation, feature extraction, and classification compared. We replaced edge-imfill method with U-Otsu method for segmentation, the previous features with new features for the criteria ABCD (asymmetry, border irregularity, color variegation, diameter) criteria, and the median thresholding with weighted receiver operating characteristic thresholding for classification. We used 88 melanoma images and expert’s segmentation. All the three steps in the suggested method were compared with the steps in the previous method, with respect to sensitivity, specificity, and accuracy of the 88 samples. For segmentation, the previous and the suggested segmentations were also compared assuming the skin cancer expert’s segmentation as a ground truth. All three steps resulted in remarkable improvement in the suggested method.},
   author = {Hyunju Lee and Kiwoon Kwon},
   doi = {10.1007/s13534-019-00142-8},
   issn = {2093985X},
   issue = {1},
   journal = {Biomedical Engineering Letters},
   title = {Diagnostic techniques for improved segmentation, feature extraction, and classification of malignant melanoma},
   volume = {10},
   year = {2020},
}
@article{Seeja2019,
   abstract = {Objective: The main objective of this study is to improve the classification performance of melanoma using deep learning based automatic skin lesion segmentation. It can be assist medical experts on early diagnosis of melanoma on dermoscopy images. Methods: First A Convolutional Neural Network (CNN) based U-net algorithm is used for segmentation process. Then extract color, texture and shape features from the segmented image using Local Binary Pattern ( LBP), Edge Histogram (EH), Histogram of Oriented Gradients (HOG) and Gabor method. Finally all the features extracted from these methods were fed into the Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbor (KNN) and Naïve Bayes (NB) classifiers to diagnose the skin image which is either melanoma or benign lesions. Results: Experimental results show the effectiveness of the proposed method. The Dice co-efficiency value of 77.5% is achieved for image segmentation and SVM classifier produced 85.19% of accuracy. Conclusion: In deep learning environment, U-Net segmentation algorithm is found to be the best method for segmentation and it helps to improve the classification performance.},
   author = {R. D. Seeja and A. Suresh},
   doi = {10.31557/APJCP.2019.20.5.1555},
   issn = {2476762X},
   issue = {5},
   journal = {Asian Pacific Journal of Cancer Prevention},
   title = {Deep learning based skin lesion segmentation and classification of melanoma using support vector machine (SVM)},
   volume = {20},
   year = {2019},
}
@article{kasmi2023,
   abstract = {Background: The removal of hair and ruler marks is critical in handcrafted image analysis of dermoscopic skin lesions. No other dermoscopic artifacts cause more problems in segmentation and structure detection. Purpose: The aim of the work is to detect both white and black hair, artifacts and finally inpaint correctly the image. Method: We introduce a new algorithm: SharpRazor, to detect hair and ruler marks and remove them from the image. Our multiple-filter approach detects hairs of varying widths within varying backgrounds, while avoiding detection of vessels and bubbles. The proposed algorithm utilizes grayscale plane modification, hair enhancement, segmentation using tri-directional gradients, and multiple filters for hair of varying widths. We develop an alternate entropy-based processing adaptive thresholding method. White or light-colored hair, and ruler marks are detected separately and added to the final hair mask. A classifier removes noise objects. Finally, a new technique of inpainting is presented, and this is utilized to remove the detected object from the lesion image. Results: The proposed algorithm is tested on two datasets, and compares with seven existing methods measuring accuracy, precision, recall, dice, and Jaccard scores. SharpRazor is shown to outperform existing methods. Conclusion: The Shaprazor techniques show the promise to reach the purpose of removing and inpaint both dark and white hair in a wide variety of lesions.},
   author = {Reda Kasmi and Jason Hagerty and Reagan Young and Norsang Lama and Januka Nepal and Jessica Miinch and William Stoecker and R. Joe Stanley},
   doi = {10.1111/srt.13203},
   issn = {16000846},
   issue = {4},
   journal = {Skin Research and Technology},
   title = {SharpRazor: Automatic removal of hair and ruler marks from dermoscopy images},
   volume = {29},
   year = {2023},
}
@article{Lee1997,
   abstract = {Recently, there has been a growing number of studies applying image processing techniques to analyze melanocytic lesions for atypia and possible malignancy and for total-body mole mapping. However, such lesions can be partially obscured by body hairs. None of these studies has fully addressed the problem of human hairs occluding the imaged lesions. In our previous study we designed an automatic segmentation program to differentiate skin lesions from the normal healthy skin, and learned that the program performed well with most of the images, the exception being those with hairs, especially dark thick hairs, covering part of the lesions. These thick dark hairs confused the program, resulting in unsatisfactory segmentation results. In this paper, we present a methods to remove hairs from an image using a pre-processing program we have called DullRazor®. This pre-processing step enables the segmentation program to achieve satisfactory results DullRazor® can be downloaded as shareware from http://www.derm.ubc.ca.},
   author = {Tim Lee and Vincent Ng and Richard Gallagher and Andrew Coldman and David McLean},
   doi = {10.1016/S0010-4825(97)00020-6},
   issn = {00104825},
   issue = {6},
   journal = {Computers in Biology and Medicine},
   title = {Dullrazor®: A software approach to hair removal from images},
   volume = {27},
   year = {1997},
}
@article{Unver2019,
   abstract = {Skin lesion segmentation has a critical role in the early and accurate diagnosis of skin cancer by computerized systems. However, automatic segmentation of skin lesions in dermoscopic images is a challenging task owing to difficulties including artifacts (hairs, gel bubbles, ruler markers), indistinct boundaries, low contrast and varying sizes and shapes of the lesion images. This paper proposes a novel and effective pipeline for skin lesion segmentation in dermoscopic images combining a deep convolutional neural network named as You Only Look Once (YOLO) and the GrabCut algorithm. This method performs lesion segmentation using a dermoscopic image in four steps: 1. Removal of hairs on the lesion, 2. Detection of the lesion location, 3. Segmentation of the lesion area from the background, 4. Post-processing with morphological operators. The method was evaluated on two publicly well-known datasets, that is the PH2 and the ISBI 2017 (Skin Lesion Analysis Towards Melanoma Detection Challenge Dataset). The proposed pipeline model has achieved a 90% sensitivity rate on the ISBI 2017 dataset, outperforming other deep learning-based methods. The method also obtained close results according to the results obtained from other methods in the literature in terms of metrics of accuracy, specificity, Dice coefficient, and Jaccard index.},
   author = {Halil Murat Ünver and Enes Ayan},
   doi = {10.3390/diagnostics9030072},
   issn = {20754418},
   issue = {3},
   journal = {Diagnostics},
   title = {Skin lesion segmentation in dermoscopic images with combination of yolo and grabcut algorithm},
   volume = {9},
   year = {2019},
}
@misc{Wen2022,
   abstract = {Publicly available skin image datasets are increasingly used to develop machine learning algorithms for skin cancer diagnosis. However, the total number of datasets and their respective content is currently unclear. This systematic review aimed to identify and evaluate all publicly available skin image datasets used for skin cancer diagnosis by exploring their characteristics, data access requirements, and associated image metadata. A combined MEDLINE, Google, and Google Dataset search identified 21 open access datasets containing 106 950 skin lesion images, 17 open access atlases, eight regulated access datasets, and three regulated access atlases. Images and accompanying data from open access datasets were evaluated by two independent reviewers. Among the 14 datasets that reported country of origin, most (11 [79%]) originated from Europe, North America, and Oceania exclusively. Most datasets (19 [91%]) contained dermoscopic images or macroscopic photographs only. Clinical information was available regarding age for 81 662 images (76·4%), sex for 82 848 (77·5%), and body site for 79 561 (74·4%). Subject ethnicity data were available for 1415 images (1·3%), and Fitzpatrick skin type data for 2236 (2·1%). There was limited and variable reporting of characteristics and metadata among datasets, with substantial under-representation of darker skin types. This is the first systematic review to characterise publicly available skin image datasets, highlighting limited applicability to real-life clinical settings and restricted population representation, precluding generalisability. Quality standards for characteristics and metadata reporting for skin image datasets are needed.},
   author = {David Wen and Saad M. Khan and Antonio Ji Xu and Hussein Ibrahim and Luke Smith and Jose Caballero and Luis Zepeda and Carlos de Blas Perez and Alastair K. Denniston and Xiaoxuan Liu and Rubeta N. Matin},
   doi = {10.1016/S2589-7500(21)00252-1},
   issn = {25897500},
   issue = {1},
   journal = {The Lancet Digital Health},
   title = {Characteristics of publicly available skin cancer image datasets: a systematic review},
   volume = {4},
   year = {2022},
}
@article{Nachbar1994,
   abstract = {Background: The difficulties in accurately assessing pigmented skin lesions are ever present in practice. The recently described ABCD rule of dermatoscopy (skin surface microscopy at ×10 magnification), based on the criteria asymmetry (A), border (B), color (C), and differential structure (D), improved diagnostic accuracy when applied retrospectively to clinical slides. Objective: A study was designed to evaluate the prospective value of the ABCD rule of dermatoscopy in melanocytic lesions. Methods: In 172 melanocytic pigmented skin lesions, the criteria of the ABCD rule of dermatoscopy were analyzed with a semiquantitative scoring system before excision. Results: According to the retrospectively determined threshold, tumors with a score higher than 5.45 (64/69 melanomas [92.8%]) were classified as malignant, whereas lesions with a lower score were considered as benign (93/103 melanocytic nevi [90.3%]). Negative predictive value for melanoma (True-Negative ÷ [True-Negative + False-Negative]) was 9 5.8%, whereas positive predictive value (True-Positive ÷ [True-Positive + False-Positive]) was 85.3%. Diagnostic accuracy for melanoma (True-Positive ÷ [True-Positive + False- Positive + False-Negative]) was 80.0%, compared with 64.4% by the naked eye. Melanoma showed a mean final dermatoscopy score of 6.79 (SD, ± 0.92), significantly differing from melanocytic nevi (mean score, 4.27 ± 0.99; p <0.01, U test). Conclusion: The ABCD rule can be easily learned and rapidly calculated, and has proven to be reliable. It should be routinely applied to all equivocal pigmented skin lesions to reach a more objective and reproducible diagnosis and to obtain this assessment preoperatively.},
   author = {Franz Nachbar and Wilhelm Stolz and Tanja Merkle and Armand B. Cognetta and Thomas Vogt and Michael Landthaler and Peter Bilek and Otto Braun-Falco and Gerd Plewig},
   doi = {10.1016/s0190-9622(94)70061-3},
   issn = {01909622},
   issue = {4},
   journal = {Journal of the American Academy of Dermatology},
   month = {4},
   pages = {551-559},
   publisher = {Elsevier BV},
   title = {The ABCD rule of dermatoscopy},
   volume = {30},
   year = {1994},
}
@article{Ghorbani2019,
   abstract = {In order for machine learning to be trusted in many applications, it is critical to be able to reliably explain why the machine learning algorithm makes certain predictions. For this reason, a variety of methods have been developed recently to interpret neural network predictions by providing, for example, feature importance maps. For both scientific robustness and security reasons, it is important to know to what extent can the interpretations be altered by small systematic perturbations to the input data, which might be generated by adversaries or by measurement biases. In this paper, we demonstrate how to generate adversarial perturbations that produce perceptively indistinguishable inputs that are assigned the same predicted label, yet have very different interpretations. We systematically characterize the robustness of interpretations generated by several widely-used feature importance interpretation methods (feature importance maps, integrated gradients, and DeepLIFT) on ImageNet and CIFAR-10. In all cases, our experiments show that systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly susceptible to adversarial attack. Our analysis of the geometry of the Hessian matrix gives insight on why robustness is a general challenge to current interpretation approaches.},
   author = {Amirata Ghorbani and Abubakar Abid and James Zou},
   doi = {10.1609/aaai.v33i01.33013681},
   issn = {2159-5399},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   pages = {3681-3688},
   title = {Interpretation of Neural Networks Is Fragile},
   volume = {33},
   year = {2019},
}
@article{chen2018,
   abstract = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed 'DeepLab' system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
   author = {Liang Chieh Chen and George Papandreou and Iasonas Kokkinos and Kevin Murphy and Alan L. Yuille},
   doi = {10.1109/TPAMI.2017.2699184},
   issn = {01628828},
   issue = {4},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   title = {DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs},
   volume = {40},
   year = {2018},
}
@article{Riaz2019,
   abstract = {This paper proposes a computer assisted diagnostic system for the detection of melanoma in dermoscopy images. Clinical findings have concluded that in case of melanoma, the lesion borders exhibit differential structures such as pigment networks and streaks as opposed to normal skin spots, which have smoother borders. We aim at validating these findings by performing segmentation of the skin lesions followed by an extraction of the peripheral region of the lesion that is subjected to feature extraction and classification for detecting melanoma. For segmentation, we propose a novel active contours based method that takes an initial lesion contour followed by the usage of Kullback-Leibler divergence between the lesion and skin to fit a curve to the lesion boundaries. After segmentation of the lesion, its periphery is extracted to detect melanoma using image features that are based on local binary patterns. For validation of our algorithms, we have used the publicly available PH2 and ISIC dermoscopy datasets. An extensive experimental analysis reveals two important findings: 1) the proposed segmentation method mimics the ground truth data; and 2) the most significant melanoma characteristics in the lesion actually lie on the lesion periphery.},
   author = {Farhan Riaz and Sidra Naeem and Raheel Nawaz and Miguel Coimbra},
   doi = {10.1109/JBHI.2018.2832455},
   issn = {21682208},
   issue = {2},
   journal = {IEEE Journal of Biomedical and Health Informatics},
   title = {Active Contours Based Segmentation and Lesion Periphery Analysis for Characterization of Skin Lesions in Dermoscopy Images},
   volume = {23},
   year = {2019},
}
@article{Albahli2020,
   abstract = {Melanoma is the skin cancer caused by the ultraviolet radiation from the Sun and has only 15-20% of survival rate. Late diagnosis of melanoma leads to the severe malignancy of disease, and metastasis expands to the other body organs i.e. liver, lungs and brain. The dermatologists analyze the pigmented lesions over the skin to discriminate melanoma from other skin diseases. However, the imprecise analysis results in the form of a series of biopsies and it complicates the treatment. Meanwhile, the process of melanoma detection can be expedited through computer vision methods by analyzing the dermoscopic images automatically. However, the visual similarity between the normal and infected skin regions, and arti-facts like gel bubbles, hair and clinical marks indicate low accuracy rates for these approaches. To overcome these challenges, in this article, a melanoma detection and segmentation approach is presented that brings significant improvement in terms of accuracy against state-of-the-art approaches. As a first step, the artifacts like hairs, gel bubbles, and clinical marks are removed from the dermoscopic images by applying the morphological operations, and image regions are sharpen. Afterwards, for infected region detection, we used YOLOv4 object detector by tuning it for melanoma detection to discriminate the highly correlated infected and non-infected regions. Once the bounding boxes against the melanoma regions are obtained, the infected melanoma regions are extracted by applying the active contour segmentation approach. For performance evaluation, the proposed approach is evaluated on ISIC2018 and ISIC2016 datasets and results are compared against state-of-the-art melanoma detection, and segmentation techniques. Our proposed approach achieves average dice score as 1 and Jaccard coefficient as 0.989. The segmentation result validates the practical bearing of our method in development of clinical decision support system for melanoma diagnosis in contrast to state-of-the-art methods. The YOLOv4 detector is capable to detect multiple skin diseases of same patient and multiple diseases of various patients.},
   author = {Saleh Albahli and Nudrat Nida and Aun Irtaza and Muhammad Haroon Yousaf and Muhammad Tariq Mahmood},
   doi = {10.1109/ACCESS.2020.3035345},
   issn = {21693536},
   journal = {IEEE Access},
   title = {Melanoma Lesion Detection and Segmentation Using YOLOv4-DarkNet and Active Contour},
   volume = {8},
   year = {2020},
}
@article{Dascalu2022,
   abstract = {Purpose: Non-melanoma skin cancer (NMSC) is the most frequent keratinocyte-origin skin tumor. It is confirmed that dermoscopy of NMSC confers a diagnostic advantage as compared to visual face-to-face assessment. COVID-19 restrictions diagnostics by telemedicine photos, which are analogous to visual inspection, displaced part of in-person visits. This study evaluated by a dual convolutional neural network (CNN) performance metrics in dermoscopic (DI) versus smartphone-captured images (SI) and tested if artificial intelligence narrows the proclaimed gap in diagnostic accuracy. Methods: A CNN that receives a raw image and predicts malignancy, overlaid by a second independent CNN which processes a sonification (image-to-sound mapping) of the original image, were combined into a unified malignancy classifier. All images were histopathology-verified in a comparison between NMSC and benign skin lesions excised as suspected NMSCs. Study criteria outcomes were sensitivity and specificity for the unified output. Results: Images acquired by DI (n = 132 NMSC, n = 33 benign) were compared to SI (n = 170 NMSC, n = 28 benign). DI and SI analysis metrics resulted in an area under the curve (AUC) of the receiver operator characteristic curve of 0.911 and 0.821, respectively. Accuracy was increased by DI (0.88; CI 81.9–92.4) as compared to SI (0.75; CI 68.1–80.6, p < 0.005). Sensitivity of DI was higher than SI (95.3%, CI 90.4–98.3 vs 75.3%, CI 68.1–81.6, p < 0.001), but not specificity (p = NS). Conclusion: Telemedicine use of smartphone images might result in a substantial decrease in diagnostic performance as compared to dermoscopy, which needs to be considered by both healthcare providers and patients.},
   author = {A. Dascalu and B. N. Walker and Y. Oron and E. O. David},
   doi = {10.1007/s00432-021-03809-x},
   issn = {14321335},
   issue = {9},
   journal = {Journal of Cancer Research and Clinical Oncology},
   title = {Non-melanoma skin cancer diagnosis: a comparison between dermoscopic and smartphone images by unified visual and sonification deep learning algorithms},
   volume = {148},
   year = {2022},
}
@misc{Wolner2017,
   abstract = {Dermoscopy increases the sensitivity for skin cancer detection, decreases the number of benign lesions biopsied for each malignant diagnosis, and enables the diagnosis of thinner melanomas compared with naked eye examination. Multiple meta-analyses have identified that dermoscopy improves the diagnostic accuracy for melanoma when compared with naked eye examination. In addition, studies have established that dermoscopy can aid in the detection of keratinocyte carcinomas. Dermoscopy triage algorithms have been developed to help novices decide when a biopsy or a referral is most appropriate. In this article, the authors illustrate the dermoscopic features that assist in identifying melanoma and keratinocyte carcinomas.},
   author = {Zachary J. Wolner and Oriol Yélamos and Konstantinos Liopyris and Tova Rogers and Michael A. Marchetti and Ashfaq A. Marghoob},
   doi = {10.1016/j.det.2017.06.003},
   issn = {15580520},
   issue = {4},
   journal = {Dermatologic Clinics},
   title = {Enhancing Skin Cancer Diagnosis with Dermoscopy},
   volume = {35},
   year = {2017},
}
@inproceedings{Tae2019,
   abstract = {The wide use of machine learning is fundamentally changing the software development paradigm (a.k.a. Software 2.0) where data becomes a first-class citizen, on par with code. As machine learning is used in sensitive applications, it becomes imperative that the trained model is accurate, fair, and robust to attacks. While many techniques have been proposed to improve the model training process (in-processing approach) or the trained model itself (post-processing), we argue that the most effective method is to clean the root cause of error: the data the model is trained on (pre-processing). Historically, there are at least three research communities that have been separately studying this problem: data management, machine learning (model fairness), and security. Although a significant amount of research has been done by each community, ultimately the same datasets must be preprocessed, and there is little understanding how the techniques relate to each other and can possibly be integrated. We contend that it is time to extend the notion of data cleaning for modern machine learning needs. We identify dependencies among the data preprocessing techniques and propose MLClean, a unified data cleaning framework that integrates the techniques and helps train accurate and fair models. This work is part of a broader trend of Big data -- Artificial Intelligence (AI) integration.},
   author = {Ki Hyun Tae and Yuji Roh and Young Hun Oh and Hyunsu Kim and Steven Euijong Whang},
   doi = {10.1145/3329486.3329493},
   title = {Data Cleaning for Accurate, Fair, and Robust Models},
   year = {2019},
}
@article{Lipton2018,
   author = {Zachary C. Lipton},
   doi = {10.1145/3233231},
   issn = {15577317},
   issue = {10},
   journal = {Communications of the ACM},
   title = {The mythos of model interpretability},
   volume = {61},
   year = {2018},
}
@article{Achanta2012,
   abstract = {Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation. © 2012 IEEE.},
   author = {Radhakrishna Achanta and Appu Shaji and Kevin Smith and Aurelien Lucchi and Pascal Fua and Sabine Süsstrunk},
   doi = {10.1109/TPAMI.2012.120},
   issn = {01628828},
   issue = {11},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   title = {SLIC superpixels compared to state-of-the-art superpixel methods},
   volume = {34},
   year = {2012},
}
@inproceedings{mendonca2013,
   abstract = {The increasing incidence of melanoma has recently promoted the development of computer-aided diagnosis systems for the classification of dermoscopic images. Unfortunately, the performance of such systems cannot be compared since they are evaluated in different sets of images by their authors and there are no public databases available to perform a fair evaluation of multiple systems. In this paper, a dermoscopic image database, called PH2, is presented. The PH2 database includes the manual segmentation, the clinical diagnosis, and the identification of several dermoscopic structures, performed by expert dermatologists, in a set of 200 dermoscopic images. The PH2 database will be made freely available for research and benchmarking purposes. © 2013 IEEE.},
   author = {Teresa Mendonca and Pedro M. Ferreira and Jorge S. Marques and Andre R.S. Marcal and Jorge Rozeira},
   doi = {10.1109/EMBC.2013.6610779},
   issn = {1557170X},
   journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
   title = {PH2 - A dermoscopic image database for research and benchmarking},
   year = {2013},
}
@misc{Takiddin2021,
   abstract = {Background: Skin cancer is the most common cancer type affecting humans. Traditional skin cancer diagnosis methods are costly, require a professional physician, and take time. Hence, to aid in diagnosing skin cancer, artificial intelligence (AI) tools are being used, including shallow and deep machine learning-based methodologies that are trained to detect and classify skin cancer using computer algorithms and deep neural networks. Objective: The aim of this study was to identify and group the different types of AI-based technologies used to detect and classify skin cancer. The study also examined the reliability of the selected papers by studying the correlation between the data set size and the number of diagnostic classes with the performance metrics used to evaluate the models. Methods: We conducted a systematic search for papers using Institute of Electrical and Electronics Engineers (IEEE) Xplore, Association for Computing Machinery Digital Library (ACM DL), and Ovid MEDLINE databases following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines. The studies included in this scoping review had to fulfill several selection criteria: being specifically about skin cancer, detecting or classifying skin cancer, and using AI technologies. Study selection and data extraction were independently conducted by two reviewers. Extracted data were narratively synthesized, where studies were grouped based on the diagnostic AI techniques and their evaluation metrics. Results: We retrieved 906 papers from the 3 databases, of which 53 were eligible for this review. Shallow AI-based techniques were used in 14 studies, and deep AI-based techniques were used in 39 studies. The studies used up to 11 evaluation metrics to assess the proposed models, where 39 studies used accuracy as the primary evaluation metric. Overall, studies that used smaller data sets reported higher accuracy. Conclusions: This paper examined multiple AI-based skin cancer detection models. However, a direct comparison between methods was hindered by the varied use of different evaluation metrics and image types. Performance scores were affected by factors such as data set size, number of diagnostic classes, and techniques. Hence, the reliability of shallow and deep models with higher accuracy scores was questionable since they were trained and tested on relatively small data sets of a few diagnostic classes.},
   author = {Abdulrahman Takiddin and Jens Schneider and Yin Yang and Alaa Abd-Alrazaq and Mowafa Househ},
   doi = {10.2196/22934},
   issn = {14388871},
   issue = {11},
   journal = {Journal of Medical Internet Research},
   title = {Artificial intelligence for skin cancer detection: Scoping review},
   volume = {23},
   year = {2021},
}
@article{Kasmi2016,
   abstract = {The ABCD (asymmetry, border irregularity, colour and dermoscopic structure) rule of dermoscopy is a scoring method used by dermatologists to quantify dermoscopy findings and effectively separate melanoma from benign lesions. Automatic detection of the ABCD features and separation of benign lesions from melanoma could enable earlier detection of melanoma. In this study, automatic ABCD scoring of dermoscopy lesions is implemented. Pre-processing enables automatic detection of hair using Gabor filters and lesion boundaries using geodesic active contours. Algorithms are implemented to extract the characteristics of ABCD attributes. Methods used here combine existing methods with novel methods to detect colour asymmetry and dermoscopic structures. To classify lesions as melanoma or benign nevus, the total dermoscopy score is calculated. The experimental results, using 200 dermoscopic images, where 80 are malignant melanomas and 120 benign lesions, show that the algorithm achieves 91.25% sensitivity of 91.25 and 95.83% specificity. This is comparable to the 92.8% sensitivity and 90.3% specificity reported for human implementation of the ABCD rule. The experimental results show that the extracted features can be used to build a promising classifier for melanoma detection.},
   author = {Reda Kasmi and Karim Mokrani},
   doi = {10.1049/iet-ipr.2015.0385},
   issn = {17519659},
   issue = {6},
   journal = {IET Image Processing},
   pages = {448-455},
   title = {Classification of malignant melanoma and benign skin lesions: Implementation of automatic ABCD rule},
   volume = {10},
   year = {2016},
}
@article{Gilpin2018,
   abstract = {There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.},
   author = {Leilani H. Gilpin and David Bau and Ben Z. Yuan and Ayesha Bajwa and Michael Specter and Lalana Kagal},
   doi = {10.1109/DSAA.2018.00018},
   isbn = {9781538650905},
   journal = {Proceedings - 2018 IEEE 5th International Conference on Data Science and Advanced Analytics, DSAA 2018},
   keywords = {Deep learning and deep analytics,Fairness and transparency in data science,Machine learning theories,Models and systems},
   pages = {80-89},
   title = {Explaining explanations: An overview of interpretability of machine learning},
   year = {2019},
}
@article{Izikson2002,
   abstract = {Objective: To estimate the prevalence of melanoma clinically mimicking seborrheic keratosis. Design: Retrospective review of cases submitted for histological examination with a clinical diagnosis of seborrheic keratosis or with a differential diagnosis that included seborrheic keratosis. Setting: A tertiary medical care center-based dermatopathology laboratory serving academic dermatology clinics that have a busy pigmented lesion clinic. Materials and Methods: A total of 9204 consecutive pathology reports containing a diagnosis of seborrheic keratosis in the clinical information field were identified between the years 1992 and 2001 through a computer database search. Reports with a final histological diagnosis of melanoma were selected for further review and clinicopathological analysis. Main Outcome Measure: Histological diagnosis, which was correlated with the preoperative clinical diagnosis. Results: Melanoma was identified in 61 cases (0.66%) submitted for histological examination with a clinical diagnosis that included seborrheic keratosis. Melanoma was in the clinical differential diagnosis of 31 cases (51%). The remaining lesions had a differential diagnosis of seborrheic keratosis vs melanocytic nevus (17 cases, 28%), basal cell carcinoma (7 cases, 12%), or a squamous proliferation (3 cases, 5%). In 3 cases (5%), seborrheic keratosis was the only clinical diagnosis. All histological types of melanoma were represented. Conclusions: Our results confirm that melanoma can mimic seborrheic keratosis. These data strongly support the current policy of submitting for histological examination all specimens that have been removed from patients.},
   author = {Leonid Izikson and Arthur J. Sober and Martin C. Mihm and Artur Zembowicz},
   doi = {10.1001/archderm.138.12.1562},
   issn = {0003987X},
   issue = {12},
   journal = {Archives of Dermatology},
   title = {Prevalence of melanoma clinically resembling seborrheic keratosis: Analysis of 9204 cases},
   volume = {138},
   year = {2002},
}
@article{Stanienda2017,
   abstract = {Introduction: Location of malignant melanoma lesions depends on environmental, genetic, sociological and demographical factors. Available sources do not provide enough information on such dependencies in various populations. There is no data concerning the role of socio-demographic factors for the population of the Central and Eastern Europe. Aim: The aim of this work was to evaluate the anatomical location of the primary malignant melanoma lesion in correlation to patients' gender and age. Material and methods: A retrospective analysis of medical documentation of 363 patients has been performed. The patients had been diagnosed with malignant melanoma and were undergoing treatment in the years 2010-2014 in two Polish oncologic hospitals. The subject group consisted of 199 (55%) females and 164 (45%) males. The age varied between 19 - 90 years, with the median of 62 years. Results: In women, the melanoma lesions seem to appear more often in their lower extremities, while in case of men such lesions seem to be more often on their torsos. In both cases, the difference was statistically significant (p < 0.01 When the specific locations are considered in women the lesions were more often located on their shins (p < 0.01), whereas for men the lesions were located on their backs (p < 0.01). It has been observed that there is dependency between lesion localization and age of patients. The lesions located on heads and necks were most common in older patients, and the lesions located in lower extremities were most common in younger ones. Conclusion: Differences in location of malignant melanoma lesions may be due to either genetic or environmental reasons. It is often emphasized in literature that correlation between the socio-demographic factors and the process of oncogenesis requires intensive research. In our work, we have tried to fill this gap for the population of Central and Eastern Europe to determine the exact epidemiology of this kind of cancer. This knowledge may be then used for developing cancer prevention methods specific to gender and age.},
   author = {Karolina Stanienda-Sokół and Natalia Salwowska and Martyna Sławińska and Katarzyna Wicherska-Pawlowska and Anna Lorenc and Dominika Wcisło-Dziadecka and Jerzy Wydmański and Wojciech Majewski},
   doi = {10.22034/APJCP.2017.18.11.3081},
   issn = {2476762X},
   issue = {11},
   journal = {Asian Pacific Journal of Cancer Prevention},
   title = {Primary locations of malignant melanoma lesions depending on patients' gender and age},
   volume = {18},
   year = {2017},
}
@article{Anantha04,
   abstract = {Dermatoscopy, also known as dermoscopy or epiluminescence microscopy (ELM), is a non-invasive, in vivo technique, which permits visualization of features of pigmented melanocytic neoplasms that are not discernable by examination with the naked eye. ELM offers a completely new range of visual features. One such prominent feature is the pigment network. Two texture-based algorithms are developed for the detection of pigment network. These methods are applicable to various texture patterns in dermatoscopy images, including patterns that lack fine lines such as cobblestone, follicular, or thickened network patterns. Two texture algorithms, Laws energy masks and the neighborhood gray-level dependence matrix (NGLDM) large number emphasis, were optimized on a set of 155 dermatoscopy images and compared. Results suggest superiority of Laws energy masks for pigment network detection in dermatoscopy images. For both methods, a texel width of 10 pixels or approximately 0.22 mm is found for dermatoscopy images. © 2004 Published by Elsevier Ltd.},
   author = {Murali Anantha and Randy H. Moss and William V. Stoecker},
   doi = {10.1016/j.compmedimag.2004.04.002},
   issn = {08956111},
   issue = {5},
   journal = {Computerized Medical Imaging and Graphics},
   title = {Detection of pigment network in dermatoscopy images using texture analysis},
   volume = {28},
   year = {2004},
}
@article{Kasuya2019,
   abstract = {Dermoscopy is a convenient tool to diagnose melanocytic lesions, especially nevus and melanoma. Various pigmented structures, including pigment network, dots and globules, and streaks, are observed in dermoscopy. Usually, 2D vertical images are used to explain the correlation of dermoscopy and histopathology. However, because the image of dermoscopy is horizontal, it is difficult for the horizontal view of dermoscopy to refer to the vertical view of histopathology. In our study, we digitally reconstructed 2D horizontal top-down view images and 3D aerial images from 50–100 serial 2D vertical sections by using high-speed scanner and 3D software in 6 cases of melanocytic lesion. Our new technology intuitively explained the histopathological structures corresponding to the dermoscopic structures. This technique could be used as a good educational tool for beginners.},
   author = {Akira Kasuya and Masahiro Aoshima and Kensuke Fukuchi and Takatoshi Shimauchi and Toshiharu Fujiyama and Yoshiki Tokura},
   doi = {10.1038/s41598-019-56522-8},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   pmid = {31882764},
   title = {An intuitive explanation of dermoscopic structures by digitally reconstructed pathological horizontal top-down view images},
   volume = {9},
   year = {2019},
}
@inproceedings{sander2013,
   abstract = {Bayesian statistics leads to a powerful fusion methodology, especially for the fusion of heterogeneous information sources. If fusion problems are handled under consideration of the full expressiveness and the full range of methods provided by Bayesian statistics, the Bayesian fusion methodology possesses an impressive wide range of applications. We discuss this by having a closer look at selected aspects of Bayesian modeling. Thereby, also parallels to other methods used for information fusion will be drawn. With regard to the practical tractability of Bayesian fusion problems, selected approaches to deal with its potentially high complexity are discussed. © 2013 IEEE.},
   author = {Jennifer Sander and Jurgen Beyerer},
   doi = {10.1109/SDF.2013.6698254},
   journal = {2013 Workshop on Sensor Data Fusion: Trends, Solutions, Applications, SDF 2013},
   title = {Bayesian fusion: Modeling and application},
   year = {2013},
}
@article{unlu2014,
   abstract = {Dermatoscopic analysis of melanocytic lesions using the CASH algorithm has rarely been described in the literature. The purpose of this study was to compare the sensitivity, specificity, and diagnostic accuracy rates of the ABCD rule of dermatoscopy, the seven-point checklist, the three-point checklist, and the CASH algorithm in the diagnosis and dermatoscopic evaluation of melanocytic lesions on the hairy skin. One hundred and fifteen melanocytic lesions of 115 patients were examined retrospectively using dermatoscopic images and compared with the histopathologic diagnosis. Four dermatoscopic algorithms were carried out for all lesions. The ABCD rule of dermatoscopy showed sensitivity of 91.6%, specificity of 60.4%, and diagnostic accuracy of 66.9%. The seven-point checklist showed sensitivity, specificity, and diagnostic accuracy of 87.5, 65.9, and 70.4%, respectively; the three-point checklist 79.1, 62.6, 66%; and the CASH algorithm 91.6, 64.8, and 70.4%, respectively. To our knowledge, this is the first study that compares the sensitivity, specificity and diagnostic accuracy of the ABCD rule of dermatoscopy, the three-point checklist, the seven-point checklist, and the CASH algorithm for the diagnosis of melanocytic lesions on the hairy skin. In our study, the ABCD rule of dermatoscopy and the CASH algorithm showed the highest sensitivity for the diagnosis of melanoma. © 2014 Japanese Dermatological Association.},
   author = {Ezgi Unlu and Bengu N. Akay and Cengizhan Erdem},
   doi = {10.1111/1346-8138.12491},
   issn = {13468138},
   issue = {7},
   journal = {Journal of Dermatology},
   keywords = {ABCD rule of dermatoscopy,CASH algorithm,dermatoscopy,seven-point checklist,three-point checklist},
   pages = {598-603},
   pmid = {24807635},
   publisher = {Blackwell Publishing Ltd},
   title = {Comparison of dermatoscopic diagnostic algorithms based on calculation: The ABCD rule of dermatoscopy, the seven-point checklist, the three-point checklist and the CASH algorithm in dermatoscopic evaluation of melanocytic lesions},
   volume = {41},
   year = {2014},
}
@article{Morton1998,
   abstract = {Diagnostic accuracy for melanoma was determined in a dedicated pigmented lesion clinic. We assessed the impact of duration of experience in dermatology and also the relationship between tumour thickness and accuracy of clinical diagnosis. We reviewed the histopathology request forms and reports for all biopsies generated by the Pigmented Lesion Clinic, Western Infirmary, Glasgow during 1992-94 inclusive. The clinic is staffed by two consultants, one senior registrar and one registrar. Diagnostic accuracy, index of suspicion, sensitivity, specificity and positive predictive value were calculated for the clinic overall, and for each grade of staff. One hundred and sixty-three lesions were diagnosed clinically as melanoma. A histopathological diagnosis of melanoma was made for 128 lesions during this period, 113 of which had been correctly diagnosed before surgery. The diagnostic accuracy for two dermatologists each with > 10 years experience in dermatology was 80%, with sensitivity of 91% and positive predictive value of 86%. Diagnostic accuracy rates for two senior registrars (each with 3-5 years experience) and six registrars (each with 1-2 years experience) were 62% and 56%, respectively. Thin and intermediate thickness melanomas generated the greatest inaccuracy irrespective of clinical experience, although registrars failed to recognize melanoma three times more often than the other groups. We report the diagnostic accuracy for melanoma by trained dermatologists to be higher than previously reported. In comparison with trainees, > 10 years experience in dermatology and exposure to more than 10 melanomas per year appears to be associated with greater diagnostic accuracy. Knowledge of the current clinical diagnostic accuracy at varying levels of experience is essential if the impact of training is to be evaluated. As pigmented lesions of virtually all types can be treated within dermatology departments, dermatologists are the appropriate first point of referral for suspected early melanoma.},
   author = {C. A. Morton and R. M. Mackie},
   doi = {10.1046/j.1365-2133.1998.02075.x},
   issn = {00070963},
   issue = {2},
   journal = {British Journal of Dermatology},
   title = {Clinical accuracy of the diagnosis of cutaneous malignant melanoma},
   volume = {138},
   year = {1998},
}
@misc{bhatia2009,
   abstract = {The 10-year survival rate for patients with metastatic melanoma is less than 10%. Although surgery and radiation therapy have a role in the treatment of metastatic disease, systemic therapy is the mainstay of treatment for most patients. Single-agent chemotherapy is well tolerated but is associated with response rates of only 5% to 20%. Combination chemotherapy and biochemotherapy may improve objective response rates but do not extend survival and are associated with greater toxicity. Immunotherapeutic approaches such as high-dose interleukin-2 are associated with durable responses in a small percentage of patients. In this article, we review the treatments for metastatic melanoma including promising investigational approaches.},
   author = {Shailender Bhatia and Scott S. Tykodi and John A. Thompson},
   issn = {08909091},
   issue = {6},
   journal = {ONCOLOGY},
   title = {Treatment of metastatic melanoma: An overview},
   volume = {23},
   year = {2009},
}
@misc{RalphBraunAshMarghoob,
   author = {Aimilios Lallas Ralph Braun, Ash Marghoob},
   journal = {Two-step algorithm},
   publisher = {dermoscopedia.},
   title = {Introduction to the top-down 2-step approach},
   url = {https://dermoscopedia.org/w/index.php?title=Introduction_to_the_top-down_2-step_approach&oldid=13500},
   year = {2021},
}
@article{Anagnostopoulos2014,
   abstract = {The main contributions of this paper are an automated approach for applying the ABCDE rules in a digital dermoscopy platform with fixed settings and a new registration method specially designed for aligning and comparing follow-up digital dermoscopy images in order to evaluate the evolution over time parameter E. Experimental evaluations of the registration method are reported for image pairs acquired during follow-up examinations.},
   author = {Christos Nikolaos E. Anagnostopoulos and Dimitrios D. Vergados and Ioannis Anagnostopoulos and Panagiotis Mintzias},
   doi = {10.1109/EMBC.2014.6945176},
   isbn = {9781424479290},
   journal = {2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2014},
   keywords = {Total Dermoscopy Score,digital dermoscopy,image processing},
   pages = {6744-6747},
   pmid = {25571544},
   title = {Total dermoscopy score calculation using quantitative measurements in digital dermoscopy},
   year = {2014},
}
@article{Takruri2017,
   abstract = {This paper studies the problem of automated noninvasive skin cancer (melanoma) detection from digital images of skin lesions. It proposes the use of Bayesian Decision Fusion of a multiple of classifiers to enhance the melanoma detection rates. A comparison with other decision fusion systems along with standalone classifiers in terms of accuracy and confidence intervals is made. The relation between confidence distribution and accuracy over different classification systems is studied. Performance evaluations of the proposed Bayesian Decision fusion method shows that it results in improved recognition accuracy compared to standalone Skin Lesion classifiers. It also provides comparable confidence intervals and can offer stable recognition rate. Hence, it can lead to increased chances of non-invasive melanoma detection.},
   author = {Maen Takruri and Abubakar Abubakar},
   doi = {10.1109/ICECTA.2017.8252063},
   isbn = {9781538608722},
   journal = {2017 International Conference on Electrical and Computing Technologies and Applications, ICECTA 2017},
   keywords = {Bayesian Fusion,Confidence,Melanoma},
   pages = {1-4},
   title = {Bayesian decision fusion for enhancing melanoma recognition accuracy},
   volume = {2018-Janua},
   year = {2017},
}
@article{Sondermann2019,
   abstract = {Recent research revealed the superiority of artificial intelligence over dermatologists to diagnose melanoma from images. However, 30–50% of all melanomas and more than half of those in young patients evolve from initially benign lesions. Despite its high relevance for melanoma screening, neither clinicians nor computers are yet able to reliably predict a nevus’ oncologic transformation. The cause of this lies in the static nature of lesion presentation in the current standard of care, both for clinicians and algorithms. The status quo makes it difficult to train algorithms (and clinicians) to precisely assess the likelihood of a benign skin lesion to transform into melanoma. In addition, it inhibits the precision of current algorithms since ‘evolution’ image features may not be part of their decision. The current literature reveals certain types of melanocytic nevi (i.e. ‘spitzoid’ or ‘dysplastic’ nevi) and criteria (i.e. visible vasculature) that, in general, appear to have a higher chance to transform into melanoma. However, owing to the cumulative nature of oncogenic mutations in melanoma, a more fine-grained early morphologic footprint is likely to be detectable by an algorithm. In this perspective article, the concept of melanoma prediction is further explored by the discussion of the evolution of melanoma, the concept for training of such a nevi classifier and the implications of early melanoma prediction for clinical practice. In conclusion, the authors believe that artificial intelligence trained on prospective image data could be transformative for skin cancer diagnostics by (a) predicting melanoma before it occurs (i.e. pre-in situ) and (b) further enhancing the accuracy of current melanoma classifiers. Necessary prospective images for this research are obtained via free mole-monitoring mobile apps.},
   author = {Wiebke Sondermann and Jochen Sven Utikal and Alexander H. Enk and Dirk Schadendorf and Joachim Klode and Axel Hauschild and Michael Weichenthal and Lars E. French and Carola Berking and Bastian Schilling and Sebastian Haferkamp and Stefan Fröhling and Christof von Kalle and Titus J. Brinker},
   doi = {10.1016/j.ejca.2019.07.009},
   issn = {18790852},
   journal = {European Journal of Cancer},
   keywords = {Artificial intelligence,Deep learning,Melanoma,Prediction,Skin cancer},
   pages = {30-34},
   pmid = {31401471},
   title = {Prediction of melanoma evolution in melanocytic nevi via artificial intelligence: A call for prospective data},
   volume = {119},
   year = {2019},
}
@article{Kim2014,
   abstract = {We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the "quintessential" observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in inter-pretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM, compared to those given by prior art.},
   author = {Been Kim and Cynthia Rudin and Julie Shah},
   issn = {10495258},
   issue = {January},
   journal = {Advances in Neural Information Processing Systems},
   pages = {1952-1960},
   title = {The Bayesian case model: A generative approach for case-based reasoning and prototype classification},
   volume = {3},
   year = {2014},
}
@article{Dick2019,
   abstract = {Importance: The recent advances in the field of machine learning have raised expectations that computer-aided diagnosis will become the standard for the diagnosis of melanoma. Objective: To critically review the current literature and compare the diagnostic accuracy of computer-aided diagnosis with that of human experts. Data Sources: The MEDLINE, arXiv, and PubMed Central databases were searched to identify eligible studies published between January 1, 2002, and December 31, 2018. Study Selection: Studies that reported on the accuracy of automated systems for melanoma were selected. Search terms included melanoma, diagnosis, detection, computer aided, and artificial intelligence. Data Extraction and Synthesis: Evaluation of the risk of bias was performed using the QUADAS-2 tool, and quality assessment was based on predefined criteria. Data were analyzed from February 1 to March 10, 2019. Main Outcomes and Measures: Summary estimates of sensitivity and specificity and summary receiver operating characteristic curves were the primary outcomes. Results: The literature search yielded 1694 potentially eligible studies, of which 132 were included and 70 offered sufficient information for a quantitative analysis. Most studies came from the field of computer science. Prospective clinical studies were rare. Combining the results for automated systems gave a melanoma sensitivity of 0.74 (95% CI, 0.66-0.80) and a specificity of 0.84 (95% CI, 0.79-0.88). Sensitivity was lower in studies that used independent test sets than in those that did not (0.51; 95% CI, 0.34-0.69 vs 0.82; 95% CI, 0.77-0.86; P <.001); however, the specificity was similar (0.83; 95% CI, 0.71-0.91 vs 0.85; 95% CI, 0.80-0.88; P =.67). In comparison with dermatologists' diagnosis, computer-aided diagnosis showed similar sensitivities and a 10 percentage points lower specificity, but the difference was not statistically significant. Studies were heterogeneous and substantial risk of bias was found in all but 4 of the 70 studies included in the quantitative analysis. Conclusions and Relevance: Although the accuracy of computer-aided diagnosis for melanoma detection is comparable to that of experts, the real-world applicability of these systems is unknown and potentially limited owing to overfitting and the risk of bias of the studies at hand.},
   author = {Vincent Dick and Christoph Sinz and Martina Mittlböck and Harald Kittler and Philipp Tschandl},
   doi = {10.1001/jamadermatol.2019.1375},
   issn = {21686068},
   issue = {11},
   journal = {JAMA Dermatology},
   pages = {1291-1299},
   pmid = {31215969},
   title = {Accuracy of Computer-Aided Diagnosis of Melanoma: A Meta-analysis},
   volume = {155},
   year = {2019},
}
@article{Kaya2016,
   abstract = {Background: Automated skin lesion border examination and analysis techniques have become an important field of research for distinguishing malignant pigmented lesions from benign lesions. An abrupt pigment pattern cutoff at the periphery of a skin lesion is one of the most important dermoscopic features for detection of neoplastic behavior. In current clinical setting, the lesion is divided into a virtual pie with eight sections. Each section is examined by a dermatologist for abrupt cutoff and scored accordingly, which can be tedious and subjective. Methods: This study introduces a novel approach to objectively quantify abruptness of pigment patterns along the lesion periphery. In the proposed approach, first, the skin lesion border is detected by the density based lesion border detection method. Second, the detected border is gradually scaled through vector operations. Then, along gradually scaled borders, pigment pattern homogeneities are calculated at different scales. Through this process, statistical texture features are extracted. Moreover, different color spaces are examined for the efficacy of texture analysis. Results: The proposed method has been tested and validated on 100 (31 melanoma, 69 benign) dermoscopy images. Analyzed results indicate that proposed method is efficient on malignancy detection. More specifically, we obtained specificity of 0.96 and sensitivity of 0.86 for malignancy detection in a certain color space. The F-measure, harmonic mean of recall and precision, of the framework is reported as 0.87. Conclusions: The use of texture homogeneity along the periphery of the lesion border is an effective method to detect malignancy of the skin lesion in dermoscopy images. Among different color spaces tested, RGB color space's blue color channel is the most informative color channel to detect malignancy for skin lesions. That is followed by YCbCr color spaces Cr channel, and Cr is closely followed by the green color channel of RGB color space.},
   author = {Sertan Kaya and Mustafa Bayraktar and Sinan Kockara and Mutlu Mete and Tansel Halic and Halle E. Field and Henry K. Wong},
   doi = {10.1186/s12859-016-1221-4},
   issn = {14712105},
   journal = {BMC Bioinformatics},
   pmid = {27766942},
   title = {Abrupt skin lesion border cutoff measurement for malignancy detection in dermoscopy images},
   volume = {17},
   year = {2016},
}
@article{Lee2003,
   abstract = {One of the important clinical features that differentiates benign melanocytic nevi from malignant melanomas is the irregularity of the lesion border. There are two types of border irregularities: texture irregularities, the small variations along the border, and structure irregularities, the global indentations and protrusions. Texture irregularities are subject to noise, whereas structure irregularities may suggest excessive cell growth or regression of a melanoma. We have designed a new algorithm for measuring the structure irregularities in the border. Our algorithm first locates all the local and global indentations and protrusions and organizes them in a hierarchical structure. Then an area-based index, called the irregularity index, is computed for each indentation and protrusion along the border. From the individual irregularity indices, two important new measures, the most significant irregularity index and the overall irregularity index are derived. These two new indices provide a measure of the degree of irregularity along the lesion border. A double-blinded test was performed to examine the effectiveness of these two new indices. Fourteen experienced dermatologists were asked to evaluate the borders of 40 pigmented lesions. The clinical evaluation result was then compared with the two new indices and other published shape measurements. The user study showed that both of the new indices vastly outperformed the other shape descriptors. Moreover, our algorithm captured the knowledge of expert dermatologists in analysing malignancy of a lesion based on its shape alone, indicating that the new measures may be useful for diagnosing melanomas. © 2002 Elsevier Science B.V. All rights reserved.},
   author = {Tim K. Lee and David I. McLean and M. Stella Atkins},
   doi = {10.1016/S1361-8415(02)00090-7},
   issn = {13618415},
   issue = {1},
   journal = {Medical Image Analysis},
   keywords = {Border irregularity,Melanoma,Scale space filtering,Shape descriptor},
   pages = {47-64},
   pmid = {12467721},
   title = {Irregularity index: A new border irregularity measure for cutaneous melanocytic lesions},
   volume = {7},
   year = {2003},
}
@article{Sayed2009,
   abstract = {Demand forecasting is considered a key factor for balancing risk of over-stocking and out-of-stock. It is the main input to supply chain processes affecting their performance. Even with much effort and funds spent to improve supply chain processes, they still lack reliability and efficiency if the demand forecast accuracy is poor. This paper presents a proposal of an integrated model of statistical methods and improved genetic algorithm to generate better demand forecast accuracy. An improved genetic algorithm is used to choose the best weights among the statistical methods and to optimize the forecasted activities combinations that maximize profit. A case study is presented using different product types. And, a comparison is conducted between results obtained from the proposed model and from traditional statistical methods, which demonstrates improved forecast accuracy using the proposed model for all time series types. © 2009 Elsevier Ltd. All rights reserved.},
   author = {Hanaa E. Sayed and Hossam A. Gabbar and Shigeji Miyazaki},
   doi = {10.1016/j.eswa.2009.03.014},
   issn = {09574174},
   issue = {9},
   journal = {Expert Systems with Applications},
   keywords = {Decision support,Forecasting techniques,Genetic algorithm,Regression methods,Statistical methods},
   pages = {11662-11670},
   title = {A hybrid statistical genetic-based demand forecasting expert system},
   volume = {36},
   year = {2009},
}
@article{Newhart2020,
   abstract = {In this work, a statistical stability metric and novel hybrid statistical-machine learning ammonia forecasting model are developed to improve the accuracy and precision of municipal wastewater treatment. Aeration for biological nutrient removal is typically the largest energy expense for municipal wastewater treatment plants (WWTP). Ammonia-based aeration control (ABAC) is one approach designed to minimize excessive aeration by adjusting air blower output from online ammonia measurements rather than from a dissolved oxygen (DO) sensor, which is the conventional aeration control approach. We propose a quantitative stability metric, Total Sample Variance, to compare system-wide variability of competing aeration control strategies. Using this metric, the performance of traditional DO and ABAC control strategies with varying setpoints and control parameters were compared in a medium-sized WWTP, and the most stable strategy was identified and implemented at the facility. To further improve ABAC performance, ammonia forecasting models were constructed using both statistical and machine learning to improve the accuracy of the aeration control system. Diurnal, diurnal-linear, artificial neural network (ANN), and hybrid diurnal-linear-ANN forecasting models were trained on real-time plant-wide process data. The diurnal-linear and diurnal-linear-ANN forecasts were found to most accurately forecast ammonia; improving upon the existing ammonia measurement by up to 32% and 46%, respectively, whereas the ANN model forecast was only able to improve by up to 8%. This work demonstrates the ease and flexibility of integrating statistics and machine learning methods for developing new treatment models in conventional WWTP for features in full-scale conventional activated sludge systems.},
   author = {Kathryn B. Newhart and Christopher A. Marks and Tanja Rauch-Williams and Tzahi Y. Cath and Amanda S. Hering},
   doi = {10.1016/j.jwpe.2020.101389},
   issn = {22147144},
   journal = {Journal of Water Process Engineering},
   keywords = {Ammonia-based aeration control,Artificial neural network,Cascade control,Stability assessment},
   title = {Hybrid statistical-machine learning ammonia forecasting in continuous activated sludge treatment for improved process control},
   volume = {37},
   year = {2020},
}
@article{Spanos2019,
   abstract = {In this paper, a security solution is proposed for IoT smart homes based on constructing behavioral device templates. These templates are being calculated by combining statistical and machine learning techniques according to their network behavior, captured within a smart home. The generated statistical metrics are being processed in order to produce the appropriate features, which are then used for constructing clusters of devices. The main idea relies on the fact that during an abnormal event, the device will be moved away from the center of the cluster, generating an alert that can be further used for proposing mitigation actions. The methodology followed in the proposed approach is given in detail, while validation is performed on a real smart home dataset. This work is part of a transparent Cyber security framework developed under EU H2020 Project GHOST.},
   author = {Georgios Spanos and Konstantinos M. Giannoutakis and Konstantinos Votis and Dimitrios Tzovaras},
   doi = {10.1109/CAMAD.2019.8858490},
   isbn = {9781728110165},
   issn = {23784873},
   journal = {IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks, CAMAD},
   keywords = {Anomaly Detection,Information Security,Internet of Things,Machine Learning,Smart Home,Statistics},
   title = {Combining statistical and machine learning techniques in IoT anomaly detection for smart homes},
   volume = {2019-Septe},
   year = {2019},
}
@article{Lattoofi2019,
   abstract = {Skin cancer is the most common cancers in the last years, especially in the human body; the Melanoma is the most destructive type of skin lesions. Detect cancer is important at the initial stage, but only an expert dermatologist can detect which one is non-melanoma and melanoma. Computer-aided diagnosis (CADs) application to skin cancer is relatively understudied. The purpose of this paper is the automated detection of Melanoma via digital image processing. In this project, the algorithm consists of automatic ABCD (asymmetry, border irregularity, colour, and dermoscopic structure) rule of dermoscopy lesions images is implemented. Before that, we use hair removal as a pre-processing step which is based on morphological filter and thresholding. Finally, the lesions are classified as either melanoma or benign. The used dataset is containing 200 dermoscopic images, where 120 are benign lesions and 80 malignant melanomas. The proposed method shows an accuracy of 93.2%, 92.59% specificity, and 90.15% sensitivity.},
   author = {Nabeel F. Lattoofi and Israa F. Al-Sharuee and Mohammed Y. Kamil and Ayoob H. Obaid and Aya A. Mahidi and Ammar A. Omar and Abdullah K. Saleh},
   doi = {10.1109/CAS47993.2019.9075465},
   isbn = {9781728140483},
   journal = {1st International Scientific Conference of Computer and Applied Sciences, CAS 2019},
   keywords = {ABCD rule,Feature extraction,Melanoma,Skin Cancer,computer-aided diagnosis},
   pages = {154-157},
   title = {Melanoma Skin Cancer Detection Based on ABCD Rule},
   year = {2019},
}
@article{Stanienda-Soko2017,
   abstract = {Introduction: Location of malignant melanoma lesions depends on environmental, genetic, sociological and demographical factors. Available sources do not provide enough information on such dependencies in various populations. There is no data concerning the role of socio-demographic factors for the population of the Central and Eastern Europe. Aim: The aim of this work was to evaluate the anatomical location of the primary malignant melanoma lesion in correlation to patients' gender and age. Material and methods: A retrospective analysis of medical documentation of 363 patients has been performed. The patients had been diagnosed with malignant melanoma and were undergoing treatment in the years 2010-2014 in two Polish oncologic hospitals. The subject group consisted of 199 (55%) females and 164 (45%) males. The age varied between 19 - 90 years, with the median of 62 years. Results: In women, the melanoma lesions seem to appear more often in their lower extremities, while in case of men such lesions seem to be more often on their torsos. In both cases, the difference was statistically significant (p < 0.01 When the specific locations are considered in women the lesions were more often located on their shins (p < 0.01), whereas for men the lesions were located on their backs (p < 0.01). It has been observed that there is dependency between lesion localization and age of patients. The lesions located on heads and necks were most common in older patients, and the lesions located in lower extremities were most common in younger ones. Conclusion: Differences in location of malignant melanoma lesions may be due to either genetic or environmental reasons. It is often emphasized in literature that correlation between the socio-demographic factors and the process of oncogenesis requires intensive research. In our work, we have tried to fill this gap for the population of Central and Eastern Europe to determine the exact epidemiology of this kind of cancer. This knowledge may be then used for developing cancer prevention methods specific to gender and age.},
   author = {Karolina Stanienda-Sokół and Natalia Salwowska and Martyna Sławińska and Katarzyna Wicherska-Pawlowska and Anna Lorenc and Dominika Wcisło-Dziadecka and Jerzy Wydmański and Wojciech Majewski},
   doi = {10.22034/APJCP.2017.18.11.3081},
   issn = {2476762X},
   issue = {11},
   journal = {Asian Pacific Journal of Cancer Prevention},
   keywords = {Age,Gender,Location,Malignant melanoma},
   pages = {3081-3086},
   pmid = {29172282},
   title = {Primary locations of malignant melanoma lesions depending on patients' gender and age},
   volume = {18},
   year = {2017},
}
@article{She2007,
   abstract = {Background/Purpose: It is known that the standard features for lesion classification are ABCD features, that is, asymmetry, border irregularity, colour variegation and diameter of lesion. However, the observation that skin patterning tends to be disrupted by malignant but not by benign skin lesions suggests that measurements of skin pattern disruption on simply captured white light optical skin images could be a useful contribution to a diagnostic feature set. Previous work using both skin line direction and intensity for lesion classification was encouraging. But these features have not been combined with the ABCD features. This paper explores the possibility of combing features from skin pattern and ABCD analysis to enhance classification performance. Methods: The skin line direction and intensity were extracted from a local tensor matrix of skin pattern. Meanwhile, ABCD analysis was conducted to generate six features. They were asymmetry, border irregularity, colour (red, green and blue) variegations and diameter of lesion. The eight features of each case were combined using a principal component analysis (PCA) to produce two dominant features for lesion classification. Results: A larger set of images containing malignant melanoma (MM) and benign naevi were processed as above and the scatter plot in a two-dimensional dominant feature space showed excellent separation of benign and malignant lesions. An ROC (receiver operating characteristic) plot enclosed an area of 0.94. Conclusions: The classification results showed that the individual features have a limited discrimination capability and the combined features were promising to distinguish MM from benign lesion. © Blackwell Munksgaard 2007.},
   author = {Zhishun She and Y. Liu and A. Damatoa},
   doi = {10.1111/j.1600-0846.2007.00181.x},
   issn = {0909752X},
   issue = {1},
   journal = {Skin Research and Technology},
   keywords = {ABCD analysis,Feature combination,Lesion classification,Melanoma,Skin pattern},
   pages = {25-33},
   pmid = {17250529},
   title = {Combination of features from skin pattern and ABCD analysis for lesion classification},
   volume = {13},
   year = {2007},
}
@article{Tenenhaus2010,
   abstract = {Background and objective: Several systems for the diagnosis of melanoma from images of naevi obtained under controlled conditions have demonstrated comparable efficiency with dermatologists. However, their robustness to analyze daily routine images was sometimes questionable. The purpose of this work is to investigate to what extent the automatic melanoma diagnosis may be achieved from the analysis of uncontrolled images of pigmented skin lesions. Materials and methods: Images were acquired during regular practice by two dermatologists using Reflex® 24 × 36 cameras combined with Heine Delta 10 dermascopes. The images were then digitalized using a scanner. In addition, five senior dermatologists were asked to give the diagnosis and therapeutic decision (exeresis) for 227 images of naevi, together with an opinion about the existence of malignancy-predictive features. Meanwhile, a learning by sample classifier for the diagnosis of melanoma was constructed, which combines image-processing with machine-learning techniques. After an automatic segmentation, geometric and colorimetric parameters were extracted from images and selected according to their efficiency in predicting malignancy features. A diagnosis was subsequently provided based on selected parameters. An extensive comparison of dermatologists' and computer results was subsequently performed. Results and conclusion: The KL-PLS-based classifier shows comparable performances with respect to dermatologists (sensitivity: 95% and specificity: 60%). The algorithm provides an original insight into the clinical knowledge of pigmented skin lesions. © 2010 John Wiley & Sons A/S.},
   author = {Arthur Tenenhaus and Alex Nkengne and Jean François Horn and Camille Serruys and Alain Giron and Bernard Fertil},
   doi = {10.1111/j.1600-0846.2009.00385.x},
   issn = {0909752X},
   issue = {1},
   journal = {Skin Research and Technology},
   keywords = {Dermatologists' expertise,Dermoscopy,KL-PLS,Melanoma diagnosis},
   pages = {85-97},
   pmid = {20384887},
   title = {Detection of melanoma from dermoscopic images of naevi acquired under uncontrolled conditions},
   volume = {16},
   year = {2010},
}
@article{Jaworek-Korjakowska2015,
   abstract = {Malignant melanoma, which is the most dangerous type of skin cancer, is commonly diagnosed in all people, regardless of age, gender, or race. In the last several years an increasing melanoma incidence and mortality rate has been observed worldwide. In this research we present a new approach to the detection and classification of border irregularity, one of the major parameter in a widely used diagnostic algorithm ABCD rule of dermoscopy. Accurate assessment of irregular borders is clinically important due to a significantly different occurrence in benign and malignant skin lesions. In this paper we describe a complex algorithm containing following steps: image enhancement, lesion segmentation, border irregularity detection as well as classification. The algorithm has been tested on 300 dermoscopic images and achieved a detection of 79% and classification accuracy of 90%. Compared to state-of-the-art, we obtain improved classification accuracy.},
   author = {J. Jaworek-Korjakowska and R. Tadeusiewicz},
   doi = {10.1109/EMBC.2015.7318940},
   issn = {1557170X},
   journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference},
   pages = {2665-2668},
   pmid = {26736840},
   title = {Determination of border irregularity in dermoscopic color images of pigmented skin lesions},
   volume = {2015},
   year = {2015},
}
@article{Ali2020b,
   author = {Abder-Rahman Ali and Jingpeng Li and Guang Yang and Sally Jane O’Shea},
   doi = {10.7717/peerj.cs.268/table-3},
   issn = {2376-5992},
   journal = {PeerJ Computer Science},
   pages = {e268},
   title = {A machine learning approach to automatic detection of irregularity in skin lesion border using dermoscopic images},
   volume = {6},
   year = {2020},
}
@article{Zaqout2016,
   abstract = {Great effort has been put into the development of diagnosis methods for the most dangerous type of skin diseases—melanoma. This paper aims to develop a prototype capable of segment and classify skin lesions in dermoscopy images based on ABCD rule. The …},
   author = {Ihab S. Zaqout},
   doi = {10.14257/ijsip.2016.9.9.18},
   issn = {20054254},
   issue = {9},
   journal = {International Journal of Signal Processing, Image Processing and Pattern Recognition},
   pages = {189-204},
   title = {Diagnosis of Skin Lesions Based on Dermoscopic Images Using Image Processing Techniques},
   volume = {9},
   year = {2016},
}
@article{Myridis2014a,
   author = {Nikolaos E. Myridis},
   doi = {10.1080/00107514.2014.907348},
   issn = {0010-7514},
   issue = {3},
   journal = {Contemporary Physics},
   pages = {247-248},
   title = {Ultra-realistic Imaging: Advanced Techniques in Analogue and Digital Colour Holography, by Hans Bjelkhagen and David Brotherton-Ratcliffe},
   volume = {55},
   year = {2014},
}
@misc{Yuan2017b,
   abstract = {This paper summarizes our method and validation results for the ISBI Challenge 2017-Skin Lesion Analysis Towards Melanoma Detection-Part 1: Lesion Segmentation.},
   author = {Yading Yuan},
   title = {Automatic skin lesion segmentation with fully convolutional-deconvolutional networks},
   year = {2017},
}
@inproceedings{Adeyinka2018,
   abstract = {This paper presents a detailed and robust survey of the state-of-the-art algorithms and techniques for performing skin lesion segmentation. The approach used is the comparative analysis of the existing methods for skin lesion analysis, critical review of the performance evaluation of some recently developed algorithms for skin lesion images segmentation, and the study of current evaluating metrics used for performance analysis. The study highlights merits and demerits of the algorithms examined, observing the strength and weakness of each algorithm. An inference can thus be made from the analysis about the best performing algorithms. It is observed that the advancement of technology and availability of a large and voluminous data set for training the machine learning algorithms encourage the application of machine learning techniques such as deep learning for performing skin lesion images segmentation. This work shows that most deep learning techniques out-perform some existing state-of-the arts algorithm for skin lesion images segmentation.},
   author = {Adegun Adekanmi Adeyinka and Serestina Viriri},
   doi = {10.1007/978-3-030-05918-7_29},
   isbn = {9783030059170},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Deep learning,Evaluation metrics,Segmentation,Skin lesion},
   month = {12},
   pages = {321-330},
   publisher = {Springer Verlag},
   title = {Skin lesion images segmentation: A survey of the state-of-the-art},
   volume = {11308 LNAI},
   url = {https://doi.org/10.1007/978-3-030-05918-7_29},
   year = {2018},
}
@article{Ali2020,
   abstract = {The ABCD rule is a simple framework that physicians, novice dermatologists and non-physicians can use to learn about the features of melanoma in its early curable stage, enhancing thereby the early detection of melanoma. Since the interpretation of the ABCD rule traits is subjective, different solutions have been proposed in literature to tackle such subjectivity and provide objective evaluations to the different traits. This paper reviews the main contributions in literature towards automating asymmetry, border irregularity, color variegation and diameter, where the different methods involved have been highlighted. This survey could serve as an essential reference for researchers interested in automating the ABCD rule.},
   author = {Abder Rahman H. Ali and Jingpeng Li and Guang Yang},
   doi = {10.1109/ACCESS.2020.2991034},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Image processing,machine learning,melanoma detection},
   pages = {83333-83346},
   title = {Automating the ABCD Rule for Melanoma Detection: A Survey},
   volume = {8},
   year = {2020},
}
@article{Ali2020a,
   abstract = {Asymmetry, color variegation and diameter are considered strong indicators of malignant melanoma. The subjectivity inherent in the first two features and the fact that 10% of melanomas tend to be missed in the early diagnosis due to having a diameter less than 6mm, deem it necessary to develop an objective computer vision system to evaluate these criteria and aid in the early detection of melanoma which could eventually lead to a higher 5-year survival rate. This paper proposes an approach for evaluating the three criteria objectively, whereby we develop a measure to find asymmetry with the aid of a decision tree which we train on the extracted asymmetry measures and then use to predict the asymmetry of new skin lesion images. A range of colors that demonstrate the suspicious colors for the color variegation feature have been derived, and Feret’s diameter has been utilized to find the diameter of the skin lesion. The decision tree is 80% accurate in determining the asymmetry of skin lesions, and the number of suspicious colors and diameter values are objectively identified.},
   author = {Abder Rahman Ali and Jingpeng Li and Sally Jane O’Shea},
   doi = {10.1371/journal.pone.0234352},
   issn = {19326203},
   issue = {6},
   journal = {PLoS ONE},
   pmid = {32544197},
   title = {Towards the automatic detection of skin lesion shape asymmetry, color variegation and diameter in dermoscopic images},
   volume = {15},
   year = {2020},
}
@article{Jaisakthi2018,
   abstract = {Skin cancer is the most common type of cancer in the world and the incidents of skin cancer have been rising over the past decade. Even with a dermoscopic imaging system, which magnifies the lesion region, detecting and classifying skin lesions by visual examination is laborious due to the complex structures of the lesions. This necessitates the need for an automated skin lesion diagnosis system to enhance the diagnostic capability of dermatologists. In this study, the authors propose an automatic skin lesion segmentation method which can be used as a preliminary step for lesion classification. The proposed method comprises two major steps, namely preprocessing and segmentation. In the preprocessing step, noise such as illumination, hair and rulers are removed using filtering techniques and in the segmentation phase, skin lesions are segmented using the GrabCut segmentation algorithm. The k-means clustering algorithm is then used along with the colour features learnt from the training images to improve the boundaries of the segments. To evaluate the authors' proposed method, they have used ISIC 2017 challenge dataset and PH2 dataset. They have obtained Dice coefficient values of 0.8236 and 0.9139 for ISIC 2017 test dataset and PH2 dataset, respectively.},
   author = {Seetharani Murugaiyan Jaisakthi and Palaniappan Mirunalini and Chandrabose Aravindan},
   doi = {10.1049/iet-cvi.2018.5289},
   issn = {17519640},
   issue = {8},
   journal = {IET Computer Vision},
   month = {12},
   pages = {1088-1095},
   publisher = {Institution of Engineering and Technology},
   title = {Automated skin lesion segmentation of dermoscopic images using GrabCut and kmeans algorithms},
   volume = {12},
   year = {2018},
}
@article{Zeebaree2017,
   abstract = {In the past few decades, a detailed and extensive research has been carried out on K-Means combine with genetic algorithm for clustering of using this combine technique; to focuses on studying the efficiency and effectiveness of most article. The basic aim of this article is to gather a complete and detailed summary and a clear well explained idea of various methods and algorithms. The calculation of the number of clusters in a data user was done automatically. Representation of operator in GA was developed and group based crossover was done to fix the number of clusters. The problem on the large scale was segregated in to various mini problems through the researchers. To solving small-scale combinatorial optimization. Improving the assembling quality with less time complexity and minimization of the total distance that is travelled by the salesman are also discussed. Overall, almost K-means algorithm with GA have high performance quality of clustering with minimum time and evolution process converge fast compared with anthers technique do not combined GA with k-means cluster.},
   author = {Diyar Qader Zeebaree and Habibollah Haron and Adnan Mohsin Abdulazeez and Subhi R.M. Zeebaree},
   issn = {09739769},
   issue = {24},
   journal = {International Journal of Applied Engineering Research},
   keywords = {Clustering,Combine of K-Means and Genetic algorithm,Data mining,Genetic algorithm,K-Means},
   pages = {14238-14245},
   title = {Combination of k-means clustering with genetic algorithm: A review},
   volume = {12},
   year = {2017},
}
@article{DiGesu2005,
   abstract = {Background: Clustering is a key step in the analysis of gene expression data, and in fact, many classical clustering algorithms are used, or more innovative ones have been designed and validated for the task. Despite the widespread use of artificial intelligence techniques in bioinformatics and, more generally, data analysis, there are very few clustering algorithms based on the genetic paradigm, yet that paradigm has great potential in finding good heuristic solutions to a difficult optimization problem such as clustering. Results: GenClust is a new genetic algorithm for clustering gene expression data. It has two key features: (a) a novel coding of the search space that is simple, compact and easy to update; (b) it can be used naturally in conjunction with data driven internal validation methods. We have experimented with the FOM methodology, specifically conceived for validating clusters of gene expression data. The validity of GenClust has been assessed experimentally on real data sets, both with the use of validation measures and in comparison with other algorithms, i.e., Average Link, Cast, Click and K-means. Conclusions: Experiments show that none of the algorithms we have used is markedly superior to the others across data sets and validation measures; i.e., in many cases the observed differences between the worst and best performing algorithm may be statistically insignificant and they could be considered equivalent. However, there are cases in which an algorithm may be better than others and therefore worthwhile. In particular, experiments for GenClust show that, although simple in its data representation, it converges very rapidly to a local optimum and that its ability to identify meaningful clusters is comparable, and sometimes superior, to that of more sophisticated algorithms. In addition, it is well suited for use in conjunction with data driven internal validation measures and, in particular, the FOM methodology. © 2005 Di Gesu et al., licensee BioMed Central Ltd.},
   author = {Vito Di Gesú and Raffaele Giancarlo and Giosué Lo Bosco and Alessandra Raimondi and Davide Scaturro},
   doi = {10.1186/1471-2105-6-289},
   issn = {14712105},
   journal = {BMC Bioinformatics},
   title = {GenClust: A genetic algorithm for clustering gene expression data},
   volume = {6},
   year = {2005},
}
@article{Aljawawdeh2017,
   abstract = {See, stats, and : https : / / www . researchgate . net / publication / 322156328 Enhanced -mean Algorithms Segmentation Article DOI : 10 . 14569 / IJACSA. 2017 . 081263 CITATIONS 0 READS 29 2 : Some : Enhanced - mean Images face Asmaa University 4 SEE Esraa University 1 SEE All . The . Abstract—Nowadays , Melanoma has become one of the most significant public health concerns . Malignant Melanoma (MM) is considered the most rapidly spreading type of skin cancer . In this paper , we have built models for detection , segmentation , and classification of Melanoma in skin images using evolutionary algorithms . The first step was to enhance the K - mean algorithm by using two kinds of Evolutionary Algorithms : a Genetic Algo - rithm and the Particle Swarm Algorithm . Then the Enhanced Algorithms and the default k - mean separately were used to do detection and segmentation of skin cancer images . Then a feature extraction step was applied on the segmented images . Finally , the classification step was done by using two predictive models . The first model was built using a Neural Network back - propagation and the other one using some threshold values for some selected features . The results showed a high accuracy using Neural Back - propagation for the Enhanced K - mean by using a Genetic Algorithm , which achieved 87 . 5% .},
   author = {Asmaa Aljawawdeh and Esraa Imraiziq and Ayat Aljawawdeh},
   doi = {10.14569/ijacsa.2017.081263},
   issn = {2158107X},
   issue = {12},
   journal = {International Journal of Advanced Computer Science and Applications},
   title = {Enhanced K-mean Using Evolutionary Algorithms for Melanoma Detection and Segmentation in Skin Images},
   volume = {8},
   year = {2017},
}
@article{Barata2013,
   abstract = {Melanoma detection using medical oriented approaches has been a trend in skin cancer research. This paper uses a Bag-of-Feature model for the detection of melanomas in dermoscopy images and aims at identifying the role of different local texture and color descriptors. This is a medical oriented approach and the reported results are promising (Sensitivity = 93%, Specificity=85%), showing the ability of this method to describe medical dermoscopic features. Moreover, the results show that color descriptors outperform texture ones. © 2013 Springer-Verlag.},
   author = {Catarina Barata and Jorge S. Marques and Teresa Mendonça},
   doi = {10.1007/978-3-642-39094-4_62},
   isbn = {9783642390937},
   issn = {03029743},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Bag-of-Features,Dermoscopy,Feature Extraction,Medical Image Analysis,Melanoma},
   pages = {547-555},
   title = {Bag-of-features classification model for the diagnose of melanoma in dermoscopy images using color and texture descriptors},
   volume = {7950 LNCS},
   year = {2013},
}
@inproceedings{I.2015,
   abstract = {The interest in image dermoscopy has been significantly increased recently and skin lesion images are nowadays routinely acquired for a number of skin disorders. An important finding in the assessment of a skin lesion severity is the existence of dark dots and globules, which are hard to locate and count using existing image software tools. In this work we present a novel methodology for detecting/segmenting and count dark dots and globules from dermoscopy images. Segmentation is performed using a multi-resolution approach based on inverse non-linear diffusion. Subsequently, a number of features are extracted from the segmented dots/globules and their diagnostic value in automatic classification of dermoscopy images of skin lesions into melanoma and non-malignant nevus is evaluated. The proposed algorithm is applied to a number of images with skin lesions with known histo-pathology. Results show that the proposed algorithm is very effective in automatically segmenting dark dots and globules. Furthermore, it was found that the features extracted from the segmented dots/globules can enhance the performance of classification algorithms that discriminate between malignant and benign skin lesions, when they are combined with other region-based descriptors.},
   author = {Maglogiannis I. and Delibasis K.K.},
   doi = {10.1016/j.cmpb.2014.12.001 LK - http://elinks.library.upenn.edu/sfx_local?sid=EMBASE&issn=18727565&id=doi:10.1016%2Fj.cmpb.2014.12.001&atitle=Enhancing+classification+accuracy+utilizing+globules+and+dots+features+in+digital+dermoscopy&stitle=Comput.+Methods+Programs+Biomed.&title=Computer+Methods+and+Programs+in+Biomedicine&volume=118&issue=2&spage=124&epage=133&aulast=Maglogiannis&aufirst=Ilias&auinit=I.&aufull=Maglogiannis+I.&coden=CMPBE&isbn=&pages=124-133&date=2015&auinit1=I&auinitm=},
   issn = {1872-7565},
   issue = {2},
   journal = {Computer Methods and Programs in Biomedicine},
   keywords = {article,classification algorithm,diagnostic accuracy,diagnostic value,epiluminescence microscopy,histopathology,image enhancement,image processing,imaging software,mathematical parameters,melanoma,nevus,perceptron,random forest,skin defect,support vector machine},
   pages = {124-133},
   title = {Enhancing classification accuracy utilizing globules and dots features in digital dermoscopy},
   volume = {118},
   url = {http://www.embase.com/search/results?subaction=viewrecord&from=export&id=L601042643%0Ahttp://dx.doi.org/10.1016/j.cmpb.2014.12.001},
   year = {2015},
}
@article{Barata2012,
   abstract = {A pigment network is one of the most important dermoscopic structures. This paper describes an automatic system that performs its detection in dermoscopy images. The proposed system involves a set of sequential steps. First, a preprocessing algorithm is applied to the dermoscopy image. Then, a bank of directional filters and a connected component analysis are used in order to detect the lines of the pigment network. Finally, features are extracted from the detected network and used to train an AdaBoost algorithm to classify each lesion regarding the presence of the pigment network. The algorithm was tested on a dataset of 200 medically annotated images from the database of Hospital Pedro Hispano (Matosinhos), achieving a sensitivity = 91.1 and a specificity = 82.1. © 1964-2012 IEEE.},
   author = {Catarina Barata and Jorge S. Marques and Jorge Rozeira},
   doi = {10.1109/TBME.2012.2209423},
   issn = {00189294},
   issue = {10},
   journal = {IEEE Transactions on Biomedical Engineering},
   keywords = {Dermoscopic structures,dermoscopy,directional filters,pattern recognition,pigment network detection},
   pages = {2744-2754},
   title = {A system for the detection of pigment network in dermoscopy images using directional filters},
   volume = {59},
   year = {2012},
}
@article{Kropidlowski2015,
   abstract = {There is no suitable golden standard for the detection of atypical pigment network and irregular streaks applied to skin lesion images. This information however is important in assessment of melanoma in skin dermatoscopic images. Thus there is a need for development of image analysis techniques that satisfy at least subjective criteria defined by dermatologists. In this paper we present the application of histogram based features for detection of atypical pigment network and shape based features supplemented by artificial neural network for detection of irregular streaks. Preliminary test results are promising, for analyzed melanoma images we get 97,7% correctly detected pigmentation networks and 94,8% correctly detected irregular streaks. This paper constitutes the part of our efforts to implement the ELM 7-point checklist in order to support melanoma diagnosis and to automate this process.},
   author = {K. Kropidlowski and M. Kociolek and M. Strzelecki and D. Czubinski},
   doi = {10.1109/SPA.2015.7365135},
   isbn = {9788362065233},
   issn = {23260319},
   journal = {Signal Processing - Algorithms, Architectures, Arrangements, and Applications Conference Proceedings, SPA},
   keywords = {7-point checklist,image processing,irregular streaks,malignant melanoma,neural network,typical and atypical pigment network},
   pages = {66-70},
   title = {Nevus atypical pigment network distinction and irregular streaks detection in skin lesions images},
   volume = {2015-Decem},
   year = {2015},
}
@article{Pathan2018,
   abstract = {The pigment network is considered as one of the most histopathologically relevant indicator of melanoma. The objective of this empirical study is to design a novel automatic system for detection of pigment network and provide a differentiation between typical and atypical network patterns. The algorithm design consists a set of sequential stages. Pigment network masks are detected using a bank of 2D Gabor filters, and a set of pigment network features are extracted to determine the role of pigment network in the diagnosis of the lesion. In the second stage, a machine learning process is carried out using the rules generated from the pigment network masks to identify the typical and atypical pigment network patterns. The proposed methodology was tested on the PH2 dataset of 200 images, obtaining an average sensitivity of 96%, specificity of 100% and accuracy of 96.7% for lesion diagnosis, and an average sensitivity, specificity and accuracy of 84.6%, 88.7% and 86.7% respectively, for pigment network classification. The proposed system stands out amongst the few state of art literatures reported in the context of dermoscopic image analysis in terms of performance and methodologies adopted, thus proving the reliability of the proposed study.},
   author = {Sameena Pathan and K. Gopalakrishna Prabhu and P. C. Siddalingaswamy},
   doi = {10.1016/j.bspc.2018.03.017},
   issn = {17468108},
   journal = {Biomedical Signal Processing and Control},
   keywords = {Atypical,Dermoscopy,Gabor,Pigment network,Polynomial curve fitting,Typical},
   pages = {25-37},
   title = {A methodological approach to classify typical and atypical pigment network patterns for melanoma diagnosis},
   volume = {44},
   year = {2018},
}
@article{Jaworek-Korjakowska2012,
   abstract = {This paper proposes and describes an automatic software system to detect and diagnose malignant melanomas. Skin melanoma is the most serious type of skin cancer and one of the most malignant tumors in humans. In the last several years increasing melanoma incidence has been observed worldwide. The aim of the present research project was to design, implement and test an application for early diagnosis of malignant melanomas. The system is based on the commonly used dermoscopic criteria scheme called the ABCD rule of dermoscopy (A stands for Asymmetry, B for border irregularity, C for color and D for diameter) and has been tested on a database of 50 lesions (20 benign lesions and 30 malignant lesions). The results of the preliminary experiments show that the image analysis with computer assistance has the potential of more accurately identifying the dermoscopic lesions. © 2012 Springer-Verlag.},
   author = {Joanna Jaworek-Korjakowska},
   doi = {10.1007/978-3-642-31196-3_7},
   isbn = {9783642311956},
   issn = {03029743},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {feature extraction,malignant tumor,medical image analysis,melanoma},
   pages = {67-76},
   title = {Automatic detection of melanomas: An application based on the ABCD criteria},
   volume = {7339 LNBI},
   year = {2012},
}
@article{Arasi2016,
   abstract = {Skin cancer is one of the most growing types and dangerous cancer in the world; the important of these cancers are malignant melanoma. The early diagnosis of malignant melanoma is a critical issue for dermatologists. In this paper, we present an overview of recent the state of the art in Computer-aided detection/diagnosis (CAD) systems in identifying and diagnosing malignant melanoma of dermoscopy images and describe its steps starting with image acquisition, preprocessing; and finishing with malignant melanoma classification of dermoscopic images. The comparative study shows that the most common methods for features extraction are the Discreet Wavelet Transform (DWT) and the method which combines both texture and color features resulting in output of very high accuracy. The methods for the classification:í µí°¾-Nearest Neighbor, Artificial Neural Networks, and Support Vector Machines are very well in the range [%90 –% 97, 5].},
   author = {Munya A Arasi and El-Sayed A El-Dahshan and El- Sayed and M El-Horbaty and Abdel-Badeeh M Salem},
   issue = {03},
   journal = {Egyptian Computer Science Journal},
   keywords = {Machine learning,Malignant melanoma,Medical Knowledge-Based systems,Medical imaging,Medical informatics,Skin cancer},
   pages = {1110-2586},
   title = {Malignant Melanoma Detection Based on Machine Learning Techniques: A Survey},
   volume = {40},
   url = {http://www.ecsjournal.org/Archive/Volume40/Issue3/1.pdf},
   year = {2016},
}
@article{Lopez-Labraca2018,
   abstract = {Computer-Aided Diagnosis (CAD) systems for melanoma detection have received a lot of attention during the last decades because of the utmost importance of detecting this type of skin cancer in its early stages. However, despite of the many research efforts devoted to this matter, these systems are not used yet in everyday clinical practice. Very likely, this is due to two main reasons: 1) the accuracy of the systems is not high enough; and 2) they simply provide a parallel diagnosis that actually does not help to the doctors (as long as there is no way to interpret it). In this paper, we propose a novel approach that aims to provide the doctor with an enriched diagnosis. Specifically, we rely on a dermoscopic-structure-based soft segmentation to design a set of structure-specific classifiers. Each individual structure-specific classifier is trained to distinguish benign lesions from melanomas just paying attention to one type of dermoscopic structure. Then, the outputs of the individual classifiers are combined by a means of the Bayesian method that, besides the final diagnosis, provide the doctor with additional valuable information, such as the opinions of the individual structure-specific experts and the uncertainty of the diagnosis. The results in terms of the features selected for the structure-specific classifiers are consistent with the expert insights. Furthermore, regarding the automatic melanoma diagnosis problem, the proposed method has been assessed on two different datasets, and the experimental results revealed that the proposed system clearly outperforms other methods in two datasets and compares well with the official submissions of the ISBI 2016 challenge on melanoma detection. Moreover, the system performance is equivalent to that of a well-known dermoscopy expert and its combination with the human diagnosis surpasses the human performance.},
   author = {Javier López-Labraca and Miguel Ángel Fernández-Torres and Iván González-Díaz and Fernando Díaz-De-María and Ángel Pizarro},
   doi = {10.1007/s11042-017-4879-3},
   issn = {15737721},
   issue = {10},
   journal = {Multimedia Tools and Applications},
   keywords = {Bayesian fusion,Computer-aided diagnosis,Dermoscopic structures,Enriched diagnosis,Melanoma diagnosis},
   pages = {12171-12202},
   title = {Enriched dermoscopic-structure-based cad system for melanoma diagnosis},
   volume = {77},
   year = {2018},
}
@article{Carrera2016,
   abstract = {Importance: The comparative diagnostic performance of dermoscopic algorithms and their individual criteria are not well studied. Objectives: To analyze the discriminatory power and reliability of dermoscopic criteria used in melanoma detection and compare the diagnostic accuracy of existing algorithms. Design, Setting, and Participants: This was a retrospective, observational study of 477 lesions (119 melanomas [24.9%] and 358 nevi [75.1%]), which were divided into 12 image sets that consisted of 39 or 40 images per set. A link on the International Dermoscopy Society website from January 1, 2011, through December 31, 2011, directed participants to the study website. Data analysis was performed from June 1, 2013, through May 31, 2015. Participants included physicians, residents, and medical students, and there were no specialty-type or experience-level restrictions. Participants were randomly assigned to evaluate 1 of the 12 image sets. Main Outcomes and Measures: Associations with melanoma and intraclass correlation coefficients (ICCs) were evaluated for the presence of dermoscopic criteria. Diagnostic accuracy measures were estimated for the following algorithms: the ABCD rule, the Menzies method, the 7-point checklist, the 3-point checklist, chaos and clues, and CASH (color, architecture, symmetry, and homogeneity). Results: A total of 240 participants registered, and 103 (42.9%) evaluated all images. The 110 participants (45.8%) who evaluated fewer than 20 lesions were excluded, resulting in data from 130 participants (54.2%), 121 (93.1%) of whom were regular dermoscopy users. Criteria associated with melanoma included marked architectural disorder (odds ratio [OR], 6.6; 95% CI, 5.6-7.8), pattern asymmetry (OR, 4.9; 95% CI, 4.1-5.8), nonorganized pattern (OR, 3.3; 95% CI, 2.9-3.7), border score of 6 (OR, 3.3; 95% CI, 2.5-4.3), and contour asymmetry (OR, 3.2; 95% CI, 2.7-3.7) (P < .001 for all). Most dermoscopic criteria had poor to fair interobserver agreement. Criteria that reached moderate levels of agreement included comma vessels (ICC, 0.44; 95% CI, 0.40-0.49), absence of vessels (ICC, 0.46; 95% CI, 0.42-0.51), dark brown color (ICC, 0.40; 95% CI, 0.35-0.44), and architectural disorder (ICC, 0.43; 95% CI, 0.39-0.48). The Menzies method had the highest sensitivity for melanoma diagnosis (95.1%) but the lowest specificity (24.8%) compared with any other method (P < .001). The ABCD rule had the highest specificity (59.4%). All methods had similar areas under the receiver operating characteristic curves. Conclusions and Relevance: Important dermoscopic criteria for melanoma recognition were revalidated by participants with varied experience. Six algorithms tested had similar but modest levels of diagnostic accuracy, and the interobserver agreement of most individual criteria was poor.},
   author = {Cristina Carrera and Michael A. Marchetti and Stephen W. Dusza and Giuseppe Argenziano and Ralph P. Braun and Allan C. Halpern and Natalia Jaimes and Harald J. Kittler and Josep Malvehy and Scott W. Menzies and Giovanni Pellacani and Susana Puig and Harold S. Rabinovitz and Alon Scope and H. Peter Soyer and Wilhelm Stolz and Rainer Hofmann-Wellenhof and Iris Zalaudek and Ashfaq A. Marghoob},
   doi = {10.1001/jamadermatol.2016.0624},
   issn = {2168-6068},
   issue = {7},
   journal = {JAMA Dermatology},
   pages = {798},
   title = {Validity and Reliability of Dermoscopic Criteria Used to Differentiate Nevi From Melanoma},
   volume = {152},
   year = {2016},
}
@article{Vocaturo2019,
   abstract = {The malignant melanoma is one of the most aggressive forms of skin cancer. Modern Dermatology recognizes early diagnosis as a fundamental role in reducing the mortality rate and to guarantee less invasive treatments for patients. Computer-Aided Diagnosis (CAD) systems are increasingly adopted for the early diagnosis of skin lesions. These systems consist of different phases that must be chosen appropriately based on the characteristics of digital images aiming to obtain a reliable diagnosis. Acquisition, pre-processing, segmentation, feature extraction and selection, and finally classification of dermoscopic images hold challenges to be faced and overcome to improve the automatic diagnosis of dangerous lesions such as melanoma. The classification phase is particularly delicate: over time, a series of automatic learning algorithms have been proposed to better face this issue. In this paper, we refer to the various machine learning approaches that have been proposed and that provide inspiration for the implementation of effective frameworks.},
   author = {Eugenio Vocaturo and Diego Perna and Ester Zumpano},
   doi = {10.1109/BIBM47256.2019.8983165},
   isbn = {9781728118673},
   journal = {Proceedings - 2019 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2019},
   keywords = {CAD Systems,Machine Learning,Melanoma Classification},
   pages = {2310-2317},
   title = {Machine Learning Techniques for Automated Melanoma Detection},
   year = {2019},
}
@article{Carrera2017,
   abstract = {IMPORTANCE: Melanomas that clinically mimic seborrheic keratosis (SK) can delay diagnosis and adequate treatment. However, little is known about the value of dermoscopy in recognizing these difficult-to-diagnose melanomas. OBJECTIVE: To describe the dermoscopic features of SK-like melanomas to understand their clinical morphology. DESIGN, SETTING, AND PARTICIPANTS: This observational retrospective study used 134 clinical and dermoscopic images of histopathologically proven melanomas in 134 patients treated in 9 skin cancer centers in Spain, France, Italy, and Austria. Without knowledge that the definite diagnosis for all the lesions was melanoma, 2 dermoscopy-trained observers evaluated the clinical descriptions and 48 dermoscopic features (including all melanocytic and nonmelanocytic criteria) of all 134 images and classified each dermoscopically as SK or not SK. The total dermoscopy score and the 7-point checklist score were assessed. Images of the lesions and patient data were collected from July 15, 2013, through July 31, 2014. MAIN OUTCOMES AND MEASURES: Frequencies of specific morphologic patterns of (clinically and dermoscopically) SK-like melanomas, patient demographics, and interobserver agreement of criteria were evaluated. RESULTS: Of the 134 cases collected from 72 men and 61 women, all of whom were white and who had a mean (SD) age of 55.6 (17.5) years, 110 (82.1%) revealed dermoscopic features suggestive of melanoma, including pigment network (74 [55.2%]), blue-white veil (72 [53.7%]), globules and dots (68 [50.7%]), pseudopods or streaks (47 [35.1%]), and blue-black sign (43 [32.3%]). The remaining 24 cases (17.9%) were considered likely SKs, even by dermoscopy. Overall, lesions showed a scaly and hyperkeratotic surface (45 [33.6%]), yellowish keratin (42 [31.3%]), comedo-like openings (41 [30.5%]), and milia-like cysts (30 [22.4%]). The entire sample achieved a mean (SD) total dermoscopy score of 4.7 (1.6) and a 7-point checklist score of 4.4 (2.3), while dermoscopically SK-like melanomas achieved a total dermoscopy score of only 4.2 (1.3) and a 7-point checklist score of 2.0 (1.9), both in the range of benignity. The most helpful criteria in correctly diagnosing SK-like melanomas were the presence of blue-white veil, pseudopods or streaks, and pigment network. Multivariate analysis found only the blue-black sign to be significantly associated with a correct diagnosis, while hyperkeratosis and fissures and ridges were independent risk markers of dermoscopically SK-like melanomas. CONCLUSIONS AND RELEVANCE: Seborrheic keratosis-like melanomas can be dermoscopically challenging, but the presence of the blue-black sign, pigment network, pseudopods or streaks, and/or blue-white veil, despite the presence of other SK features, allows the correct diagnosis of most of the difficult melanoma cases.},
   author = {Cristina Carrera and Sonia Segura and Paula Aguilera and Massimiliano Scalvenzi and Caterina Longo and Alicia Barreiro and Paolo Broganelli and Stefano Cavicchini and Alex Llambrich and Pedro Zaballos and Luc Thomas and Josep Malvehy and Susana Puig and Iris Zalaudek},
   doi = {10.1001/jamadermatol.2017.0129},
   issn = {21686068},
   issue = {6},
   journal = {JAMA Dermatology},
   pages = {544-551},
   title = {Dermoscopic clues for diagnosing melanomas that resemble seborrheic keratosis},
   volume = {153},
   year = {2017},
}
@article{Holmes2018,
   abstract = {Use of dermoscopy and detection algorithms by primary care physicians can enhance assessment of clinically suspicious lesions compared with that of naked eye examinations.},
   author = {G Alden Holmes and Janna M Vassantachart and Brittanya A Limone and Michael Zumwalt and Jane Hirokane and Sharon E Jacob},
   issn = {1945-337X},
   issue = {Suppl 4},
   journal = {Federal practitioner : for the health care professionals of the VA, DoD, and PHS},
   pages = {S39-S45},
   pmid = {30766399},
   title = {Using Dermoscopy to Identify Melanoma and Improve Diagnostic Discrimination.},
   volume = {35},
   url = {http://www.ncbi.nlm.nih.gov/pubmed/30766399%0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6375419},
   year = {2018},
}
@article{Kelly2019,
   abstract = {Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.},
   author = {Christopher J. Kelly and Alan Karthikesalingam and Mustafa Suleyman and Greg Corrado and Dominic King},
   doi = {10.1186/s12916-019-1426-2},
   issn = {17417015},
   issue = {1},
   journal = {BMC Medicine},
   keywords = {Algorithms,Artificial intelligence,Evaluation,Machine learning,Regulation,Translation},
   title = {Key challenges for delivering clinical impact with artificial intelligence},
   volume = {17},
   year = {2019},
}
@article{Combalia2019,
   abstract = {This article summarizes the BCN20000 dataset, composed of 19424 dermoscopic images of skin lesions captured from 2010 to 2016 in the facilities of the Hospital Cl\'inic in Barcelona. With this dataset, we aim to study the problem of unconstrained classification of dermoscopic images of skin cancer, including lesions found in hard-to-diagnose locations (nails and mucosa), large lesions which do not fit in the aperture of the dermoscopy device, and hypo-pigmented lesions. The BCN20000 will be provided to the participants of the ISIC Challenge 2019, where they will be asked to train algorithms to classify dermoscopic images of skin cancer automatically.},
   author = {Marc Combalia and Noel C. F. Codella and Veronica Rotemberg and Brian Helba and Veronica Vilaplana and Ofer Reiter and Cristina Carrera and Alicia Barreiro and Allan C. Halpern and Susana Puig and Josep Malvehy},
   title = {BCN20000: Dermoscopic Lesions in the Wild},
   url = {http://arxiv.org/abs/1908.02288},
   year = {2019},
}
@article{Walter2013,
   abstract = {Background GPs need to recognise significant pigmented skin lesions, given rising UK incidence rates for malignant melanoma. The 7-point checklist (7PCL) has been recommended by NICE (2005) for routine use in UK general practice to identify clinically significant lesions which require urgent referral. Aim To validate the Original and Weighted versions of the 7PCL in the primary care setting. Design and setting Diagnostic validation study, using data from a SIAscopic diagnostic aid randomised controlled trial in eastern England. Method Adults presenting in general practice with a pigmented skin lesion that could not be immediately diagnosed as benign were recruited into the trial. Reference standard diagnoses were histology or dermatology expert opinion; 7PCL scores were calculated blinded to the reference diagnosis. A case was defined as a clinically significant lesion for primary care referral to secondary care (total 1436 lesions: 225 cases, 1211 controls); or melanoma (36). Results For diagnosing clinically significant lesions there was a difference between the performance of the Original and Weighted 7PCLs (respectively, area under curve: 0.66, 0.69, difference = 0.03, P<0.001). For the identification of melanoma, similar differences were found. Increasing the Weighted 7PCL's cut-off score from recommended 3 to 4 improved detection of clinically significant lesions in primary care: sensitivity 73.3%, specificity 57.1%, positive predictive value 24.1%, negative predictive value 92.0%, while maintaining high sensitivity of 91.7% and moderate specificity of 53.4% for melanoma. Conclusion The Original and Weighted 7PCLs both performed well in a primary care setting to identify clinically significant lesions as well as melanoma. The Weighted 7PCL, with a revised cut-off score of 4 from 3, performs slightly better and could be applied in general practice to support the recognition of clinically significant lesions and therefore the early identification of melanoma. © British Journal of General Practice.},
   author = {Fiona M. Walter and A. Toby Prevost and Joana Vasconcelos and Per N. Hall and Nigel P. Burrows and Helen C. Morris and Ann Louise Kinmonth and Jon D. Emery},
   doi = {10.3399/bjgp13X667213},
   issn = {09601643},
   issue = {610},
   journal = {British Journal of General Practice},
   keywords = {Diagnostic techniques and procedures,General practice,Melanoma,Pigmented skin lesions},
   title = {Using the 7-point checklist as a diagnostic aid for pigmented skin lesions in general practice: A diagnostic validation study},
   volume = {63},
   year = {2013},
}
@article{Xiong2017,
   abstract = {Purpose: Dermoscopy and reflectance confocal microscopy (RCM) are non-invasive methods for diagnosis of malignant skin tumours. The aim of this study was to compare the accuracy of dermoscopy and RCM for the diagnosis of malignant skin tumours. Methods: Systematic electronic literature searches were conducted to include PubMed, Medline, Embase, the Cochrane Library database, and Web of Science, up to 26 April 2016. Pooled additional detection rate (ADR), diagnostic accuracy, and 95% confidence intervals (CIs) were calculated using STATA and Meta-Disc analysis. Results: Eight published studies were included in the analysis, involving 1141 skin lesions, which reported a per-lesion analysis of dermoscopy and RCM. Within the same patient group and at the per-lesion level, RCM significantly increased the detection rate of malignant skin tumours by 7.7% (95% CI 0.01–0.14). The pooled sensitivity of dermoscopy was similar to RCM [88.1% (95% CI 0.85–0.91) vs. 93.5% (95% CI 0.91–0.96)]. The specificity of dermoscopy was significantly lower than that of RCM [52.9% (95% CI 0.49–0.57) vs. 80.3% (95% CI 0.77–0.83)]. The pooled ADR of RCM for melanoma detection was 4.3% (95% CI 0.002–0.08). Pooled sensitivity and specificity of dermoscopy for melanoma detection were 88.4% (95% CI 0.84–0.92) and 49.1% (95% CI 0.45–0.53), respectively. The pooled sensitivity and specificity of RCM were 93.5% (95% CI 0.90–0.96) and 78.8% (95% CI 0.75–0.82), respectively. Conclusions: When compared with dermoscopy, RCM has a significantly greater diagnostic specificity for malignant skin tumours and so could improve their detection rate.},
   author = {Yi Quan Xiong and Shu Juan Ma and Yun Mo and Shu Ting Huo and Yu Qi Wen and Qing Chen},
   doi = {10.1007/s00432-017-2391-9},
   issn = {14321335},
   issue = {9},
   journal = {Journal of Cancer Research and Clinical Oncology},
   keywords = {Dermoscopy,Melanoma,Meta-analysis,Reflectance confocal microscopy,Skin cancer},
   pages = {1627-1635},
   title = {Comparison of dermoscopy and reflectance confocal microscopy for the diagnosis of malignant skin tumours: a meta-analysis},
   volume = {143},
   year = {2017},
}
@article{Barata2019,
   abstract = {Dermoscopy image analysis (DIA) is a growing field, with works being published every week. This makes it difficult not only to keep track of all the contributions, but also for new researchers to identify relevant information and new directions to be explored. Several surveys have been written in the past decade, but these tend to cover all of the steps of a CAD system, which can be overwhelming. Moreover, in these works, each of the steps is briefly discussed due to lack of space. Among the different blocks of the CAD system, the most relevant is the one devoted to feature extraction. This is also the block where existing works exhibit the most variability. Therefore, we believe that it is important to review the state-of-the-art on this matter. This work thoroughly explores the several types of features that have been used in DIA. A discussion on their relevance and limitations, as well as suggestions for future research are provided.},
   author = {Catarina Barata and M. Emre Celebi and Jorge S. Marques},
   doi = {10.1109/JBHI.2018.2845939},
   issn = {21682194},
   issue = {3},
   journal = {IEEE Journal of Biomedical and Health Informatics},
   keywords = {CAD systems,Dermoscopy,feature extraction,melanoma,skin cancer},
   pages = {1096-1109},
   title = {A Survey of Feature Extraction in Dermoscopy Image Analysis of Skin Cancer},
   volume = {23},
   year = {2019},
}
@article{Kawahara2019,
   abstract = {The presence of certain clinical dermoscopic features within a skin lesion may indicate melanoma, and automatically detecting these features may lead to more quantitative and reproducible diagnoses. We reformulate the task of classifying clinical dermoscopic features within superpixels as a segmentation problem, and propose a fully convolutional neural network to detect clinical dermoscopic features from dermoscopy skin lesion images. Our neural network architecture uses interpolated feature maps from several intermediate network layers, and addresses imbalanced labels by minimizing a negative multilabel Dice-F 1 score, where the score is computed across the minibatch for each label. Our approach ranked first place in the 2017 ISIC-ISBI Part 2: Dermoscopic Feature Classification Task, challenge over both the provided validation and test datasets, achieving a 0.895% area under the receiver operator characteristic curve score. We show how simple baseline models can outrank state-of-the-art approaches when using the official metrics of the challenge, and propose to use a fuzzy Jaccard Index that ignores the empty set (i.e., masks devoid of positive pixels) when ranking models. Our results suggest that the classification of clinical dermoscopic features can be effectively approached as a segmentation problem, and the current metrics used to rank models may not well capture the efficacy of the model. We plan to make our trained model and code publicly available.},
   author = {Jeremy Kawahara and Ghassan Hamarneh},
   doi = {10.1109/JBHI.2018.2831680},
   issn = {21682194},
   issue = {2},
   journal = {IEEE Journal of Biomedical and Health Informatics},
   keywords = {Convolutional neural networks,dermoscopy,milia-like cysts,negative network,pigment network,streaks},
   pages = {578-585},
   title = {Fully Convolutional Neural Networks to Detect Clinical Dermoscopic Features},
   volume = {23},
   year = {2019},
}
@article{Monisha2018,
   abstract = {This study describes the usage of neural community based on the texture evaluation of pores and skin a variety of similarities in their signs, inclusive of Measles (rubella), German measles (rubella), and Chickenpox etc. In fashionable, these illnesses have similarities in sample of infection and symptoms along with redness and rash. Various skin problems have similar symptoms. For example, in German measles (rubella), Chicken pox and Measles (rubella) a similarity can be observed in skin rashes and redness. The prognosis of skin problems take a long time as the patient’s previous medical records, physical examination report and the respective laboratory diagnostic reports have to be studied. The recognition and diagnosis get tough due to the complexity involved. Subsequently, a computer aided analysis and recognition gadget would be handy in such cases. Computer algorithm steps include image processing, picture characteristic extraction and categorize facts with the help of a classifier with Artificial Neural Network (ANN). The ANN can analyze the patterns of symptoms of a particular disease and present faster prognosis and reputation than a human doctor. For this reason, the patients can undergo the treatment for the pores and skin problems based totally on the symptoms detected.},
   author = {M. Monisha and A. Suresh and M. R. Rashmi},
   doi = {10.1007/s10916-018-1112-5},
   issn = {1573689X},
   issue = {1},
   journal = {Journal of Medical Systems},
   keywords = {Dominant rotated local binary pattern (DRLBP),Gaussian mixture model classifier (GMM),Gray level co-occurrence matrix (GLCM),Pre-processing,Probabilistic neural network (PNN) classification,Super pixel segmentation},
   title = {Artificial Intelligence Based Skin Classification Using GMM},
   volume = {43},
   year = {2018},
}
@article{Guo2018,
   abstract = {This paper proposes novel skin lesion detection based on neutrosophic clustering and adaptive region growing algorithms applied to dermoscopic images, called NCARG. First, the dermoscopic images are mapped into a neutrosophic set domain using the shearlet transform results for the images. The images are described via three memberships: true, indeterminate, and false memberships. An indeterminate filter is then defined in the neutrosophic set for reducing the indeterminacy of the images. A neutrosophic c-means clustering algorithm is applied to segment the dermoscopic images. With the clustering results, skin lesions are identified precisely using an adaptive region growing method. To evaluate the performance of this algorithm, a public data set (ISIC 2017) is employed to train and test the proposed method. Fifty images are randomly selected for training and 500 images for testing. Several metrics are measured for quantitatively evaluating the performance of NCARG. The results establish that the proposed approach has the ability to detect a lesion with high accuracy, 95.3% average value, compared to the obtained average accuracy, 80.6%, found when employing the neutrosophic similarity score and level set (NSSLS) segmentation approach.},
   author = {Yanhui Guo and Amira S. Ashour and Florentin Smarandache},
   doi = {10.3390/sym10040119},
   issn = {20738994},
   issue = {4},
   journal = {Symmetry},
   keywords = {Dermoscopy,Image segmentation,Neutrosophic c-means clustering,Neutrosophic clustering,Region growing,Skin cancer},
   title = {A novel skin lesion detection approach using neutrosophic clustering and adaptive region growing in dermoscopy images},
   volume = {10},
   year = {2018},
}
@article{Minagawa2017,
   abstract = {Making a definitive diagnosis of seborrheic keratosis (SK) can be challenging for the naked eye due to its wide variation in clinical features. Fortunately, however, most cases of SK exhibit the typical dermoscopic findings of fissures and ridges, hairpin vessels with white halo, comedo-like openings, and milia-like cysts, all of which are helpful to distinguish SK from melanoma, melanocytic nevus, squamous cell carcinoma, basal cell carcinoma (BCC) and other skin tumors. Histopathologically, these dermoscopic characteristics correspond to papillomatous surface of the epidermis, enlarged capillaries of the dermal papillae, pseudohorn cysts in the epidermis opened to the surface of the lesion and intraepidermal cysts, respectively. Clinicians should bear in mind that the clonal type of SK dermoscopically mimics melanoma and BCC by the presence of globule-like structures, while regressing SK exhibits a granular pattern that is similar to the peppering found in melanoma. Furthermore, milia-like cysts alone are insufficient for a conclusive diagnosis of SK because melanoma in rare cases displays cysts along with other SK-like dermoscopic findings.},
   author = {Akane Minagawa},
   doi = {10.1111/1346-8138.13657},
   issn = {13468138},
   issue = {5},
   journal = {Journal of Dermatology},
   keywords = {dermoscopy,histopathology,melanoma,milia-like cysts,seborrheic keratosis},
   pages = {518-524},
   title = {Dermoscopy–pathology relationship in seborrheic keratosis},
   volume = {44},
   year = {2017},
}
@article{Subramanian2013,
   abstract = {Early detection of melanoma by magnified visible-light imaging (dermoscopy) is hindered by lesions which mimic melanoma. Automatic discrimination of melanoma from mimics could allow detection of melanoma at an earlier stage. Seborrheic keratoses are common mimics; these have distinctive bright structures: starry milia-like cysts (MLCs). We report discrimination of MLCs from mimics by features extracted from starry MLC (star) candidates. After pre-processing, 2D template matching is optimized with respect to star template size, histogram pre-processing, and 2D statistics. The novel aspects of this research were new details for region of interest (ROI) analysis of the centers of the star candidate, a new method for determining shape of hazy objects and multiple template matching, using unprocessed ROIs, shape-limited ROIs, and histogram-equalized ROIs. Features retained in the final model for the decision MLC vs. mimic by logistic regression include star size, 2D first correlation coefficient, correlation coefficient to the star shape template, equalized correlation coefficient, relative star brightness, and statistical features at the star center. These methods allow optimization of MLC features found by 2D template correlation. This research confirms the importance of fine ROI features and ROI neighborhoods in medical imaging.},
   author = {Viswanaath Subramanian and Randy H. Moss and Ryan K. Rader and Sneha K. Mahajan and William V. Stoecker},
   doi = {10.5220/0004227504440448},
   isbn = {9789898565471},
   journal = {VISAPP 2013 - Proceedings of the International Conference on Computer Vision Theory and Applications},
   keywords = {Image processing,Milia-like cysts,Object detection,Pattern analysis,Seborrheic keratosis,Template matching},
   pages = {444-448},
   title = {Template matching for detection of starry milia-like cysts in dermoscopic images},
   volume = {1},
   year = {2013},
}
@article{Arroyo2014,
   abstract = {Computers in Biology and Medicine, 44 + (2013) 144-157. doi:10.1016/j.compbiomed.2013.11.002},
   author = {Jose Luis García Arroyo and Begoña García Zapirain},
   issue = {C},
   journal = {Computers in Biology and Medicine},
   pages = {144-157},
   title = {Detection of pigment network in dermoscopy images using supervised machine learning and structural analysis},
   volume = {44},
   url = {http://dx.doi.org/10.1016/j.compbiomed.2013.11.002%5Cnpapers2://publication/doi/10.1016/j.compbiomed.2013.11.002},
   year = {2014},
}
@article{Meskini2018,
   abstract = {Background: With advances in medical imaging systems, digital dermoscopy has become one of the major imaging modalities in the analysis of skin lesions. Thus, automated segmentation or border detection has a great impact on the subsequent steps of skin cancer computer-aided diagnosis using demoscopy images. Since dermoscopy images suffer from artifacts such as shading and hair, there is a need for automated and robust artifact attenuation removal and lesion border detection. Methods: A method for segmentation of dermoscopy images is proposed based on active contour. To this end, at first, a simple method for hair pixels is restored and a new scheme for shading detection is proposed. Then, particle swarm optimization (PSO) algorithm is applied to select the best coefficients for converting RGB to gray level. The obtained gray level image is then used as input for multi Otsu method which provides initial contour for border detection using active contour. Finally, Chan and Vese active contour is used for final lesion border detection. Results: The method is tested on a total of 145 dermoscopic images: 79 cases with benign lesion and 75 cases with melanoma lesion. Mean accuracy, sensitivity and specificity were obtained 94%, 78.5% and 99%, respectively. Conclusion: Results reveal that the proposed method segments the lesion from dermoscopy images accurately.},
   author = {E. Meskini and M. S. Helfroush and K. Kazemi and M. Sepaskhah},
   doi = {10.22086/jbpe.v0i0.444},
   issn = {22517200},
   issue = {1},
   journal = {Journal of Biomedical Physics and Engineering},
   keywords = {Active contour,Dermoscopy,Melanoma,Segmentation},
   pages = {109-118},
   title = {A new algorithm for skin lesion border detection in dermoscopy images},
   volume = {8},
   year = {2018},
}
@article{Majumder2019b,
   author = {Sharmin Majumder and Muhammad Ahsan Ullah},
   doi = {10.1007/s42452-019-0786-8},
   issn = {2523-3963},
   issue = {7},
   journal = {SN Applied Sciences},
   title = {Feature extraction from dermoscopy images for melanoma diagnosis},
   volume = {1},
   year = {2019},
}
@article{Stricklin2011,
   abstract = {Background Seborrheic keratoses are the most common skin lesions known to contain small white or yellow structures called milia-like cysts (MLCs). Varied appearances can sometimes make it difficult to differentiate benign lesions from malignant lesions such as melanoma, the deadliest form of skin cancer found in humans. Objective The purpose of this study was to determine the statistical occurrence of MLCs in benign vs. malignant lesions. Methods A medical student with 10 months experience in examining approximately 1000 dermoscopy images and a dermoscopy-naïve observer analysed contact non-polarized dermoscopy images of 221 malignant melanomas and 175 seborrheic keratoses for presence of MLCs. Results The observers found two different types of MLCs present: large ones described as cloudy and smaller ones described as starry. Starry MLCs were found to be prevalent in both seborrheic keratoses and melanomas. Cloudy MLCs, however, were found to have 99.1% specificity for seborrheic keratoses among this group of seborrheic keratoses and melanomas. Conclusion Cloudy MLCs can be a useful tool for differentiating between seborrheic keratoses and melanomas. © 2010 The Authors. Journal of the European Academy of Dermatology and Venereology © 2010 European Academy of Dermatology and Venereology.},
   author = {S. M. Stricklin and W. V. Stoecker and M. C. Oliviero and H. S. Rabinovitz and S. K. Mahajan},
   doi = {10.1111/j.1468-3083.2010.03920.x},
   issn = {09269959},
   issue = {10},
   journal = {Journal of the European Academy of Dermatology and Venereology},
   keywords = {melanoma,milia-like Cyst,seborrheic Keratosis},
   pages = {1222-1224},
   title = {Cloudy and starry milia-like cysts: How well do they distinguish seborrheic keratoses from malignant melanomas?},
   volume = {25},
   year = {2011},
}
@article{Rashid2019b,
   abstract = {Early detection and frequent monitoring are critical for survival of skin cancer patients. Unfortunately, in practice a significant number of cases remain undetected until advanced stages, reducing the chances of survival. An appealing approach for early detection is to employ automated classification of dermoscopic images acquired via low-cost, smartphone-based hardware. By far, the most successful classification approaches on this task are based on deep learning. Unfortunately, most medical image classification tasks are unable to leverage the true potential of deep learning due to limited sizes of training datasets. Investigation of novel data generation techniques is thus an appealing option since it can enable us to augment our training data by a large number of synthetically generated examples. In this work, we investigate the possibility of obtaining realistic looking dermoscopic images via generative adversarial networks (GANs). These images are then employed to augment our existing training set in an effort to enhance the performance of a deep convolutional neural network on the skin lesion classification task. Results are compared with conventional data augmentation strategies and demonstrate that GAN based augmentation delivers significant performance gains.},
   author = {Haroon Rashid and M. Asjid Tanveer and Hassan Aqeel Khan},
   doi = {10.1109/EMBC.2019.8857905},
   issn = {1557170X},
   journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference},
   pages = {916-919},
   title = {Skin Lesion Classification Using GAN based Data Augmentation},
   volume = {2019},
   year = {2019},
}
@article{Bibi2018,
   author = {Maryam Bibi and Anmol Hamid and Samabia Tehseen},
   doi = {10.4108/eai.29-7-2019.159800},
   issn = {2032-9407},
   issue = {0},
   journal = {ICST Transactions on Scalable Information Systems},
   pages = {159800},
   title = {Automated Skin Lesion Detection towards Melanoma},
   volume = {0},
   year = {2018},
}
@article{Badrinarayanan2017,
   abstract = {We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network [1]. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2] and also with the well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments show that SegNet provides good performance with competitive inference time and most efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.},
   author = {Vijay Badrinarayanan and Alex Kendall and Roberto Cipolla},
   doi = {10.1109/TPAMI.2016.2644615},
   issn = {01628828},
   issue = {12},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   keywords = {Deep convolutional neural networks,decoder,encoder,indoor scenes,pooling,road scenes,semantic pixel-wise segmentation,upsampling},
   pages = {2481-2495},
   pmid = {28060704},
   title = {SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},
   volume = {39},
   year = {2017},
}
@article{Pereira2020,
   abstract = {Machine learning algorithms are progressively assuming an important role as a computational tool to support clinical diagnosis, namely in the classification of pigmented skin lesions. The current classification methods commonly rely on features derived from shape, colour, or texture, obtained after image segmentation, but these do not always guarantee the best results. To improve the classification accuracy, this work proposes to further exploit the border-line characteristics of the lesion segmentation mask, by combining gradients with local binary patterns (LBP). In the proposed method, these border-line features are used together with the conventional ones to enhance the performance of skin lesion classification algorithms. When the new features are combined with the classical ones, the experimental results show higher accuracy, which impacts positively the overall performance of the classification algorithms. As the medical image datasets usually present large class imbalance, which results in low sensitivity for the classifiers, the border-line features have a positive impact on this classification metric, as evidenced by the experimental results. Both the features’ usefulness and their impact are assessed in regard to the classification results, which in turn are statistically tested for completeness, using three different classifiers and two medical image datasets.},
   author = {Pedro M.M. Pereira and Rui Fonseca-Pinto and Rui Pedro Paiva and Pedro A.A. Assuncao and Luis M.N. Tavora and Lucas A. Thomaz and Sergio M.M. Faria},
   doi = {10.1016/j.bspc.2019.101765},
   issn = {17468108},
   journal = {Biomedical Signal Processing and Control},
   keywords = {Classification,Feature extraction,Image segmentation,Medical imaging,Skin lesion},
   title = {Skin lesion classification enhancement using border-line features – The melanoma vs nevus problem},
   volume = {57},
   year = {2020},
}
@article{Fan2017,
   abstract = {Segmentation is one of the crucial steps for the computer-aided diagnosis (CAD) of skin cancer with dermoscopy images. To accurately extract lesion borders from dermoscopy images, a novel automatic segmentation algorithm using saliency combined with Otsu threshold is proposed in this paper, which includes enhancement and segmentation stages. In the enhancement stage, prior information on healthy skin is extracted, and the color saliency map and brightness saliency map are constructed respectively. By fusing the two saliency maps, the final enhanced image is obtained. In the segmentation stage, according to the histogram distribution of the enhanced image, an optimization function is designed to adjust the traditional Otsu threshold method to obtain more accurate lesion borders. The proposed model is validated from enhancement effectiveness and segmentation accuracy. Experimental results demonstrate that our method is robust and performs better than other state-of-the-art methods.},
   author = {Haidi Fan and Fengying Xie and Yang Li and Zhiguo Jiang and Jie Liu},
   doi = {10.1016/j.compbiomed.2017.03.025},
   issn = {18790534},
   journal = {Computers in Biology and Medicine},
   keywords = {Automatic segmentation,Computer-aided diagnosis,Dermoscopy images,Saliency,Threshold},
   pages = {75-85},
   title = {Automatic segmentation of dermoscopy images using saliency combined with Otsu threshold},
   volume = {85},
   year = {2017},
}
@article{Filali2019,
   abstract = {Skin cancer is considered as one of the dangerous types of cancer with a high proportion of deaths. This cancer can be categorized into two main types; Melanoma, which is the deadliest form, and Non-Melanoma. Early melanoma detection and diagnosis allows more treatment options and decreases significantly the number of deaths. Many researchers proposed to use image processing for skin lesion detection. The process can be divided into three main stages: lesion identification based on image segmentation, features extraction and lesion classification. Segmentation and features extraction are the key-steps and significantly influence the outcome of the classification results. In this paper, an improved segmentation approach for skin lesion detection and classification has been proposed. The proposed approach consists on a pre-processing based on multiscale decomposition thats separate the input image into two components. The geometrical component will be used in the segmentation stage and the texture component in features extraction. The efficiency and the performance of the proposed approach has been evaluated in comparison with recent and robust dermoscopic approaches from literature.},
   author = {Youssef Filali and My Abdelouahed Sabri and Abdellah Aarab},
   doi = {10.19139/soic.v7i2.533},
   issn = {23105070},
   issue = {2},
   journal = {Statistics, Optimization and Information Computing},
   keywords = {Features extraction,PDE Multi-scale decomposition,SVM,Skin cancer,Texture analysis},
   pages = {456-467},
   title = {An improved segmentation approach for skin lesion classification},
   volume = {7},
   year = {2019},
}
@article{Bakheet2017,
   abstract = {Early detection of skin cancer through improved techniques and innovative technologies has the greatest potential for significantly reducing both morbidity and mortality associated with this disease. In this paper, an effective framework of a CAD (Computer-Aided Diagnosis) system for melanoma skin cancer is developed mainly by application of an SVM (Support Vector Machine) model on an optimized set of HOG (Histogram of Oriented Gradient) based descriptors of skin lesions. Experimental results obtained by applying the presented methodology on a large, publicly accessible dataset of dermoscopy images demonstrate that the proposed framework is a strong contender for the state-of-the-art alternatives by achieving high levels of sensitivity, specificity, and accuracy (98.21%, 96.43% and 97.32%, respectively), without sacrificing computational soundness.},
   author = {Samy Bakheet},
   doi = {10.3390/computation5010004},
   issn = {20793197},
   issue = {1},
   journal = {Computation},
   keywords = {CAD,Dermoscopy,HOG descriptors,Melanoma skin cancer,SVM classification},
   title = {An SVM framework for malignant melanoma detection based on optimized HOG features},
   volume = {5},
   year = {2017},
}
@article{Hu2019b,
   abstract = {Segmentation is the essential requirement in automated computer-aided diagnosis (CAD) of skin diseases. In this paper, we propose an unsupervised skin lesion segmentation method to challenge the difficulties existing in the dermoscopy images such as low contrast, border indistinct, and skin lesion is close to the boundary. The proposed method combines the enhanced fusion saliency with adaptive thresholding based on wavelet transform to get the lesion regions. Firstly, a fusion saliency map increases the contract of the skin lesion and healthy skin, and then an adaptive thresholding method based on wavelet transform is used to obtain more accurate lesion regions. We compare the proposed method with seven state-of-the-art approaches using a series of evaluation metrics on both PH2 and ISBI2016 datasets. The results demonstrate the effectiveness of the proposed method superior to the state-of-the-art approaches in accordance with quantitative results and visual effects.},
   author = {Kai Hu and Si Liu and Yuan Zhang and Chunhong Cao and Fen Xiao and Wei Huang and Xieping Gao},
   doi = {10.1007/s11042-019-7160-0},
   issn = {15737721},
   journal = {Multimedia Tools and Applications},
   keywords = {Adaptive thresholding,Dermoscopy images,Saliency map,Segmentation,Wavelet transform},
   title = {Automatic segmentation of dermoscopy images using saliency combined with adaptive thresholding based on wavelet transform},
   year = {2019},
}
@article{Olugbara2018,
   abstract = {The prevalence of melanoma skin cancer disease is rapidly increasing as recorded death cases of its patients continue to annually escalate. Reliable segmentation of skin lesion is one essential requirement of an efficient noninvasive computer aided diagnosis tool for accelerating the identification process of melanoma. This paper presents a new algorithm based on perceptual color difference saliency along with binary morphological analysis for segmentation of melanoma skin lesion in dermoscopic images. The new algorithm is compared with existing image segmentation algorithms on benchmark dermoscopic images acquired from public corpora. Results of both qualitative and quantitative evaluations of the new algorithm are encouraging as the algorithm performs excellently in comparison with the existing image segmentation algorithms.},
   author = {Oludayo O. Olugbara and Tunmike B. Taiwo and Delene Heukelman},
   doi = {10.1155/2018/1524286},
   issn = {1024-123X},
   journal = {Mathematical Problems in Engineering},
   pages = {1-19},
   title = {Segmentation of Melanoma Skin Lesion Using Perceptual Color Difference Saliency with Morphological Analysis},
   volume = {2018},
   year = {2018},
}
@article{Ahn2017b,
   abstract = {The segmentation of skin lesions in dermoscopic images is a fundamental step in automated computer-aided diagnosis of melanoma. Conventional segmentation methods, however, have difficulties when the lesion borders are indistinct and when contrast between the lesion and the surrounding skin is low. They also perform poorly when there is a heterogeneous background or a lesion that touches the image boundaries; this then results in under- and oversegmentation of the skin lesion. We suggest that saliency detection using the reconstruction errors derived from a sparse representation model coupled with a novel background detection can more accurately discriminate the lesion from surrounding regions. We further propose a Bayesian framework that better delineates the shape and boundaries of the lesion. We also evaluated our approach on two public datasets comprising 1100 dermoscopic images and compared it to other conventional and state-of-the-art unsupervised (i.e., no training required) lesion segmentation methods, as well as the state-of-the-art unsupervised saliency detection methods. Our results show that our approach is more accurate and robust in segmenting lesions compared to other methods. We also discuss the general extension of our framework as a saliency optimization algorithm for lesion segmentation.},
   author = {Euijoon Ahn and Jinman Kim and Lei Bi and Ashnil Kumar and Changyang Li and Michael Fulham and David Dagan Feng},
   doi = {10.1109/JBHI.2017.2653179},
   issn = {21682194},
   issue = {6},
   journal = {IEEE Journal of Biomedical and Health Informatics},
   keywords = {Computer-aided diagnosis (CAD),dermoscopic image,lesion segmentation,saliency detection},
   pages = {1685-1693},
   title = {Saliency-Based Lesion Segmentation Via Background Detection in Dermoscopic Images},
   volume = {21},
   year = {2017},
}
@article{Peng2019,
   abstract = {Skin lesion image segmentation task has many difficulties due to the hair occlusion or low contrast. Traditional methods based image quality are powerless when processing these kinds of skin images. In this paper, a segmentation architecture based adversarial networks is proposed. The architecture is consist of a segmentation network based U-net and a discrimination network linked by certain convolutional layers. Both two networks are trained alternately and at last segmentation network gets a high segmentation accuracy. We test our architecture on dataset PH 2 and dataset obtained from “Skin Lesion Analysis Toward Melanoma Detection” challenge which was hosted by ISBI 2016 conference and we achieved segmentation average accuracy of 0.97, dice coefficient of 0.94 which outperform other existed segmentation network, including winner of ISBI 2016 challenge for skin melanoma segmentation.},
   author = {Yanjun Peng and Ning Wang and Yuanhong Wang and Meiling Wang},
   doi = {10.1007/s11042-018-6523-2},
   issn = {15737721},
   issue = {8},
   journal = {Multimedia Tools and Applications},
   keywords = {Adversarial network,Convolutional neural networks,Image segmentation,Skin lesion},
   pages = {10965-10981},
   title = {Segmentation of dermoscopy image using adversarial networks},
   volume = {78},
   year = {2019},
}
@article{Khan2018,
   abstract = {Background: Melanoma is the deadliest type of skin cancer with highest mortality rate. However, the annihilation in its early stage implies a high survival rate therefore, it demands early diagnosis. The accustomed diagnosis methods are costly and cumbersome due to the involvement of experienced experts as well as the requirements for the highly equipped environment. The recent advancements in computerized solutions for this diagnosis are highly promising with improved accuracy and efficiency. Methods: In this article, a method for the identification and classification of the lesion based on probabilistic distribution and best features selection is proposed. The probabilistic distribution such as normal distribution and uniform distribution are implemented for segmentation of lesion in the dermoscopic images. Then multi-level features are extracted and parallel strategy is performed for fusion. A novel entropy-based method with the combination of Bhattacharyya distance and variance are calculated for the selection of best features. Only selected features are classified using multi-class support vector machine, which is selected as a base classifier. Results: The proposed method is validated on three publicly available datasets such as PH2, ISIC (i.e. ISIC MSK-2 and ISIC UDA), and Combined (ISBI 2016 and ISBI 2017), including multi-resolution RGB images and achieved accuracy of 97.5%, 97.75%, and 93.2%, respectively. Conclusion: The base classifier performs significantly better on proposed features fusion and selection method as compared to other methods in terms of sensitivity, specificity, and accuracy. Furthermore, the presented method achieved satisfactory segmentation results on selected datasets.},
   author = {M. Attique Khan and Tallha Akram and Muhammad Sharif and Aamir Shahzad and Khursheed Aurangzeb and Musaed Alhussein and Syed Irtaza Haider and Abdualziz Altamrah},
   doi = {10.1186/s12885-018-4465-8},
   issn = {14712407},
   issue = {1},
   journal = {BMC Cancer},
   keywords = {Features fusion,Features selection,Image enhancement,Image fusion,Multi-level features extraction,Uniform distribution},
   title = {An implementation of normal distribution based segmentation and entropy controlled features selection for skin lesion detection and classification},
   volume = {18},
   year = {2018},
}
@article{Akram2020,
   abstract = {Melanoma is considered to be one of the deadliest skin cancer types, whose occurring frequency elevated in the last few years; its earlier diagnosis, however, significantly increases the chances of patients’ survival. In the quest for the same, a few computer based methods, capable of diagnosing the skin lesion at initial stages, have been recently proposed. Despite some success, however, margin exists, due to which the machine learning community still considers this an outstanding research challenge. In this work, we come up with a novel framework for skin lesion classification, which integrates deep features information to generate most discriminant feature vector, with an advantage of preserving the original feature space. We utilize recent deep models for feature extraction, and by taking advantage of transfer learning. Initially, the dermoscopic images are segmented, and the lesion region is extracted, which is later subjected to retrain the selected deep models to generate fused feature vectors. In the second phase, a framework for most discriminant feature selection and dimensionality reduction is proposed, entropy-controlled neighborhood component analysis (ECNCA). This hierarchical framework optimizes fused features by selecting the principle components and extricating the redundant and irrelevant data. The effectiveness of our design is validated on four benchmark dermoscopic datasets; PH2, ISIC MSK, ISIC UDA, and ISBI-2017. To authenticate the proposed method, a fair comparison with the existing techniques is also provided. The simulation results clearly show that the proposed design is accurate enough to categorize the skin lesion with 98.8%, 99.2% and 97.1% and 95.9% accuracy with the selected classifiers on all four datasets, and by utilizing less than 3% features.},
   author = {Tallha Akram and Hafiz M.Junaid Lodhi and Syed Rameez Naqvi and Sidra Naeem and Majed Alhaisoni and Muhammad Ali and Sajjad Ali Haider and Nadia N. Qadri},
   doi = {10.1186/s13673-020-00216-y},
   issn = {21921962},
   issue = {1},
   journal = {Human-centric Computing and Information Sciences},
   keywords = {Convolutional neural network,Deep learning,Dermoscopy,Feature selection,Skin lesion,Transfer learning},
   title = {A multilevel features selection framework for skin lesion classification},
   volume = {10},
   year = {2020},
}
@article{Serte2019,
   abstract = {Skin cancer cases are increasing and becoming one of the main problems worldwide. Skin cancer is known as a malignant type of skin lesion, and early detection and treatment are necessary. Malignant melanoma and seborrheic keratosis are known as common skin lesion types. A fast and accurate medical diagnosis of these lesions is crucial. In this study, a novel Gabor wavelet-based deep convolutional neural network is proposed for the detection of malignant melanoma and seborrheic keratosis. The proposed method is based on the decomposition of input images into seven directional sub-bands. Seven sub-band images and the input image are used as inputs to eight parallel CNNs to generate eight probabilistic predictions. Decision fusion based on the sum rule is utilized to classify the skin lesion. Gabor based approach provides directional decomposition where each sub-band gives isolated decisions that can be fused for improved overall performance. The results show that the proposed method outperforms alternative methods in the literature developed for skin cancer detection.},
   author = {Sertan Serte and Hasan Demirel},
   doi = {10.1016/j.compbiomed.2019.103423},
   issn = {18790534},
   journal = {Computers in Biology and Medicine},
   keywords = {Convolutional neural networks,Gabor wavelets,Model fusion},
   pmid = {31499395},
   title = {Gabor wavelet-based deep learning for skin lesion classification},
   volume = {113},
   year = {2019},
}
@article{Hosny2019,
   abstract = {Skin cancer is one of most deadly diseases in humans. According to the high similarity between melanoma and nevus lesions, physicians take much more time to investigate these lesions. The automated classification of skin lesions will save effort, time and human life. The purpose of this paper is to present an automatic skin lesions classification system with higher classification rate using the theory of transfer learning and the pre-trained deep neural network. The transfer learning has been applied to the Alex-net in different ways, including fine-tuning the weights of the architecture, replacing the classification layer with a softmax layer that works with two or three kinds of skin lesions, and augmenting dataset by fixed and random rotation angles. The new softmax layer has the ability to classify the segmented color image lesions into melanoma and nevus or into melanoma, seborrheic keratosis, and nevus. The three well-known datasets, MED-NODE, Derm (IS & Quest) and ISIC, are used in testing and verifying the proposed method. The proposed DCNN weights have been fine-tuned using the training and testing dataset from ISIC in addition to 10-fold cross validation for MED-NODE and DermIS—DermQuest. The accuracy, sensitivity, specificity, and precision measures are used to evaluate the performance of the proposed method and the existing methods. For the datasets, MED-NODE, Derm (IS & Quest) and ISIC, the proposed method has achieved accuracy percentages of 96.86%, 97.70%, and 95.91% respectively. The performance of the proposed method has outperformed the performance of the existing classification methods of skin cancer.},
   author = {Khalid M. Hosny and Mohamed A. Kassem and Mohamed M. Foaud},
   doi = {10.1371/journal.pone.0217293},
   issn = {19326203},
   issue = {5},
   journal = {PLoS ONE},
   title = {Classification of skin lesions using transfer learning and augmentation with Alex-net},
   volume = {14},
   year = {2019},
}
@article{Hekler2019,
   abstract = {Background: In recent studies, convolutional neural networks (CNNs) outperformed dermatologists in distinguishing dermoscopic images of melanoma and nevi. In these studies, dermatologists and artificial intelligence were considered as opponents. However, the combination of classifiers frequently yields superior results, both in machine learning and among humans. In this study, we investigated the potential benefit of combining human and artificial intelligence for skin cancer classification. Methods: Using 11,444 dermoscopic images, which were divided into five diagnostic categories, novel deep learning techniques were used to train a single CNN. Then, both 112 dermatologists of 13 German university hospitals and the trained CNN independently classified a set of 300 biopsy-verified skin lesions into those five classes. Taking into account the certainty of the decisions, the two independently determined diagnoses were combined to a new classifier with the help of a gradient boosting method. The primary end-point of the study was the correct classification of the images into five designated categories, whereas the secondary end-point was the correct classification of lesions as either benign or malignant (binary classification). Findings: Regarding the multiclass task, the combination of man and machine achieved an accuracy of 82.95%. This was 1.36% higher than the best of the two individual classifiers (81.59% achieved by the CNN). Owing to the class imbalance in the binary problem, sensitivity, but not accuracy, was examined and demonstrated to be superior (89%) to the best individual classifier (CNN with 86.1%). The specificity in the combined classifier decreased from 89.2% to 84%. However, at an equal sensitivity of 89%, the CNN achieved a specificity of only 81.5% Interpretation: Our findings indicate that the combination of human and artificial intelligence achieves superior results over the independent results of both of these systems.},
   author = {Achim Hekler and Jochen S. Utikal and Alexander H. Enk and Axel Hauschild and Michael Weichenthal and Roman C. Maron and Carola Berking and Sebastian Haferkamp and Joachim Klode and Dirk Schadendorf and Bastian Schilling and Tim Holland-Letz and Benjamin Izar and Christof von Kalle and Stefan Fröhling and Titus J. Brinker and Laurenz Schmitt and Wiebke K. Peitsch and Friederike Hoffmann and Jürgen C. Becker and Christina Drusio and Philipp Jansen and Georg Lodde and Stefanie Sammet and Wiebke Sondermann and Selma Ugurel and Jeannine Zader and Alexander Enk and Martin Salzmann and Sarah Schäfer and Knut Schäkel and Julia Winkler and Priscilla Wölbing and Hiba Asper and Ann Sophie Bohne and Victoria Brown and Bianca Burba and Sophia Deffaa and Cecilia Dietrich and Matthias Dietrich and Katharina Antonia Drerup and Friederike Egberts and Anna Sophie Erkens and Salim Greven and Viola Harde and Marion Jost and Merit Kaeding and Katharina Kosova and Stephan Lischner and Maria Maagk and Anna Laetitia Messinger and Malte Metzner and Rogina Motamedi and Ann Christine Rosenthal and Ulrich Seidl and Jana Stemmermann and Kaspar Torz and Juliana Giraldo Velez and Jennifer Haiduk and Mareike Alter and Claudia Bär and Paul Bergenthal and Anne Gerlach and Christian Holtorf and Ante Karoglan and Sophie Kindermann and Luise Kraas and Moritz Felcht and Maria R. Gaiser and Claus Detlev Klemke and Hjalmar Kurzen and Thomas Leibing and Verena Müller and Raphael R. Reinhard and Jochen Utikal and Franziska Winter and Laurie Eicher and Daniela Hartmann and Markus Heppt and Katharina Kilian and Sebastian Krammer and Diana Lill and Anne Charlotte Niesert and Eva Oppel and Elke Sattler and Sonja Senner and Jens Wallmichrath and Hans Wolff and Anja Gesierich and Tina Giner and Valerie Glutsch and Andreas Kerstan and Dagmar Presser and Philipp Schrüfer and Patrick Schummer and Ina Stolze and Judith Weber and Konstantin Drexler and Marion Mickler and Camila Toledo Stauner and Alexander Thiem},
   doi = {10.1016/j.ejca.2019.07.019},
   issn = {18790852},
   journal = {European Journal of Cancer},
   keywords = {Artificial intelligence,Deep learning,Melanoma,Skin cancer},
   pages = {114-121},
   pmid = {31518967},
   title = {Superior skin cancer classification by the combination of human and artificial intelligence},
   volume = {120},
   year = {2019},
}
@article{Clawson2007,
   abstract = {Malignant melanoma is the deadliest form of skin cancer and must be diagnosed and excised during its earliest stages. The development of computerised systems which accurately quantify features representative of this cancer aims to assist diagnosis and improve preoperative diagnostic accuracy. One clinical feature suggestive of malignancy is asymmetry, which considers lesion shape, colour distribution and texture. In this paper techniques for the detection of colour asymmetry are evaluated and a new method for visually displaying and quantifying colour asymmetry is proposed. Automatic induction methods and a neural network model are utilised to evaluate the diagnostic capability of our features and identify those of greatest relative importance. Results indicate that those features quantifying possible areas of regression are most indicative of colour asymmetry. © 2007 Crown Copyright.},
   author = {K. M. Clawson and P. J. Morrow and B. W. Scotney and D. J. McKenna and O. M. Dolan},
   doi = {10.1109/IMVIP.2007.15},
   isbn = {0769528872},
   journal = {International Machine Vision and Image Processing Conference, IMVIP 2007},
   pages = {75-82},
   title = {Computerised skin lesion surface analysis for pigment asymmetry quantification},
   year = {2007},
}
@article{Rajesh2017a,
   abstract = {Human Cancer is a standout amongest the most unsafe illnesses which is for the most part brought about by hereditary insecurity of various sub-atomic modifications. Among many types of human disease, skin tumour is the most widely recognized one. To recognize skin tumour at an early stage we will think about and break down them through different methods named as segmentation and feature extraction. Here, we center threatening melanoma skin disease, (because of the high grouping of Melanoma-Hier we offer our skin, in the dermis layer of the skin) location. In this, We utilized our ABCD govern dermoscopy innovation for harmful melanoma skin malignancy location. In this framework distinctive stride for melanoma skin injury portrayal i.e, to begin with, the Image Acquisition Technique, pre-processing, segmentation, characterize a component for skin Feature Selection decides sore portrayal, grouping strategies. In the Feature extraction by advanced picture preparing technique incorporates, Asymmetry recognition, Border Detection, Colour, and Diameter detection and furthermore we utilized LBP for extract the texture based features. Here we proposed the Back Propagation Neural Network to classify the benign or malignant stage.},
   author = {A. Rajesh},
   doi = {10.1109/ICEICE.2017.8191916},
   isbn = {9781509049967},
   journal = {Proceedings - 2017 IEEE International Conference on Electrical, Instrumentation and Communication Engineering, ICEICE 2017},
   pages = {1-8},
   title = {Classification of malignant melanoma and Benign Skin Lesion by using back propagation neural network and ABCD rule},
   volume = {2017-Decem},
   year = {2017},
}
@article{Celebi2014a,
   abstract = {Dermoscopy is a noninvasive skin imaging technique, which permits visualization of features of pigmented melanocytic neoplasms that are not discernable by examination with the naked eye. Color information is indispensable for the clinical diagnosis malignant melanoma, the most deadly form of skin cancer. For this reason, most of the currently accepted dermoscopic scoring systems either directly or indirectly incorporate color as a diagnostic criterion. For example, both the asymmetry, border, colors, and dermoscopic (ABCD) rule of dermoscopy and the more recent color, architecture, symmetry, and homogeneity (CASH) algorithm include the number of clinically significant colors in their calculation of malignancy scores. In this paper, we present a machine learning approach to the automated quantification of clinically significant colors in dermoscopy images. Given a true-color dermoscopy image with N colors, we first reduce the number of colors in this image to a small number K, i.e., K N, using the K-means clustering algorithm incorporating a spatial term. The optimal K value for the image is estimated separately using five commonly used cluster validity criteria. We then train a symbolic regression algorithm using the estimates given by these criteria, which are calculated on a set of 617 images. Finally, the mathematical equation given by the regression algorithm is used for two-class (benign versus malignant) classification. The proposed approach yields a sensitivity of 62% and a specificity of 76% on an independent test set of 297 images. © 2014 IEEE.},
   author = {M. Emre Celebi and Azaria Zornberg},
   doi = {10.1109/JSYST.2014.2313671},
   issn = {19379234},
   issue = {3},
   journal = {IEEE Systems Journal},
   keywords = {Clustering,dermoscopy,symbolic regression},
   pages = {980-984},
   title = {Automated quantification of clinically significant colors in dermoscopy images and its application to skin lesion classification},
   volume = {8},
   year = {2014},
}
@article{Hagerty2019a,
   abstract = {This paper presents an approach that combines conventional image processing with deep learning by fusing the features from the individual techniques. We hypothesize that the two techniques, with different error profiles, are synergistic. The conventional image processing arm uses three handcrafted biologically inspired image processing modules and one clinical information module. The image processing modules detect lesion features comparable to clinical dermoscopy information - atypical pigment network, color distribution, and blood vessels. The clinical module includes information submitted to the pathologist - patient age, gender, lesion location, size, and patient history. The deep learning arm utilizes knowledge transfer via a ResNet-50 network that is repurposed to predict the probability of melanoma classification. The classification scores of each individual module from both processing arms are then ensembled utilizing logistic regression to predict an overall melanoma probability. Using cross-validated results of melanoma classification measured by area under the receiver operator characteristic curve (AUC), classification accuracy of 0.94 was obtained for the fusion technique. In comparison, the ResNet-50 deep learning based classifier alone yields an AUC of 0.87 and conventional image processing based classifier yields an AUC of 0.90. Further study of fusion of conventional image processing techniques and deep learning is warranted.},
   author = {Jason R. Hagerty and R. Joe Stanley and Haidar A. Almubarak and Norsang Lama and Reda Kasmi and Peng Guo and Rhett J. Drugge and Harold S. Rabinovitz and Margaret Oliviero and William V. Stoecker},
   doi = {10.1109/JBHI.2019.2891049},
   issn = {21682208},
   issue = {4},
   journal = {IEEE Journal of Biomedical and Health Informatics},
   keywords = {Melanoma,classifier,deep learning,dermoscopy,transfer learning},
   pages = {1385-1391},
   title = {Deep Learning and Handcrafted Method Fusion: Higher Diagnostic Accuracy for Melanoma Dermoscopy Images},
   volume = {23},
   year = {2019},
}
@article{Ruiz-Castilla2019a,
   abstract = {Skin cancer is detected in skin lesions. The most common skin cancer is melanoma. Skin cancer is increasing in several parts of the world. Due to the above, it is important to work on the classification of melanomas, in order to support the possible detection of malignant melanomas that cause skin cancer. We use Convolutional Neural Networks (CNN) for the classification of melanomas. We use images available from International Skin Imaging Collaboration (ISIC). We created a repository of 1000 images and did training with a sequential CNN to obtain two categories: benign and malignant melanomas. In the first instance we obtained results of 94.89% accuracy and 82.25% in validation. In the second instance we created another repository of 600 images for the method that we propose that consists in adding metadata within the same pixel matrix of the image in each RGB layer. The image was shown with a band of colors at the bottom. We made training with the CNN using images with metadata and achieved the results: 98.39% of accuracy and 79% of validation. Therefore, we conclude that adding the metadata repeatedly to the pixel matrix of the image improves the results of the classification.},
   author = {José Sergio Ruiz-Castilla and Juan José Rangel-Cortes and Farid García-Lamont and Adrián Trueba-Espinosa},
   doi = {10.1007/978-3-030-26969-2_54},
   isbn = {9783030269685},
   issn = {16113349},
   journal = {CNN and Metadata for Classification of Benign and Malignant Melanomas},
   keywords = {Classification,Convolutional neural networks,Melanomas,Metadata,Prediction},
   pages = {569-579},
   title = {CNN and Metadata for Classification of Benign and Malignant Melanomas},
   volume = {11644 LNCS},
   year = {2019},
}
@article{Liu2013a,
   abstract = {Background Computer-assisted diagnosis (CAD) of malignant melanoma (MM) has been advocated to help clinicians to achieve a more objective and reliable assessment. However, conventional CAD systems examine only the features extracted from digital photographs of lesions. Failure to incorporate patients' personal information constrains the applicability in clinical settings. Objectives To develop a new CAD system to improve the performance of automatic diagnosis of melanoma, which, for the first time, incorporates digital features of lesions with important patient metadata into a learning process. Methods Thirty-two features were extracted from digital photographs to characterize skin lesions. Patients' personal information, such as age, gender and, lesion site, and their combinations, was quantified as metadata. The integration of digital features and metadata was realized through an extended Laplacian eigenmap, a dimensionality-reduction method grouping lesions with similar digital features and metadata into the same classes. Results The diagnosis reached 82·1% sensitivity and 86·1% specificity when only multidimensional digital features were used, but improved to 95·2% sensitivity and 91·0% specificity after metadata were incorporated appropriately. The proposed system achieves a level of sensitivity comparable with experienced dermatologists aided by conventional dermoscopes. This demonstrates the potential of our method for assisting clinicians in diagnosing melanoma, and the benefit it could provide to patients and hospitals by greatly reducing unnecessary excisions of benign naevi. Conclusions This paper proposes an enhanced CAD system incorporating clinical metadata into the learning process for automatic classification of melanoma. Results demonstrate that the additional metadata and the mechanism to incorporate them are useful for improving CAD of melanoma. What's already known about this topic? Computer-assisted diagnosis (CAD) of melanoma has been advocated to improve clinical diagnostic accuracy. Existing CAD systems can only partially simulate the procedure adopted by dermatologists in making a diagnosis. What does this study add? In addition to information on the individual lesion itself, patient metadata are, for the first time, incorporated to form a new CAD system for melanoma diagnosis. The integration of clinical metadata helps to improve the performance of automatic identification of melanoma. © 2013 British Association of Dermatologists.},
   author = {Z. Liu and J. Sun and M. Smith and L. Smith and R. Warr},
   doi = {10.1111/bjd.12550},
   issn = {00070963},
   issue = {5},
   journal = {British Journal of Dermatology},
   pages = {1034-1040},
   title = {Incorporating clinical metadata with digital image features for automated identification of cutaneous melanoma},
   volume = {169},
   year = {2013},
}
@article{Yan2019a,
   abstract = {We propose an attention-based method for melanoma recognition. The attention modules, which are learned together with other network parameters, estimate attention maps that highlight image regions of interest that are relevant to lesion classification. These attention maps provide a more interpretable output as opposed to only outputting a class label. Additionally, we propose to utilize prior information by regularizing attention maps with regions of interest (ROIs) (e.g.,Â lesion segmentation or dermoscopic features). Whenever such prior information is available, both the classification performance and the attention maps can be further refined. To our knowledge, we are the first to introduce an end-to-end trainable attention module with regularization for melanoma recognition. We provide both quantitative and qualitative results on public datasets to demonstrate the effectiveness of our method. The code is available at https://github.com/SaoYan/IPMI2019-AttnMel.},
   author = {Yiqi Yan and Jeremy Kawahara and Ghassan Hamarneh},
   doi = {10.1007/978-3-030-20351-1_62},
   isbn = {9783030203504},
   issn = {16113349},
   journal = {International Conference on Information Processing in Medical Imaging},
   pages = {793-804},
   title = {Melanoma Recognition via Visual Attention},
   volume = {11492 LNCS},
   year = {2019},
}
@article{Gurumoorthy2019,
   abstract = {Prototypical examples that best summarize and compactly represent an underlying complex data distribution, communicate meaningful insights to humans in domains where simple explanations are hard to extract. In this paper, we present algorithms with strong theoretical guarantees to mine these data sets and select prototypes, a.k.a. representatives that optimally describes them. Our work notably generalizes the recent work by Kim et al. (2016) where in addition to selecting prototypes, we also associate non-negative weights which are indicative of their importance. This extension provides a single coherent framework under which both prototypes and criticisms (i.e. outliers) can be found. Furthermore, our framework works for any symmetric positive definite kernel thus addressing one of the key open questions laid out in Kim et al. (2016). By establishing that our objective function enjoys a key property of that of weak submodularity, we present a fast ProtoDash algorithm and also derive approximation guarantees for the same. We demonstrate the efficacy of our method on diverse domains such as retail, digit recognition (MNIST) and on publicly available 40 health questionnaires obtained from the Center for Disease Control (CDC) website maintained by the US Dept. of Health. We validate the results quantitatively as well as qualitatively based on expert feedback and recently published scientific studies on public health, thus showcasing the power of our technique in providing actionability (for retail), utility (for MNIST), and insight (on CDC datasets), which arguably are the hallmarks of an effective interpretable machine learning method.},
   author = {Karthik S. Gurumoorthy and Amit Dhurandhar and Guillermo Cecchi and Charu Aggarwal},
   doi = {10.1109/ICDM.2019.00036},
   isbn = {9781728146034},
   issn = {15504786},
   journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
   keywords = {Data summarization,Outlier detection,Prototype selection,Submodularity},
   pages = {260-269},
   title = {Efficient data representation by selecting prototypes with importance weights},
   volume = {2019-Novem},
   year = {2019},
}
@article{Nie2016a,
   abstract = {Computed tomography (CT) is critical for various clinical applications, e.g., radiotherapy treatment planning and also PET attenuation correction. However, CT exposes radiation during CT imaging, which may cause side effects to patients. Compared to CT, magnetic resonance imaging (MRI) is much safer and does not involve any radiation. Therefore, recently researchers are greatly motivated to estimate CT image from its corresponding MR image of the same subject for the case of radiotherapy planning. In this paper, we propose a 3D deep learning based method to address this challenging problem. Specifically, a 3D fully convolutional neural network (FCN) is adopted to learn an endto-end nonlinear mapping from MR image to CT image. Compared to the conventional convolutional neural network (CNN), FCN generates structured output and can better preserve the neighborhood information in the predicted CT image. We have validated our method in a real pelvic CT/MRI dataset. Experimental results show that our method is accurate and robust for predicting CT image from MRI image, and also outperforms three state-of-the-art methods under comparison. In addition, the parameters, such as network depth and activation function, are extensively studied to give an insight for deep learning based regression tasks in our application.},
   author = {Dong Nie and Xiaohuan Cao and Yaozong Gao and Li Wang and Dinggang Shen},
   doi = {10.1007/978-3-319-46976-8_18},
   isbn = {9783319469751},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {170-178},
   title = {Estimating CT image from MRI data using 3D fully convolutional networks},
   volume = {10008 LNCS},
   year = {2016},
}
@article{Oktay2016,
   abstract = {3D cardiac MR imaging enables accurate analysis of cardiac morphology and physiology. However,due to the requirements for long acquisition and breath-hold,the clinical routine is still dominated by multi-slice 2D imaging,which hamper the visualization of anatomy and quantitative measurements as relatively thick slices are acquired. As a solution,we propose a novel image super-resolution (SR) approach that is based on a residual convolutional neural network (CNN) model. It reconstructs high resolution 3D volumes from 2D image stacks for more accurate image analysis. The proposed model allows the use of multiple input data acquired from different viewing planes for improved performance. Experimental results on 1233 cardiac short and long-axis MR image stacks show that the CNN model outperforms state-of-the-art SR methods in terms of image quality while being computationally efficient. Also,we show that image segmentation and motion tracking benefits more from SR-CNN when it is used as an initial upscaling method than conventional interpolation methods for the subsequent analysis.},
   author = {Ozan Oktay and Wenjia Bai and Matthew Lee and Ricardo Guerrero and Konstantinos Kamnitsas and Jose Caballero and Antonio De Marvao and Stuart Cook and Declan O’Regan and Daniel Rueckert},
   doi = {10.1007/978-3-319-46726-9_29},
   isbn = {9783319467252},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {246-254},
   title = {Multi-input cardiac image super-resolution using convolutional neural networks},
   volume = {9902 LNCS},
   year = {2016},
}
@article{Satheesha2017,
   abstract = {Melanoma mortality rates are the highest amongst skin cancer patients. Melanoma is life threating when it grows beyond the dermis of the skin. Hence, depth is an important factor to diagnose melanoma. This paper introduces a non-invasive computerized dermoscopy system that considers the estimated depth of skin lesions for diagnosis. A 3-D skin lesion reconstruction technique using the estimated depth obtained from regular dermoscopic images is presented. On basis of the 3-D reconstruction, depth and 3-D shape features are extracted. In addition to 3-D features, regular color, texture, and 2-D shape features are also extracted. Feature extraction is critical to achieve accurate results. Apart from melanoma, in-situ melanoma the proposed system is designed to diagnose basal cell carcinoma, blue nevus, dermatofibroma, haemangioma, seborrhoeic keratosis, and normal mole lesions. For experimental evaluations, the PH2, ISIC: Melanoma Project, and ATLAS dermoscopy data sets is considered. Different feature set combinations is considered and performance is evaluated. Significant performance improvement is reported the post inclusion of estimated depth and 3-D features. The good classification scores of sensitivity = 96%, specificity = 97% on PH2 data set and sensitivity = 98%, specificity = 99% on the ATLAS data set is achieved. Experiments conducted to estimate tumor depth from 3-D lesion reconstruction is presented. Experimental results achieved prove that the proposed computerized dermoscopy system is efficient and can be used to diagnose varied skin lesion dermoscopy images.},
   author = {T. Y. Satheesha and D. Satyanarayana and M. N.Giri Prasad and Kashyap D. Dhruve},
   doi = {10.1109/JTEHM.2017.2648797},
   issn = {21682372},
   journal = {IEEE Journal of Translational Engineering in Health and Medicine},
   keywords = {3D features and tumor depth estimation,3D lesion reconstruction,Melanoma in-situ,classification,skin lesions},
   title = {Melanoma Is Skin Deep: A 3D Reconstruction Technique for Computerized Dermoscopic Skin Lesion Classification},
   volume = {5},
   year = {2017},
}
@article{Hu2019a,
   abstract = {Bag-of-features (BoF) model based melanoma classification methods can effectively assist dermatologists to diagnose skin diseases. Codebook learning is a key step in the BoF model and the k-means clustering algorithm is often used to learn a codebook. However, the cluster centers generated by k-means algorithm are irresistibly attracted to the denser regions. This produces a suboptimal codebook in which most of the clusters are located in dense regions and a few are in sparse regions. Therefore, this can easily affect the classification accuracy. In this paper, we develop a novel methodology for classifying skin lesions. Firstly, we propose a new codebook learning algorithm based on feature similarity measurement (FSM) to effectively quantify the original features of melanomas. We utilize the combination of the linearly independent and linear prediction (LP) algorithms to measure feature similarity. Especially, the codewords learned by the proposed FSM algorithm are not affected by the density of samples. Therefore, a more discriminating BoF histogram for the melanoma classification is achieved. Secondly, we propose a melanoma classification method based on the FSM codebook learning algorithm. In particular, we adopt the BoF histogram fusion strategy of different feature descriptors, i.e., RGB color histogram and scale-invariant feature transform (SIFT). Finally, the experimental results show that the proposed melanoma classification method outperforms some state-of-the-art methods in terms of classification accuracy and efficiency. The results also show the performance of the proposed method is greatly improved by the use of the proposed codebook learning algorithm.},
   author = {Kai Hu and Xiaorui Niu and Si Liu and Yuan Zhang and Chunhong Cao and Fen Xiao and Wanchun Yang and Xieping Gao},
   doi = {10.1016/j.bspc.2019.02.018},
   issn = {17468108},
   journal = {Biomedical Signal Processing and Control},
   keywords = {Bag of features,Codebook learning,Feature similarity measurement,Melanoma classification},
   pages = {200-209},
   title = {Classification of melanoma based on feature similarity measurement for codebook learning in the bag-of-features model},
   volume = {51},
   year = {2019},
}
@article{Moher2015,
   author = {D Moher and L Shamseer and M Clarke and D Ghersi and A Liberati and M Petticrew},
   doi = {10.1186/2046-4053-4-1},
   journal = {Systematic Reviews},
   title = {PRISMA-P Group. Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P)},
   volume = {4},
   url = {http://dx.doi.org/10.1186/2046-4053-4-1},
   year = {2015},
}
@article{Chen2013,
   abstract = {Desmoplastic melanoma (DM) is a variant of spindle cell melanoma typically found on chronically sun-damaged skin of older individuals. Early diagnosis can be challenging because it is often amelanotic and has a predominantly dermal component. DM can be difficult to diagnose not only clinically but also histologically, and can be mistaken for a variety of benign and malignant nonmelanocytic spindle cell tumors when viewed on prepared histopathology slides. Pathologists have observed that DMs can manifest significant variation with respect to the extent of intratumoral cellularity, fibrosis, and/or perineural invasion. Furthermore, some tumors present with a pure desmoplastic invasive component (>90%) while other tumors display mixed features of DM and nondesmoplastic melanoma. This has led to the separation of DM into 2 histologic subtypes, pure and mixed. With a focus on the distinction between pure and mixed DM, this review will detail what is currently known about the diagnostic features of DM, discuss risk and prognostic factors, and examine the current literature on disease progression and management. © 2012 by the American Academy of Dermatology, Inc.},
   author = {Lucy L. Chen and Natalia Jaimes and Christopher A. Barker and Klaus J. Busam and Ashfaq A. Marghoob},
   doi = {10.1016/j.jaad.2012.10.041},
   issn = {01909622},
   issue = {5},
   journal = {Journal of the American Academy of Dermatology},
   keywords = {dermoscopy,desmoplastic melanoma,melanoma,pathology,prognosis,risk factors,sentinel lymph node biopsy},
   pages = {825-833},
   title = {Desmoplastic melanoma: A review},
   volume = {68},
   year = {2013},
}
@article{Cognetta1994,
   abstract = {Background: The difficulties in accurately assessing pigmented skin lesions are ever present in practice. The recently described ABCD rule of dermatoscopy (skin surface microscopy at ×10 magnification), based on the criteria asymmetry (A), border (B), color (C), and differential structure (D), improved diagnostic accuracy when applied retrospectively to clinical slides. Objective: A study was designed to evaluate the prospective value of the ABCD rule of dermatoscopy in melanocytic lesions. Methods: In 172 melanocytic pigmented skin lesions, the criteria of the ABCD rule of dermatoscopy were analyzed with a semiquantitative scoring system before excision. Results: According to the retrospectively determined threshold, tumors with a score higher than 5.45 (64/69 melanomas [92.8%]) were classified as malignant, whereas lesions with a lower score were considered as benign (93/103 melanocytic nevi [90.3%]). Negative predictive value for melanoma (True-Negative ÷ [True-Negative + False-Negative]) was 9 5.8%, whereas positive predictive value (True-Positive ÷ [True-Positive + False-Positive]) was 85.3%. Diagnostic accuracy for melanoma (True-Positive ÷ [True-Positive + False- Positive + False-Negative]) was 80.0%, compared with 64.4% by the naked eye. Melanoma showed a mean final dermatoscopy score of 6.79 (SD, ± 0.92), significantly differing from melanocytic nevi (mean score, 4.27 ± 0.99; p <0.01, U test). Conclusion: The ABCD rule can be easily learned and rapidly calculated, and has proven to be reliable. It should be routinely applied to all equivocal pigmented skin lesions to reach a more objective and reproducible diagnosis and to obtain this assessment preoperatively. © 1994, American Academy of Dermatology, Inc.. All rights reserved.},
   author = {Armand B. Cognetta and Thomas Vogt and Michael Landthaler and Otto Braun-Falco and Gerd Plewig},
   doi = {10.1016/S0190-9622(94)70061-3},
   issn = {01909622},
   issue = {4},
   journal = {Journal of the American Academy of Dermatology},
   pages = {551-559},
   pmid = {8157780},
   title = {The ABCD rule of dermatoscopy: High prospective value in the diagnosis of doubtful melanocytic skin lesions},
   volume = {30},
   year = {1994},
}
@article{Dourmishev2013,
   abstract = {Basal cell carcinoma (BCC) is the most common paraneoplastic disease among human neoplasms. The tumor affects mainly photoexposed areas, most often in the head and seldom appears on genitalia and perigenital region. BCC progresses slowly and metastases are found in less than 0.5% of the cases; however, a considerable local destruction and mutilation could be observed when treatment is neglected or inadequate. Different variants as nodular, cystic, micronodular, superficial, pigment BCC are described in literature and the differential diagnosis in some cases could be difficult. The staging of BCC is made according to Tumor, Node, Metastasis (TNM) classification and is essential for performing the adequate treatment. Numerous therapeutic methods established for treatment of BCC, having their advantages or disadvantages, do not absolutely dissolve the risk of relapses. The early diagnostics based on the good knowledge and timely organized and adequate treatment is a precondition for better prognosis. Despite the slow progress and numerous therapeutic methods, the basal cell carcinoma should not be underestimated.},
   author = {LyubomirA Dourmishev and Darena Rusinova and Ivan Botev},
   doi = {10.4103/2229-5178.105456},
   issn = {2229-5178},
   issue = {1},
   journal = {Indian Dermatology Online Journal},
   pages = {12},
   pmid = {23439912},
   title = {Clinical variants, stages, and management of basal cell carcinoma},
   volume = {4},
   year = {2013},
}
@article{Fusco2015,
   author = {Nicola Fusco and Gianluca Lopez and Umberto Gianelli},
   doi = {10.1177/1066896915593802},
   issue = {6},
   journal = {International Journal of Surgical Pathology},
   title = {Basal Cell Carcinoma and Seborrheic Keratosis: When Opposites Attract.},
   volume = {23},
   url = {https://www.researchgate.net/publication/279729943_Basal_Cell_Carcinoma_and_Seborrheic_Keratosis_When_Opposites_Attract},
   year = {2015},
}
@article{Braun2015,
   author = {Ralph P. Braun and Ashfaq Marghoob},
   doi = {10.1001/jamadermatol.2014.4714},
   issn = {21686068},
   issue = {4},
   journal = {JAMA Dermatology},
   pages = {456-457},
   title = {High-dynamic-range dermoscopy imaging and diagnosis of hypopigmented skin cancers},
   volume = {151},
   year = {2015},
}
@article{Pillay2019a,
   abstract = {Automatic diagnosis of skin cancer images is especially difficult in medical image processing. Moreover, proper segmentation is crucial for the partitioning of growths from the skin, which can aid in the differentiation between melanoma and benign skin lesions. To address these issues, this research work investigates the widely used ABCD rule (Asymmetry, Border Irregularity, Colour and Diameter) on macroscopic images and the Graph-Cut segmentation technique as it demonstrates capabilities for handling extremely textured, noisy and colour images which are present in macroscopic images. The accuracy rates achieved by the proposed model with the use of the TDS (Total Dermoscopy Score) classifier is 73,529%, SVM is 75,294% and KNN classifier is 74,706%.},
   author = {Verosha Pillay and Serestina Viriri},
   doi = {10.1109/ICTAS.2019.8703611},
   isbn = {9781538673652},
   journal = {2019 Conference on Information Communications Technology and Society, ICTAS 2019},
   title = {Skin cancer detection from macroscopic images},
   year = {2019},
}
@article{Sato2013,
   abstract = {Objective: To facilitate identification of dermoscopic structures by new dermoscopy trainees using image conversion. Design: Observational study. Setting: Dermatology clinic. Materials: Dermoscopy images of 4 melanocytic nevi, 1 malignant melanoma, 1 seborrheic keratosis, 1 basal cell carcinoma and 1 Bowen’s disease. Intervention: Comparative analysis of dermoscopic images by high dynamic range (HDR) image conversion and original images. Main outcome measures: Disease-specific dermoscopic structures, including typical pigment network, regular dots/globules, regular streaks, and parallel furrow pattern in melanocytic nevi; atypical pigment network, peripheral dots/globules, blue-whitish veil in melanoma; comedo-like openings, multiple milia-like cysts, and fissures/ridges in seborrheic keratosis; arborizing vessels, leaf-like areas, multiple blue-gray globules, and spoke-wheel areas in basal cell carcinoma; red-blue lacunae in vascular lesions; and dotted vessels, glomerular vessels, and scaling in Bowen’s disease. Results: The use of HDR images improved detection with clear contrast and visualization of dermoscopic structures even in structureless areas. Conclusion: The results suggest that HDR image conversion facilitates identification of dermoscopic structures by new dermoscopy trainees.},
   author = {Toshitsugu Sato and Masaru Tanaka},
   issue = {2},
   journal = {The Japanese Journal of Dermotology},
   pages = {121-131},
   title = {Improved detection of dermoscopic structures by high dynamic range image conversion},
   volume = {123},
   url = {https://www.jstage.jst.go.jp/article/dermatol/123/2/123_121/_article},
   year = {2013},
}
@article{Min2011,
   abstract = {Multiple images with different exposures are used to produce a high dynamic range (HDR) image. Sometimes high-sensitivity setting is needed for capturing images in low light condition as in an indoor room. However, current digital cameras do not produce a high-quality HDR image when noise occurs in low light condition or high-sensitivity setting. In this paper, we propose a noise reduction method in generating HDR images using a set of low dynamic range (LDR) images with different exposures, where ghost artifacts are effectively removed by image registration and local motion information. In high-sensitivity setting, motion information is used in generating a HDR image. We analyze the characteristics of the proposed method and compare the performance of the proposed and existing HDR image generation methods, in which Reinhard et al.'s global tone mapping method is used for displaying the final HDR images. Experiments with several sets of test LDR images with different exposures show that the proposed method gives better performance than existing methods in terms of visual quality and computation time. © 2011 Springer-Verlag London Limited.},
   author = {Tae Hong Min and Rae Hong Park and Soon Keun Chang},
   doi = {10.1007/s11760-010-0203-7},
   issn = {18631703},
   issue = {3},
   journal = {Signal, Image and Video Processing},
   keywords = {Ghost removal,High dynamic range image,Image registration,Motion detection,Noise reduction,Radiance map generation},
   pages = {315-328},
   title = {Noise reduction in high dynamic range images},
   volume = {5},
   year = {2011},
}
@article{Sato2014,
   abstract = {A 48-year-old woman presented with a 3 mm, pigmented macule at her first visit to our clinic. The macule, which showed complete symmetry and a typical network, was tentatively diagnosed as a Clark nevus; a 6-month follow-up was recommended, and the patient returned 7 months later. At the second visit, the lesion had enlarged to a diameter of 5 mm, and dermoscopy revealed that it had maintained its typical pigment network. At this point, evidence-based monitoring would have led to excision but the decision was made to continue monitoring. Owing to poor compliance, the patient went another 2 years without follow-up. When we assess small lesions, such as this, the usefulness of dermoscopy is apparent. Additionally, we examined the benefits and drawbacks of high dynamic range (HDR) conversion of the dermoscopy images and their helpfulness for inspecting small lesions. Although the delicate structures present in the lesion can be recognized by a dermoscopy expert and HDR image conversion has a capacity to highlight important structures, there is also a risk that HDR image conversion may mask some of the structural changes. However, a comparison of the original dermoscopy images with the HDR-converted images provides newly trained dermoscopists the opportunity to recognize new findings and to distinguish the differences in the findings between both the types of images. Therefore, such comparisons might be useful for obtaining an accurate diagnosis by using dermoscopy and HDR image conversion.},
   author = {Toshitsugu Sato and Masaru Tanaka},
   doi = {10.5826/dpc.0404a10},
   issn = {2160-9381},
   issue = {5},
   journal = {Dermatology Practical & Conceptual},
   title = {A case of a superficial spreading melanoma in situ diagnosed via digital dermoscopic monitoring with high dynamic range conversion},
   volume = {4},
   year = {2014},
}
@misc{Hoffman2014,
   author = {Matthew Hoffman},
   journal = {WebMD},
   pages = {1-4},
   title = {Picture of the Skin},
   url = {http://www.webmd.com/skin-problems-and-treatments/picture-of-the-skin},
   year = {2014},
}
@article{Bsoul2004,
   abstract = {Core Messages: Basal cell carcinoma (BCC) is the most common human cancer. The most significant environmental carcinogen for BCC is ultraviolet light (UVL) exposure. Clinical pathological correlation is essential in choosing the appropriate treatment for the various subtypes of BCC. Untreated BCC or inappropriately managed BCC can cause significant morbidity and even mortality. The mainstay of treatment has focused on the total removal (excision) or mechanical destruction of the tumor. New treatment modalities include immune modulators, topical photodynamic therapy (PDT), and drugs targeting genetic defects. Education on skin cancer prevention should target all age groups. © 2010 Springer-Verlag Berlin Heidelberg.},
   author = {Manisha J. Patel and Phillip M. Williford and Stephen Shumack},
   doi = {10.1007/978-3-540-79347-2_3},
   isbn = {9783540793465},
   issn = {0033-6572},
   issue = {3},
   journal = {Managing Skin Cancer},
   keywords = {Basal Cell,Carcinoma,Diagnosis,Differential,Facial Neoplasms,Humans,Mohs Surgery,Skin Neoplasms,Sunlight},
   pages = {37-49},
   title = {Basal cell carcinoma},
   volume = {35},
   year = {2010},
}
@article{Saito2010,
   abstract = {There is persuasive clinical and experimental evidence that macrophages promote cancer initiation and malignant progression. During tumor initiation they create an inflammatory environment that is mutagenic and which promotes growth. As tumors progress to malignancy, macrophages stimulate angiogenesis, enhance tumor cell migration, invasion, and suppress anti-tumor immunity. At metastatic sites macrophages prepare the target tissue for arrival of tumor cells and then a different subpopulation of macrophages promotes tumor cell extravasation, survival, and subsequent growth. Specialized subpopulations of macrophages may represent important new therapeutic targets.},
   author = {Toshiro Saito and Junichi Sadoshima},
   doi = {10.1161/CIRCRESAHA.116.303790.The},
   isbn = {0324141122},
   issn = {1527-5418},
   issue = {8},
   journal = {Cell},
   keywords = {autophagy,mitophagy,parkin,pink1},
   pages = {1477-1490},
   pmid = {24655651},
   title = {applying lean methodologies reduces ED},
   volume = {116},
   year = {2016},
}
@article{VA2003,
   author = {Victor A. Neel and Arthur J. Sober},
   journal = {Holland-Frei Cancer Medicine. 6th edition. Hamilton},
   title = {Tumors Arising from Dermis},
   url = {http://www.ncbi.nlm.nih.gov/books/NBK13857/},
   year = {2003},
}
@article{Yousef2018,
   abstract = {Skin is the largest organ in the body. It covers the body's entire external surface, serving as a first-order barrier against pathogens, UV light, and chemicals, and provides a mechanical barrier to injury. It also regulates temperature and amount of water released into the environment. Skin Thickness: Hairless skin of the palms of the hands and soles of the feet is thick skin, referring to thickness of epidermis. The thickest skin based on the thickness of the dermis is on the upper portion of the back. But it is considered “thin skin” histologically because of epidermal thickness. Layers of Epidermis: Stratum basale aka stratum germinativum – deepest layer, separated from dermis by basement membrane (basal lamina) and attached by hemidesmosomes. Cells are cuboidal to columnar and are mitotically active stem cells. Stratum spinosum aka prickle cell layer - irregular, polyhedral cells with processes (“spines”) that extend outward and contact neighboring cells by desmosomes. Stratum granulosum - diamond shaped cells which contain keratohyalin granules; aggregates keratin filaments present in cornified cells. Stratum lucidum - if present, thin clear layer consisting of eleidin (transformation product of keratohyalin); usually seen in thick skin only. Stratum corneum - outermost layer, made up of keratin and horny scales which were once living cells; dead cells known as squamous (anucleate); layer which varies most in thickness, especially thick in callused skin. Cells of the Epidermis: Keratinocytes. Melanocytes. Langerhans’ cells. Merkel’s cell. Keratinocytes: Predominate cell type of epidermis. Originate in basal layer. Produce keratin. Formation of epidermal water barrier. Melanocytes: Derived from neural crest cells. Manufacture melanin. Melanin mainly found in stratum basale and is protective against UV radiation; melanocytes found between cells of stratum basale. Produced by oxidation of tyrosine to 3,4–DOPA by tyrosinase and then there is the transformation of DOPA into melanin. Melanocytes send out long processes extending between epidermal cells, contacting them. Melanin granules from melanocytes are transferred via the long processes to cytoplasm of basal keratinocyte. Melanin transferred to neighboring keratinocytes by “pigment donation”; involves phagocytosis of tips of melanocyte processes by keratinocytes. Langerhans’ Cells: Dendritic, antigen-presenting, need special stains to visualize in stratum spinosum (mainly). Mesenchymal origin, derived from stem cells of bone marrow – part of mononuclear-phagocytic system. Birbeck granules. Express MHC I and MHC II molecules. Uptake antigens in skin and transport to lymph node. Merkel Cells: Modified epidermal cells in stratum basale. Sensory function for fine-touch, most populous in fingertips. Bound to adjoining keratinocytes by desmosomes and have intermediate keratin filaments. Dermis It consists of two layers of connective tissue which merge together, no clear demarcation. Papillary layer - Outer layer, thinner, composed of loose connective tissue and contacts epidermis. Reticular layer - Deeper layer, thicker, less cellular, and consists of dense connective tissue/ bundles of collagen fibers. The dermis houses the skin appendages (sweat glands and hairs), many sensory neurons, and blood vessels. Hypodermis Also called subcutaneous fascia, Deepest layer of skin. Contains adipose lobules along with some skin appendages (hair follicles), sensory neurons, and blood vessels.},
   author = {Hani Yousef and Sandeep Sharma},
   journal = {StatPearls},
   pmid = {29262154},
   title = {Anatomy, Skin (Integument), Epidermis},
   url = {http://www.ncbi.nlm.nih.gov/pubmed/29262154},
   year = {2018},
}
@article{Jensen2015,
   author = {J. Daniel Jensen and Boni E. Elewski},
   issn = {19412789},
   issue = {2},
   journal = {Journal of Clinical and Aesthetic Dermatology},
   pages = {15},
   pmid = {25741397},
   title = {The ABCDEF rule: Combining the 'ABCDE rule' and the "ugly duckling sign" in an effort to improve patient self-screening examinations},
   volume = {8},
   year = {2015},
}
@article{Pizzichetta2004,
   abstract = {Background: Amelanotic malignant melanoma is a subtype of cutaneous melanoma with little or no pigment on visual inspection. It may mimic benign and malignant variants of both melanocytic and nonmelanocytic lesions. Objectives: To evaluate whether dermoscopy is also a useful technique for the diagnosis of amelanotic/hypomelanotic melanoma (AHM). Methods: We conducted a retrospective clinical study of 151 amelanotic/hypomelanotic skin lesions from 151 patients with a mean age of 47 years (± 17.5 SD). Digitized images of amelanotic/hypomelanotic skin lesions were converted to JPEG format and sent by e-mail from the five participating centres. Lesions included 55 amelanotic/hypomelanotic nonmelanocytic lesions (AHNML), 52 amelanotic/ hypomelanotic benign melanocytic lesions (AHBML), and 44 AHM, 10 (23%) of which were nonpigmented, truly amelanotic melanomas (AM). The 44 AHM lesions were divided into thin melanomas (TnM) ≤ 1 mm (29 cases) and thick melanomas (TkM) > 1 mm (15 cases), according to the Breslow index. Five clinical features (elevation, ulceration, shape, borders and colour) as well as 10 dermoscopic criteria (pigment network, pigmentation, streaks, dots/globules, blue-whitish veil, regression structures, hypopigmentation, leaf-like areas, multiple grey-bluish globules, central white patch) and eight vascular patterns (comma, arborizing, hairpin, dotted, linear irregular, dotted and linear irregular vessels, and milky-red areas) were evaluated in order to achieve clinical and dermoscopic diagnoses. Statistical analyses were performed with the χ2-test and Fisher's exact test, when appropriate. Results: The most frequent and significant clinical features for TnM and TkM were asymmetry and ulceration (the latter only for TkM) compared with AHBML. Irregular dots/globules (62% vs. 35%; P ≤ 0.03), regression structures (48% vs. 27%; P ≤ 0.03), irregular pigmentation (41% vs. 11%; P ≤ 0.03) and blue-whitish veil (10% vs. 0%; P ≤ 0.03) were the most relevant dermoscopic criteria for TnM in comparison with AHBML. TkM differed significantly from AHBML in frequency of occurrence of irregular pigmentation (87% vs. 11%; P ≤ 0.03), irregular dots/globules (73% vs. 35%; P ≤ 0.03), regression structures (67% vs. 27%; P ≤ 0.03), blue-whitish veil (27% vs. 0%; P ≤ 0.03) and hypopigmentation (13% vs. 55%; P ≤ 0.03). Linear irregular vessels and the combination of dotted and linear irregular vessels associated with TnM and TkM were not found in our cases of AHBML and were only rarely seen in AHNML (3.6% and 1.8%, respectively). Moreover, TkM differed significantly from AHBML and TnM in frequency of occurrence of milky-red areas (93% vs. 17%; P ≤ 0.03 and 93% vs. 31%; P ≤ 0.01, respectively). The dermoscopic diagnosis of melanoma had a higher sensitivity and specificity than the clinical diagnosis (89% and 96% vs. 65% and 88%, respectively). With the limitation of the small number of cases, vascular patterns were the only dermoscopic criteria for 'truly' AM. In the 10 cases of 'truly' AM, we found milky-red areas in more than half of the cases (six of 10), dotted vessels in four, hairpin vessels in two, linear irregular vessels in two, dotted and linear irregular vessels in two. Conclusions: Because dermoscopy uses criteria reflecting pigmentation (irregular pigmentation and irregular dots/globules) and vascular patterns, it is a useful technique not only for pigmented melanoma but also for hypomelanotic melanoma. In 'truly' AM, vascular patterns alone may not be sufficient to diagnose melanoma. A combined approach with the clinical information should help in the detection of 'truly' AM.},
   author = {M. A. Pizzichetta and R. Talamini and I. Stanganelli and P. Puddu and R. Bono and G. Argenziano and A. Veronesi and G. Trevisan and H. Rabinovitz and H. P. Soyer},
   doi = {10.1111/j.1365-2133.2004.05928.x},
   issn = {00070963},
   issue = {6},
   journal = {British Journal of Dermatology},
   keywords = {Amelanotic melanoma,Dermatoscopy,Dermoscopy,Epiluminescence microscopy,Melanocytic skin lesion,Nonmelanocytic skin lesions},
   pages = {1117-1124},
   title = {Amelanotic/hypomelanotic melanoma: Clinical and dermoscopic features},
   volume = {150},
   year = {2004},
}
@article{Damsky2011,
   abstract = {Metastasis accounts for the vast majority of morbidity and mortality associated with melanoma. Evidence suggests melanoma has a predilection for metastasis to particular organs. Experimental analyses have begun to shed light on the mechanisms regulating melanoma metastasis and organ specificity, but these analyses are complicated by observations of metastatic dormancy and dissemination of melanocytes that are not yet fully malignant. Additionally, tumor extrinsic factors in the microenvironment, both at the site of the primary tumor and the site of metastasis, play important roles in mediating the metastatic process. As metastasis research moves forward, paradigms explaining melanoma metastasis as a step-wise process must also reflect the temporal complexity and heterogeneity in progression of this disease. Genetic drivers of melanoma as well as extrinsic regulators of disease spread, particularly those that mediate metastasis to specific organs, must also be incorporated into newer models of melanoma metastasis. © 2010 by the authors; licensee MDPI, Basel, Switzerland.},
   author = {William E. Damsky and Lara E. Rosenbaum and Marcus Bosenberg},
   doi = {10.3390/cancers3010126},
   issn = {20726694},
   issue = {1},
   journal = {Cancers},
   keywords = {Melanoma,Metastasis,Metastatic dormancy,Organ-specific,Pre-malignant dissemination},
   pages = {126-163},
   title = {Decoding melanoma metastasis},
   volume = {3},
   year = {2011},
}
@article{Zhang2019,
   abstract = {This paper aims to quantitatively explain the rationales of each prediction that is made by a pre-trained convolutional neural network (CNN). We propose to learn a decision tree, which clarifies the specific reason for each prediction made by the CNN at the semantic level. I.e., the decision tree decomposes feature representations in high conv-layers of the CNN into elementary concepts of object parts. In this way, the decision tree tells people which object parts activate which filters for the prediction and how much each object part contributes to the prediction score. Such semantic and quantitative explanations for CNN predictions have specific values beyond the traditional pixel-level analysis of CNNs. More specifically, our method mines all potential decision modes of the CNN, where each mode represents a typical case of how the CNN uses object parts for prediction. The decision tree organizes all potential decision modes in a coarse-to-fine manner to explain CNN predictions at different fine-grained levels. Experiments have demonstrated the effectiveness of the proposed method.},
   author = {Quanshi Zhang and Yu Yang and Haotian Ma and Ying Nian Wu},
   doi = {10.1109/CVPR.2019.00642},
   isbn = {9781728132938},
   issn = {10636919},
   journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   keywords = {Deep Learning,Grouping and Shape,Others,Representation Learning,Segmentation,Statistical Learn,Visual Reasoning},
   pages = {6254-6263},
   title = {Interpreting cnns via decision trees},
   volume = {2019-June},
   year = {2019},
}
@article{Lundberg2017,
   abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
   author = {Scott M. Lundberg and Su In Lee},
   issn = {10495258},
   journal = {Advances in Neural Information Processing Systems},
   pages = {4766-4775},
   title = {A unified approach to interpreting model predictions},
   volume = {2017-Decem},
   year = {2017},
}
@article{Lundberg,
   abstract = {Tree-based machine learning models such as random forests, decision trees, and gradient boosted trees are the most popular non-linear predictive models used in practice today, yet comparatively little attention has been paid to explaining their predictions. Here we significantly improve the interpretability of tree-based models through three main contributions: 1) The first polynomial time algorithm to compute optimal explanations based on game theory. 2) A new type of explanation that directly measures local feature interaction effects. 3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to i) identify high magnitude but low frequency non-linear mortality risk factors in the general US population, ii) highlight distinct population sub-groups with shared risk characteristics, iii) identify non-linear interaction effects among risk factors for chronic kidney disease, and iv) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model's performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
   author = {Scott M. Lundberg and Gabriel Erion and Hugh Chen and Alex DeGrave and Jordan M. Prutkin and Bala Nair and Ronit Katz and Jonathan Himmelfarb and Nisha Bansal and Su-In Lee},
   doi = {10.1038/s42256-019-0138-9},
   issue = {1},
   journal = {Nature Machine Intelligence},
   pages = {56-67},
   title = {From local explanations to global understanding with explainable AI for trees},
   volume = {2},
   url = {http://arxiv.org/abs/1905.04610},
   year = {2020},
}
@article{Montavon2017,
   abstract = {Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets.},
   author = {Grégoire Montavon and Sebastian Lapuschkin and Alexander Binder and Wojciech Samek and Klaus Robert Müller},
   doi = {10.1016/j.patcog.2016.11.008},
   issn = {00313203},
   journal = {Pattern Recognition},
   keywords = {Deep neural networks,Heatmapping,Image recognition,Relevance propagation,Taylor decomposition},
   pages = {211-222},
   title = {Explaining nonlinear classification decisions with deep Taylor decomposition},
   volume = {65},
   year = {2017},
}
@article{Nguyen2015,
   abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between com- puter and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the- art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neu- ral networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possi- ble to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling ex- amples). Our results shed light on interesting differences between human vision and current DNNs, and raise ques- tions about the generality of DNN computer vision},
   author = {Anh Nguyen and Jason Yosinski and Jeff Clune},
   doi = {10.1109/CVPR.2015.7298640},
   isbn = {9781467369640},
   issn = {1875-7855},
   journal = {Computer Vision and Pattern Recognition, 2015 IEEE Conference on},
   pages = {427-436},
   pmid = {24309266},
   title = {Deep Neural Networks are Easily Fooled},
   year = {2015},
}
@article{Li2018,
   abstract = {This letter reports on WaterGAN, a generative adversarial network (GAN) for generating realistic underwater images from in-air image and depth pairings in an unsupervised pipeline used for color correction of monocular underwater images. Cameras onboard autonomous and remotely operated vehicles can capture high-resolution images to map the seafloor; however, underwater image formation is subject to the complex process of light propagation through the water column. The raw images retrieved are characteristically different than images taken in air due to effects, such as absorption and scattering, which cause attenuation of light at different rates for different wavelengths. While this physical process is well described theoretically, the model depends on many parameters intrinsic to the water column as well as the structure of the scene. These factors make recovery of these parameters difficult without simplifying assumptions or field calibration; hence, restoration of underwater images is a nontrivial problem. Deep learning has demonstrated great success in modeling complex nonlinear systems but requires a large amount of training data, which is difficult to compile in deep sea environments. Using WaterGAN, we generate a large training dataset of corresponding depth, in-air color images, and realistic underwater images. These data serve as input to a two-stage network for color correction of monocular underwater images. Our proposed pipeline is validated with testing on real data collected from both a pure water test tank and from underwater surveys collected in the field. Source code, sample datasets, and pretrained models are made publicly available.},
   author = {Jie Li and Katherine A. Skinner and Ryan M. Eustice and Matthew Johnson-Roberson},
   doi = {10.1109/LRA.2017.2730363},
   issn = {23773766},
   issue = {1},
   journal = {IEEE Robotics and Automation Letters},
   keywords = {Marine robotics,visual learning},
   pages = {387-394},
   title = {WaterGAN: Unsupervised generative network to enable real-time color correction of monocular underwater images},
   volume = {3},
   year = {2018},
}
@article{Zhou2018,
   abstract = {Lighting estimation from faces is an important task and has applications in many areas such as image editing, intrinsic image decomposition, and image forgery detection. We propose to train a deep Convolutional Neural Network (CNN) to regress lighting parameters from a single face image. Lacking massive ground truth lighting labels for face images in the wild, we use an existing method to estimate lighting parameters, which are treated as ground truth with noise. To alleviate the effect of such noise, we utilize the idea of Generative Adversarial Networks (GAN) and propose a Label Denoising Adversarial Network (LDAN). LDAN makes use of synthetic data with accurate ground truth to help train a deep CNN for lighting regression on real face images. Experiments show that our network outperforms existing methods in producing consistent lighting parameters of different faces under similar lighting conditions. To further evaluate the proposed method, we also apply it to regress object 2D key points where ground truth labels are available. Our experiments demonstrate its effectiveness on this application.},
   author = {Hao Zhou and Jin Sun and Yaser Yacoob and David W. Jacobs},
   doi = {10.1109/CVPR.2018.00653},
   isbn = {9781538664209},
   issn = {10636919},
   journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   pages = {6238-6247},
   title = {Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Faces},
   year = {2018},
}
@article{Amelard2014,
   abstract = {Skin lesion analysis using standard camera images has received limited attention from the scientific community due to its technical complexity and scarcity of data. The images are privy to lighting variations caused by uneven source lighting, and unconstrained differences in resolution, scale, and equipment. In this chapter, we propose a framework that performs illumination correction and feature extraction on photographs of skin lesions acquired using standard consumer-grade cameras. We apply a multi-stage illumination correction algorithm and define a set of high-level intuitive features (HLIF) that quantifies the level of asymmetry and border irregularity about a lesion. This lighting-corrected intuitive feature model framework can be used to classify skin lesion diagnoses with high accuracy. The framework accurately corrects the illumination variations and achieves high and precise sensitivity (95 \{%\} confidence interval (CI), 73.1--73.5 \{%\}) and specificity (95 \{%\} CI, 72.0--72.4 \{%\}) using a linear support vector machine classifier with cross-validation trials. It exhibits higher test-retest reliability than the much larger state-of-the-art low-level feature set (95 \{%\} CI, 78.1--79.7 \{%\} sensitivity, 75.3--76.3 \{%\} specificity). Combining our framework with these low-level features attains sensitivity (95 \{%\} CI, 83.3--84.8 \{%\}) and specificity (95 \{%\} CI, 79.7--80.1 \{%\}), which is more accurate and reliable than classification using the low-level feature set.},
   author = {Robert Amelard and Jeffrey Glaister and Alexander Wong and David A. Clausi},
   doi = {10.1007/978-3-642-39608-3_7},
   journal = {Computer Vision Techniques for the Diagnosis of Skin Cancer},
   pages = {193-219},
   title = {Melanoma Decision Support Using Lighting-Corrected Intuitive Feature Models},
   year = {2014},
}
@article{Roh2019,
   abstract = {Data collection is a major bottleneck in machine learning and an active research topic in multiple communities. There are largely two reasons data collection has recently become a critical issue. First, as machine learning is becoming more widely-used, we are seeing new applications that do not necessarily have enough labeled data. Second, unlike traditional machine learning, deep learning techniques automatically generate features, which saves feature engineering costs, but in return may require larger amounts of labeled data. Interestingly, recent research in data collection comes not only from the machine learning, natural language, and computer vision communities, but also from the data management community due to the importance of handling large amounts of data. In this survey, we perform a comprehensive study of data collection from a data management point of view. Data collection largely consists of data acquisition, data labeling, and improvement of existing data or models. We provide a research landscape of these operations, provide guidelines on which technique to use when, and identify interesting research challenges. The integration of machine learning and data management for data collection is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research.},
   author = {Yuji Roh and Geon Heo and Steven Euijong Whang},
   doi = {10.1109/tkde.2019.2946162},
   issn = {1041-4347},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   pages = {1-1},
   title = {A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective},
   year = {2019},
}
@article{Ramezani2014,
   abstract = {In order to distinguish between benign and malignant types of pigmented skin lesions, computerized procedures have been developed for images taken by different equipment that the most available one of them is conventional digital cameras. In this research, a new procedure to detect malignant melanoma from benign pigmented lesions using macroscopic images is presented. The images are taken by conventional digital cameras with spatial resolution higher than one megapixel and by considering no constraints and special conditions during imaging. In the proposed procedure, new methods to weaken the effect of nonuniform illumination, correction of the effect of thick hairs and large glows on the lesion and also, a new threshold-based segmentation algorithm are presented. 187 features representing asymmetry, border irregularity, color variation, diameter and texture are extracted from the lesion area and after reducing the number of features using principal component analysis (PCA), lesions are determined as malignant or benign using support vector machine classifier. According to the dermatologist diagnosis, the proposed processing methods have the ability to detect lesions area with high accuracy. The evaluation measures of classification have indicated that 13 features extracted by PCA method lead to better results than all of the extracted features. These results led to an accuracy of 82.2%, sensitivity of 77% and specificity of 86.93%. The proposed method may help dermatologists to detect the malignant lesions in the primary stages due to the minimum constraints during imaging, the ease of usage by the public and nonexperts, and high accuracy in detection of the lesion type.},
   author = {Maryam Ramezani and Alireza Karimian and Payman Moallem},
   doi = {10.4103/2228-7477.144052},
   issn = {22287477},
   issue = {4},
   journal = {Journal of Medical Signals and Sensors},
   keywords = {Classification,malignant melanoma,melanoma diagnosis,skin lesions},
   pages = {281-290},
   pmid = {25426432},
   title = {Automatic Detection of Malignant Melanoma using Macroscopic Images},
   volume = {4},
   year = {2014},
}
@article{Pillay2019,
   abstract = {Automatic diagnosis of skin cancer images is especially difficult in medical image processing. Moreover, proper segmentation is crucial for the partitioning of growths from the skin, which can aid in the differentiation between melanoma and benign skin lesions. To address these issues, this research work investigates the widely used ABCD rule (Asymmetry, Border Irregularity, Colour and Diameter) on macroscopic images and the Graph-Cut segmentation technique as it demonstrates capabilities for handling extremely textured, noisy and colour images which are present in macroscopic images. The accuracy rates achieved by the proposed model with the use of the TDS (Total Dermoscopy Score) classifier is 73,529%, SVM is 75,294% and KNN classifier is 74,706%.},
   author = {Verosha Pillay and Serestina Viriri},
   doi = {10.1109/ICTAS.2019.8703611},
   isbn = {9781538673652},
   journal = {2019 Conference on Information Communications Technology and Society, ICTAS 2019},
   keywords = {ABCD rule,Graph-Cut segmentation,Macroscopic images,Skin cancer,TDS},
   title = {Skin cancer detection from macroscopic images},
   year = {2019},
}
@article{Carvalho2019,
   abstract = {Machine learning systems are becoming increasingly ubiquitous. These systems’s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.},
   author = {Diogo V. Carvalho and Eduardo M. Pereira and Jaime S. Cardoso},
   doi = {10.3390/electronics8080832},
   issn = {20799292},
   issue = {8},
   journal = {Electronics (Switzerland)},
   keywords = {Explainability,Interpretability,Machine learning,XAI},
   title = {Machine learning interpretability: A survey on methods and metrics},
   volume = {8},
   year = {2019},
}
@article{Veltmeijer2019,
   author = {Emmeke A. Veltmeijer and Sezer Karaoglu and Theo Gevers},
   issn = {16130073},
   journal = {CEUR Workshop Proceedings},
   keywords = {Explainable AI,Melanoma,Multi-task learning,Skin lesion classification},
   title = {Integrating clinically-relevant features into skin lesion classification},
   volume = {2491},
   year = {2019},
}
@article{Lage2019a,
   abstract = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable under three specific tasks that users may perform with machine learning systems: simulation of the response, verification of a suggested response, and determining whether the correctness of a suggested response changes under a change to the inputs. Through carefully controlled human-subject experiments, we identify regularizers that can be used to optimize for the interpretability of machine learning systems. Our results show that the type of complexity matters: cognitive chunks (newly defined concepts) affect performance more than variable repetitions, and these trends are consistent across tasks and domains. This suggests that there may exist some common design principles for explanation systems.},
   author = {Isaac Lage and Emily Chen and Jeffrey He and Menaka Narayanan and Been Kim and Sam Gershman and Finale Doshi-Velez},
   title = {An Evaluation of the Human-Interpretability of Explanation},
   url = {http://arxiv.org/abs/1902.00006},
   year = {2019},
}
@article{Codella2018a,
   abstract = {Automated dermoscopic image analysis has witnessed rapid growth in diagnostic performance. Yet adoption faces resistance, in part, because no evidence is provided to support decisions. In this work, an approach for evidence-based classification is presented. A feature embedding is learned with CNNs, triplet-loss, and global average pooling, and used to classify via kNN search. Evidence is provided as both the discovered neighbors, as well as localized image regions most relevant to measuring distance between query and neighbors. To ensure that results are relevant in terms of both label accuracy and human visual similarity for any skill level, a novel hierarchical triplet logic is implemented to jointly learn an embedding according to disease labels and non-expert similarity. Results are improved over baselines trained on disease labels alone, as well as standard multiclass loss. Quantitative relevance of results, according to non-expert similarity, as well as localized image regions, are also significantly improved.},
   author = {Noel C.F. Codella and Chung Ching Lin and Allan Halpern and Michael Hind and Rogerio Feris and John R. Smith},
   doi = {10.1007/978-3-030-02628-8_11},
   isbn = {9783030026271},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Deep learning,Dermoscopy,Evidence,Explainable,Global average pooling,Interpretable,Melanoma,Triplet-loss,Weighted activation maps},
   pages = {97-105},
   title = {Collaborative human-AI (CHAI): Evidence-based interpretable melanoma classification in dermoscopic images},
   volume = {11038 LNCS},
   year = {2018},
}
@article{Xie2019,
   abstract = {For diagnosing melanoma, hematoxylin and eosin (H&amp;E) stained tissue slides remains the gold standard. These images contain quantitative information in different magnifications. In the present study, we investigated whether deep convolutional neural networks can extract structural features of complex tissues directly from these massive size images in a patched way. In order to face the challenge arise from morphological diversity in histopathological slides, we built a multicenter database of 2241 digital whole-slide images from 1321 patients from 2008 to 2018. We trained both ResNet50 and Vgg19 using over 9.95 million patches by transferring learning, and test performance with two kinds of critical classifications: malignant melanomas versus benign nevi in separate and mixed magnification; and distinguish among nevi in maximum magnification. The CNNs achieves superior performance across both tasks, demonstrating an AI capable of classifying skin cancer in the analysis from histopathological images. For making the classifications reasonable, the visualization of CNN representations is furthermore used to identify cells between melanoma and nevi. Regions of interest (ROI) are also located which are significantly helpful, giving pathologists more support of correctly diagnosis.},
   author = {Kai Lu Mingzhu Yin Fangfang Li Yu Zhang Ke Zuo Peizhen Xie},
   doi = {arXiv:1904.06156v1},
   journal = {arXiv Computer Science},
   title = {Interpretable Classification from Skin Cancer Histology Slides Using Deep Learning: A Retrospective Multicenter Study. (arXiv:1904.06156v1 [q-bio.TO])},
   url = {https://arxiv.org/ftp/arxiv/papers/1904/1904.06156.pdf%0Ahttp://arxiv.org/abs/1904.06156},
   year = {2019},
}
@article{Lage2019,
   abstract = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable under three specific tasks that users may perform with machine learning systems: simulation of the response, verification of a suggested response, and determining whether the correctness of a suggested response changes under a change to the inputs. Through carefully controlled human-subject experiments, we identify regularizers that can be used to optimize for the interpretability of machine learning systems. Our results show that the type of complexity matters: cognitive chunks (newly defined concepts) affect performance more than variable repetitions, and these trends are consistent across tasks and domains. This suggests that there may exist some common design principles for explanation systems.},
   author = {Isaac Lage and Emily Chen and Jeffrey He and Menaka Narayanan and Been Kim and Sam Gershman and Finale Doshi-Velez},
   title = {An Evaluation of the Human-Interpretability of Explanation},
   url = {http://arxiv.org/abs/1902.00006},
   year = {2019},
}
@article{BarredoArrieta2020,
   abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
   author = {Alejandro Barredo Arrieta and Natalia Díaz-Rodríguez and Javier Del Ser and Adrien Bennetot and Siham Tabik and Alberto Barbado and Salvador Garcia and Sergio Gil-Lopez and Daniel Molina and Richard Benjamins and Raja Chatila and Francisco Herrera},
   doi = {10.1016/j.inffus.2019.12.012},
   issn = {15662535},
   journal = {Information Fusion},
   keywords = {Accountability,Comprehensibility,Data Fusion,Deep Learning,Explainable Artificial Intelligence,Fairness,Interpretability,Machine Learning,Privacy,Responsible Artificial Intelligence,Transparency},
   pages = {82-115},
   title = {Explainable Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
   volume = {58},
   year = {2020},
}
@article{Codella2019,
   abstract = {Using machine learning in high-stakes applications often requires predictions to be accompanied by explanations comprehensible to the domain user, who has ultimate responsibility for decisions and outcomes. Recently, a new framework for providing explanations, called TED, has been proposed to provide meaningful explanations for predictions. This framework augments training data to include explanations elicited from domain users, in addition to features and labels. This approach ensures that explanations for predictions are tailored to the complexity expectations and domain knowledge of the consumer. In this paper, we build on this foundational work, by exploring more sophisticated instantiations of the TED framework and empirically evaluate their effectiveness in two diverse domains, chemical odor and skin cancer prediction. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, improving modeling accuracy.},
   author = {Noel C. F. Codella and Michael Hind and Karthikeyan Natesan Ramamurthy and Murray Campbell and Amit Dhurandhar and Kush R. Varshney and Dennis Wei and Aleksandra Mojsilović},
   title = {Teaching AI to Explain its Decisions Using Embeddings and Multi-Task Learning},
   url = {http://arxiv.org/abs/1906.02299},
   year = {2019},
}
@article{Andreas2017a,
   abstract = {Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents' messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.},
   author = {Jacob Andreas and Anca Dragan and Dan Klein},
   doi = {10.18653/v1/P17-1022},
   isbn = {9781945626753},
   journal = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
   pages = {232-242},
   title = {Translating neuralese},
   volume = {1},
   year = {2017},
}
@article{Holzinger2017,
   abstract = {Artificial intelligence (AI) generally and machine learning (ML) specifically demonstrate impressive practical success in many different application domains, e.g. in autonomous driving, speech recognition, or recommender systems. Deep learning approaches, trained on extremely large data sets or using reinforcement learning methods have even exceeded human performance in visual tasks, particularly on playing games such as Atari, or mastering the game of Go. Even in the medical domain there are remarkable results. The central problem of such models is that they are regarded as black-box models and even if we understand the underlying mathematical principles, they lack an explicit declarative knowledge representation, hence have difficulty in generating the underlying explanatory structures. This calls for systems enabling to make decisions transparent, understandable and explainable. A huge motivation for our approach are rising legal and privacy aspects. The new European General Data Protection Regulation entering into force on May 25th 2018, will make black-box approaches difficult to use in business. This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time, however, there must be a possibility to make the results re-traceable on demand. In this paper we outline some of our research topics in the context of the relatively new area of explainable-AI with a focus on the application in medicine, which is a very special domain. This is due to the fact that medical professionals are working mostly with distributed heterogeneous and complex sources of data. In this paper we concentrate on three sources: images, *omics data and text. We argue that research in explainable-AI would generally help to facilitate the implementation of AI/ML in the medical domain, and specifically help to facilitate transparency and trust.},
   author = {Andreas Holzinger and Chris Biemann and Constantinos S. Pattichis and Douglas B. Kell},
   journal = {ArXiv},
   title = {What do we need to build explainable AI systems for the medical domain?},
   url = {http://arxiv.org/abs/1712.09923},
   year = {2017},
}
@article{Hind2019,
   abstract = {Artificial intelligence systems are being increasingly deployed due to their potential to increase the efficiency, scale, consistency, fairness, and accuracy of decisions. However, as many of these systems are opaque in their operation, there is a growing demand for such systems to provide explanations for their decisions. Conventional approaches to this problem attempt to expose or discover the inner workings of a machine learning model with the hope that the resulting explanations will be meaningful to the consumer. In contrast, this paper suggests a new approach to this problem. It introduces a simple, practical framework, called Teaching Explanations for Decisions (TED), that provides meaningful explanations that match the mental model of the consumer. We illustrate the generality and effectiveness of this approach with two different examples, resulting in highly accurate explanations with no loss of prediction accuracy for these two examples.},
   author = {Michael Hind and Dennis Wei and Murray Campbell and Noel C.F. Codella and Amit Dhurandhar and Aleksandra Mojsilović and Karthikeyan Natesan Ramamurthy and Kush R. Varshney},
   doi = {10.1145/3306618.3314273},
   isbn = {9781450363242},
   journal = {AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
   keywords = {AI Ethics,Elicitation,Explainable AI,Machine Learning,Meaningful Explanation,Supervised Classification},
   pages = {123-129},
   title = {TED: Teaching AI to explain its decisions},
   year = {2019},
}
@article{Majumder2019,
   author = {Sharmin Majumder and Muhammad Ahsan Ullah},
   doi = {10.1007/s42452-019-0786-8},
   issn = {2523-3963},
   issue = {7},
   journal = {SN Applied Sciences},
   title = {Feature extraction from dermoscopy images for melanoma diagnosis},
   volume = {1},
   year = {2019},
}
@article{Andre2017,
   abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images - two orders of magnitude larger than previous datasets - consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
   author = {Esteva Andre and Kuprel Brett and Novoa Roberto A. and Ko Justin and Swetter Susan M. and Blau Helen M. and Thrun Sebastian},
   doi = {10.1038/nature21056 LK - http://elinks.library.upenn.edu/sfx_local?sid=EMBASE&issn=14764687&id=doi:10.1038%2Fnature21056&atitle=Dermatologist-level+classification+of+skin+cancer+with+deep+neural+networks&stitle=Nature&title=Nature&volume=542&issue=7639&spage=115&epage=118&aulast=Esteva&aufirst=Andre&auinit=A.&aufull=Esteva+A.&coden=NATUA&isbn=&pages=115-118&date=2017&auinit1=A&auinitm=},
   issn = {1476-4687},
   issue = {7639},
   journal = {Nature},
   keywords = {amelanotic melanoma,article,artificial intelligence,cancer classification,cancer patient,cancer screening,clinical decision making,comparative study,convolutional neural network,dermatologist,diagnostic accuracy,epiluminescence microscopy,histopathology,human,keratinocyte,learning algorithm,medical education,melanoma,nevus,priority journal,probability,seborrheic keratosis,sensitivity and specificity,skin biopsy,skin cancer,skin defect},
   pages = {115-118},
   title = {Dermatologist-level classification of skin cancer with deep neural networks},
   volume = {542},
   url = {http://www.embase.com/search/results?subaction=viewrecord&from=export&id=L614981551%0Ahttp://dx.doi.org/10.1038/nature21056},
   year = {2017},
}
@article{Zhang2018,
   abstract = {Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model. Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches -- especially model-based methods -- have been proposed and applied in real-world systems. In this survey, we provide a comprehensive review for the explainable recommendation research. We highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation, including user study approaches in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research: one dimension is the information source of the explanations, and the other dimension is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable recommendation applies to different recommendation tasks, such as product, social, and POI recommendations. We also devote a section to discuss the future directions to promote the explainable recommendation research.},
   author = {Yongfeng Zhang and Xu Chen},
   title = {Explainable Recommendation: A Survey and New Perspectives},
   url = {http://arxiv.org/abs/1804.11192},
   year = {2018},
}
@article{Petkovic2018,
   abstract = {The goals of this workshop are to discuss challenges in explainability of current Machine Leaning and Deep Analytics (MLDA) used in biocomputing and to start the discussion on ways to improve it. We define explainability in MLDA as easy to use information explaining why and how the MLDA approach made its decisions. We believe that much greater effort is needed to address the issue of MLDA explainability because of: 1) the ever increasing use and dependence on MLDA in biocomputing including the need for increased adoption by non-MLD experts; 2) the diversity, complexity and scale of biocomputing data and MLDA algorithms; 3) the emerging importance of MLDA-based decisions in patient care, in daily research, as well as in the development of new costly medical procedures and drugs. This workshop aims to: a) analyze and challenge the current level of explainability of MLDA methods and practices in biocomputing; b) explore benefits of improvements in this area; and c) provide useful and practical guidance to the biocomputing community on how to address these challenges and how to develop improvements. The workshop format is designed to encourage a lively discussion with panelists to first motivate and understand the problem and then to define next steps and solutions needed to improve MLDA explainability.},
   author = {Dragutin Petkovic and Lester Kobzik and Christopher Re},
   doi = {10.1142/9789813235533_0058},
   issn = {23356936},
   issue = {212669},
   journal = {Pacific Symposium on Biocomputing},
   keywords = {Explainability,Interpretability,Machine learning,Workshop},
   pages = {623-627},
   pmid = {29218921},
   title = {Machine learning and deep analytics for biocomputing: Call for better explainability},
   volume = {0},
   year = {2018},
}
@article{Chalkiadakis2018,
   author = {Ioannis Chalkiadakis},
   pages = {1-20},
   title = {A brief survey of visualization methods for deep learning models from the perspective of Explainable AI .},
   url = {https://www.macs.hw.ac.uk/~ic14/IoannisChalkiadakis_RRR.pdf},
   year = {2018},
}
@article{Selvaraju2016,
   abstract = {We propose a technique for producing "visual explanations" for decisions from a large class of CNN-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, GradCAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in tasks with multimodal inputs (e.g. VQA) or reinforcement learning, without any architectural changes or re-training. We combine GradCAM with fine-grained visualizations to create a high-resolution class-discriminative visualization and apply it to off-the-shelf image classification, captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into their failure modes (showing that seemingly unreasonable predictions have reasonable explanations), (b) are robust to adversarial images, (c) outperform previous methods on weakly-supervised localization, (d) are more faithful to the underlying model and (e) help achieve generalization by identifying dataset bias. For captioning and VQA, our visualizations show that even non-attention based models can localize inputs. Finally, we conduct human studies to measure if GradCAM explanations help users establish trust in predictions from deep networks and show that GradCAM helps untrained users successfully discern a "stronger" deep network from a "weaker" one. Our code is available at https://github.com/ramprs/grad-cam. A demo and a video of the demo can be found at http://gradcam.cloudcv.org and youtu.be/COjUB9Izk6E.},
   author = {Ramprasaath R. Selvaraju and Michael Cogswell and Abhishek Das and Ramakrishna Vedantam and Devi Parikh and Dhruv Batra},
   issn = {00418781},
   journal = {Revista do Hospital das Cl??nicas},
   pages = {331-336},
   title = {Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization},
   volume = {17},
   url = {http://arxiv.org/abs/1610.02391},
   year = {2016},
}
@article{Samek2019a,
   abstract = {In recent years, machine learning (ML) has become a key enabling technology for the sciences and industry. Especially through improvements in methodology, the availability of large databases and increased computational power, today’s ML algorithms are able to achieve excellent performance (at times even exceeding the human level) on an increasing number of complex tasks. Deep learning models are at the forefront of this development. However, due to their nested non-linear structure, these powerful models have been generally considered “black boxes”, not providing any information about what exactly makes them arrive at their predictions. Since in many applications, e.g., in the medical domain, such lack of transparency may be not acceptable, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This introductory paper presents recent developments and applications in this field and makes a plea for a wider use of explainable learning algorithms in practice.},
   author = {Wojciech Samek and Klaus Robert Müller},
   doi = {10.1007/978-3-030-28954-6_1},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Deep learning,Explainable artificial intelligence,Interpretability,Model transparency,Neural networks},
   pages = {5-22},
   title = {Towards Explainable Artificial Intelligence},
   volume = {11700 LNCS},
   year = {2019},
}
@article{Andreas2017,
   abstract = {Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents' messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.},
   author = {Jacob Andreas and Anca Dragan and Dan Klein},
   doi = {10.18653/v1/P17-1022},
   isbn = {9781945626753},
   journal = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
   pages = {232-242},
   title = {Translating neuralese},
   volume = {1},
   year = {2017},
}
@article{Fuji2019,
   abstract = {One of the most significant advancements made in AI in recent years is the greatly enhanced accuracy of machine learning through deep learning. However, because deep learning deals with huge volumes of data and involves vast neural networks in the learning process, it is often difficult to explain how or why an output was reached even if the inference was correct. This issue impedes the application of AI technology to such business areas as finance and medicine, which demand absolute reliability. To address this issue, we have developed an AI technology that combines Deep Tensor, Fujitsu’s original machine-learning technology based on enhanced deep learning, and another Fujitsu-developed machine-learning technology based on knowledge graph, a knowledge base represented by graph data taken from past documents and databases. This has enabled us to logically explain the reasons and bases in which Deep Tensor reaches its inference output. This paper explains the technology that makes Explainable AI possible in terms of application cases in network intrusion detection and genomic medicine.},
   author = {Masaru Fuji and Hajime Morita and Keisuke Goto and Koji Maruhashi and Hirokazu Anai and Nobuyuki Igata},
   issn = {00162523},
   issue = {2},
   journal = {Fujitsu Scientific and Technical Journal},
   pages = {58-64},
   title = {Explainable AI through combination of deep tensor and knowledge graph},
   volume = {55},
   year = {2019},
}
@article{Bondarev2019,
   abstract = {Melanoma is an aggressive skin cancer prevalent among the Caucasian population. The site of melanoma is gender dependent: for women the prevalent site is the legs. Success of the treatment strongly correlates with early dysplastic nevus excision. Diagnosis relies on full-body skin examination and baseline photography to locate evolving, and therefore suspicious, moles. We designed the first semi-automated legs scanner which uses one camera and laser range finder to capture images and measurements respectively. The scanner circulates around the leg, along its full length. From the collected data, a 3D leg model with moles is created. The moles are registered over temporal scans for comparison and detection of moles' evolution. Our algorithm was tested on simulated leg model that changes over time. The average accuracy of mole registration from two temporal scans at optimal scanner settings was 94.87% with standard deviation of 6.10.},
   author = {Alisa Bondarev},
   institution = {Carleton University},
   title = {Leg Scanner for Detection and Tracking of Evolving Pigmented Skin Lesions for Melanoma Cancer Prevention},
   url = {https://curve.carleton.ca/23ae0da5-a344-4000-84dc-f4f91f685563},
   year = {2019},
}
@article{Miller2017,
   abstract = {In his seminal book The Inmates are Running the Asylum: Why High-Tech Products Drive Us Crazy And How To Restore The Sanity [2004, Sams Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is often poorly designed (from a user perspective) is that programmers are in charge of design decisions, rather than interaction designers. As a result, programmers design software for themselves, rather than for their target audience; a phenomenon he refers to as the ‘inmates running the asylum’. This paper argues that ex- plainable AI risks a similar fate. While the re-emergence of explainable AI is positive, this paper argues most of us as AI researchers are building explanatory agents for ourselves, rather than for the intended users. But ex- plainable AI is more likely to succeed if researchers and practitioners understand, adopt, implement, and improve models from the vast and valuable bodies of research in philosophy, psychology, and cognitive science; and if evalu- ation of these models is focused more on people than on technology. From a light scan of litera- ture, we demonstrate that there is considerable scope to infuse more results from the social and behavioural sciences into explainable AI, and present some key results from these fields that are relevant to explainable AI.},
   author = {Tim Miller and Piers Hower and Liz Sonenberg},
   doi = {10.1016/j.foodchem.2017.11.091},
   issn = {0308-8146},
   issue = {October},
   journal = {IJCAI 2017 workshop on explainable artificial intelligence (XAI)},
   pages = {363},
   title = {Explainable AI: beware of inmates running the asylum},
   url = {http://home.earthlink.net/},
   year = {2017},
}
@article{Yen2017,
   abstract = {Nonmelanoma skin cancer (NMSC) comprises mainly basal cell carcinoma (BCC) and cutaneous squamous cell carcinoma (cSCC). The association between alcohol intake and NMSC has been inconclusive; therefore the objective of this study is to quantify the relationship between alcohol intake and NMSC using meta-analyses. A systematic literature search of PubMed and Embase was performed on 30 October 2016. Eligible articles were case–control or cohort studies that examined alcohol intake and risk of BCC or cSCC and reported relative risks (RRs) with 95% confidence intervals (CIs). Of the 307 articles identified, 13 case–control and cohort studies were included in the systematic review, including 95 241 NMSC cases (91 942 BCC and 3299 cSCC cases). A random-effects model was used to obtain summary RRs and 95% CIs for dose–response meta-analyses. For every 10-gram increase in ethanol intake per day, a positive association was found for both BCC (summary RR of 1·07; 95% CI 1·04–1·09) and cSCC (summary RR of 1·11; 95% CI 1·06–1·16). While there was evidence suggesting a nonlinear association for BCC, it may be due to the sparse data at higher alcohol intake levels. This meta-analysis found evidence that alcohol drinking is positively associated with both BCC and cSCC risk in a dose-dependent manner. These results should be interpreted with caution due to potential residual confounding. Nonetheless, because alcohol drinking is a prevalent and modifiable behaviour, it could serve as an important public health target to reduce the global health burden of NMSC.},
   author = {H. Yen and A. Dhana and J. P. Okhovat and A. Qureshi and N. Keum and E. Cho},
   doi = {10.1111/bjd.15647},
   issn = {13652133},
   issue = {3},
   journal = {British Journal of Dermatology},
   pages = {696-707},
   title = {Alcohol intake and risk of nonmelanoma skin cancer: a systematic review and dose–response meta-analysis},
   volume = {177},
   year = {2017},
}
@article{Yi2019,
   abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
   author = {Xin Yi and Ekta Walia and Paul Babyn},
   doi = {10.1016/j.media.2019.101552},
   issn = {13618423},
   journal = {Medical Image Analysis},
   keywords = {Deep learning,Generative adversarial network,Generative model,Medical imaging,Review},
   title = {Generative adversarial network in medical imaging: A review},
   volume = {58},
   year = {2019},
}
@article{Chi2018,
   abstract = {Dermoscopic imaging is an established technique to detect, track, and diagnose malignant melanoma, and one of the ways to improve this technique is via computer-aided image segmentation. Image segmentation is an important step towards building computerized detection and classification systems by delineating the area of interest, in our case, the skin lesion, from the background. However, current segmentation techniques are hard pressed to account for color artifacts within dermoscopic images that are often incorrectly detected as part of the lesion. Often there are few annotated examples of these artifacts, which limits training segmentation methods like the fully convolutional network (FCN) due to the skewed dataset. We propose to improve FCN training by augmenting the dataset with synthetic images created in a controlled manner using a generative adversarial network (GAN). Our novelty lies in the use of a color label (CL) to specify the different characteristics (approximate size, location, and shape) of the different regions (skin, lesion, artifacts) in the synthetic images. Our GAN is trained to perform style transfer of real melanoma image characteristics (e.g. texture) onto these color labels, allowing us to generate specific types of images containing artifacts. Our experimental results demonstrate that the synthetic images generated by our technique have a lower mean average error when compared to synthetic images generated using traditional binary labels. As a consequence, we demonstrated improvements in melanoma image segmentation when using synthetic images generated by our technique.},
   author = {Yucong Chi and Lei Bi and Jinman Kim and Dagan Feng and Ashnil Kumar},
   doi = {10.1109/EMBC.2018.8512842},
   isbn = {9781538636466},
   issn = {1557170X},
   journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
   keywords = {data augmentation,dermoscopic image,image segmentation,melanoma},
   pages = {2591-2594},
   title = {Controlled Synthesis of Dermoscopic Images via a New Color Labeled Generative Style Transfer Network to Enhance Melanoma Segmentation},
   volume = {2018-July},
   year = {2018},
}
@article{Bissoto2019,
   abstract = {Skin cancer is by far the most common type of cancer. Early detection is the key to increase the chances for successful treatment significantly. Currently, Deep Neural Networks are the state-of-the-art results on automated skin cancer classification. To push the results further, we need to address the lack of annotated data, which is expensive and require much effort from specialists. To bypass this problem, we propose using Generative Adversarial Networks for generating realistic synthetic skin lesion images. To the best of our knowledge, our results are the first to show visually-appealing synthetic images that comprise clinically-meaningful information.},
   author = {Alceu Bissoto and Fábio Perez and Eduardo Valle and Sandra Avila},
   doi = {10.1007/978-3-030-01201-4_32},
   isbn = {9783030012007},
   issn = {16113349},
   journal = {ArXiv},
   keywords = {Deep learning,Generative models,Skin cancer},
   pages = {294-302},
   title = {Skin lesion synthesis with generative adversarial networks},
   volume = {11041 LNCS},
   year = {2019},
}
@article{Baur2018,
   abstract = {Generative Adversarial Networks (GANs) have been successfully used to synthesize realistically looking images of faces, scenery and even medical images. Unfortunately, they usually require large training datasets, which are often scarce in the medical field, and to the best of our knowledge GANs have been only applied for medical image synthesis at fairly low resolution. However, many state-of-the-art machine learning models operate on high resolution data as such data carries indispensable, valuable information. In this work, we try to generate realistically looking high resolution images of skin lesions with GANs, using only a small training dataset of 2000 samples. The nature of the data allows us to do a direct comparison between the image statistics of the generated samples and the real dataset. We both quantitatively and qualitatively compare state-of-the-art GAN architectures such as DCGAN and LAPGAN against a modification of the latter for the task of image generation at a resolution of 256x256px. Our investigation shows that we can approximate the real data distribution with all of the models, but we notice major differences when visually rating sample realism, diversity and artifacts. In a set of use-case experiments on skin lesion classification, we further show that we can successfully tackle the problem of heavy class imbalance with the help of synthesized high resolution melanoma samples.},
   author = {Christoph Baur and Shadi Albarqouni and Nassir Navab},
   journal = {ArXiv},
   title = {MelanoGANs: High Resolution Skin Lesion Synthesis with GANs},
   url = {http://arxiv.org/abs/1804.04338},
   year = {2018},
}
@misc{UK2019,
   author = {Cancer Research UK},
   journal = {Cancer Researh UK},
   title = {Melanoma skin cancer statistics | Cancer Research UK},
   url = {https://www.cancerresearchuk.org/health-professional/cancer-statistics/statistics-by-cancer-type/melanoma-skin-cancer#heading-Three},
   year = {2019},
}
@article{Rashid2019,
   author = {Haroon Rashid and M. Asjid Tanveer and Hassan Aqeel Khan},
   doi = {10.1109/embc.2019.8857905},
   pages = {916-919},
   title = {Skin Lesion Classification Using GAN based Data Augmentation},
   year = {2019},
}
@article{Deepa2019,
   abstract = {Deep learning plays an important role in prediction and analytical process. Deep learning applications are recognizing patters, recognizing speech, NLP (Natural Language Processing), etc. It is a subset of machine learning and its techniques raise research interests as it solves many problems which could not be approached before. This paper provides detailed analysis of deep learning and its techniques used in various applications and especially to provide an extensive reference for the researchers in deep learning and its algorithms, implementation techniques and applications used in recent technologies. This paper will also help to improve investigation of deep learning and highlights new research areas and advancements of technology.},
   author = {N. Deepa and S. P. Chokkalingam},
   doi = {10.14419/ijet.v7i3.33.18588},
   issn = {22498958},
   issue = {3},
   journal = {International Journal of Engineering and Advanced Technology},
   pages = {607-610},
   title = {Deep convolutional neural networks (CNN) for medical image analysis},
   volume = {8},
   year = {2019},
}
@article{Ghorbani2019a,
   abstract = {Despite the recent success in applying supervised deep learning to medical imaging tasks, the problem of obtaining large and diverse expert-annotated datasets required for the development of high performant models remains particularly challenging. In this work, we explore the possibility of using Generative Adverserial Networks (GAN) to synthesize clinical images with skin condition. We propose DermGAN, an adaptation of the popular Pix2Pix architecture, to create synthetic images for a pre-specified skin condition while being able to vary its size, location and the underlying skin color. We demonstrate that the generated images are of high fidelity using objective GAN evaluation metrics. In a Human Turing test, we note that the synthetic images are not only visually similar to real images, but also embody the respective skin condition in dermatologists' eyes. Finally, when using the synthetic images as a data augmentation technique for training a skin condition classifier, we observe that the model performs comparably to the baseline model overall while improving on rare but malignant conditions.},
   author = {Amirata Ghorbani and Vivek Natarajan and David Coz and Yuan Liu},
   journal = {ArXiv},
   title = {DermGAN: Synthetic Generation of Clinical Skin Images with Pathology},
   url = {http://arxiv.org/abs/1911.08716},
   year = {2019},
}
@article{Mikoajczyk2018,
   abstract = {These days deep learning is the fastest-growing field in the field of Machine Learning (ML) and Deep Neural Networks (DNN). Among many of DNN structures, the Convolutional Neural Networks (CNN) are currently the main tool used for the image analysis and classification purposes. Although great achievements and perspectives, deep neural networks and accompanying learning algorithms have some relevant challenges to tackle. In this paper, we have focused on the most frequently mentioned problem in the field of machine learning, that is the lack of sufficient amount of the training data or uneven class balance within the datasets. One of the ways of dealing with this problem is so called data augmentation. In the paper we have compared and analyzed multiple methods of data augmentation in the task of image classification, starting from classical image transformations like rotating, cropping, zooming, histogram based methods and finishing at Style Transfer and Generative Adversarial Networks, along with the representative examples. Next, we presented our own method of data augmentation based on image style transfer. The method allows to generate the new images of high perceptual quality that combine the content of a base image with the appearance of another ones. The newly created images can be used to pre-train the given neural network in order to improve the training process efficiency. Proposed method is validated on the three medical case studies: skin melanomas diagnosis, histopathological images and breast magnetic resonance imaging (MRI) scans analysis, utilizing the image classification in order to provide a diagnose. In such kind of problems the data deficiency is one of the most relevant issues. Finally, we discuss the advantages and disadvantages of the methods being analyzed.},
   author = {Agnieszka Mikołajczyk and Michał Grochowski},
   doi = {10.1109/IIPHDW.2018.8388338},
   isbn = {9781538661437},
   journal = {2018 International Interdisciplinary PhD Workshop, IIPhDW 2018},
   keywords = {Machine learning,data augmentation,deep learning,medical imaging,style transfer},
   pages = {117-122},
   title = {Data augmentation for improving deep learning in image classification problem},
   year = {2018},
}
@article{Newlands2016,
   abstract = {This is the official guideline endorsed by the specialty associations involved in the care of head and neck cancer patients in the UK. This paper provides consensus recommendations on the management of cutaneous basal cell carcinoma and squamous cell carcinoma in the head and neck region on the basis of current evidence.},
   author = {C Newlands and R Currie and A Memon and S Whitaker and T Woolford},
   doi = {10.1017/s0022215116000554},
   issn = {0022-2151},
   issue = {S2},
   journal = {The Journal of Laryngology & Otology},
   pages = {S125-S132},
   title = {Non-melanoma skin cancer: United Kingdom National Multidisciplinary Guidelines},
   volume = {130},
   year = {2016},
}
@article{Casals2019,
   abstract = {<p class="p1">Generative Adversarial Networks (GANs) are deep learning architectures known for their usefulness on synthesizing new images. Conditioned image generation or the synthesis of super-resolution images are some of their main uses, but they are also helpful when tackling particular image classification and segmentation problems. The latter application is the motivation for the work presented in this document.<span class="Apple-converted-space">&nbsp;</span></p>
<p class="p1">This work studies the synthesis of acne images for data augmentation, a procedure validated using said synthetic images to tackle an image classification problem.<span class="Apple-converted-space">&nbsp;</span></p>
<p class="p1">The main challenge will be to work around the instability in the training of GANs. Therefore, different known solutions will be implemented in order to overcome this problem.<span class="Apple-converted-space">&nbsp;</span></p>},
   author = {Roger Casals},
   title = {Synthesis of acne images for data augmentation with generative adversarial networks},
   year = {2019},
}
@article{Abhishek2019,
   abstract = {Skin lesion segmentation is a vital task in skin cancer diagnosis and further treatment. Although deep learning based approaches have significantly improved the segmentation accuracy, these algorithms are still reliant on having a large enough dataset in order to achieve adequate results. Inspired by the immense success of generative adversarial networks (GANs), we propose a GAN-based augmentation of the original dataset in order to improve the segmentation performance. In particular, we use the segmentation masks available in the training dataset to train the Mask2Lesion model, and use the model to generate new lesion images given any arbitrary mask, which are then used to augment the original training dataset. We test Mask2Lesion augmentation on the ISBI ISIC 2017 Skin Lesion Segmentation Challenge dataset and achieve an improvement of 5.17% in the mean Dice score as compared to a model trained with only classical data augmentation techniques.},
   author = {Kumar Abhishek and Ghassan Hamarneh},
   doi = {10.1007/978-3-030-32778-1_8},
   journal = {ArXiv},
   pages = {71-80},
   title = {Mask2Lesion: Mask-Constrained Adversarial Skin Lesion Image Synthesis},
   year = {2019},
}
@article{Baur2018a,
   abstract = {As many other machine learning driven medical image analysis tasks, skin image analysis suffers from a chronic lack of labeled data and skewed class distributions, which poses problems for the training of robust and well-generalizing models. The ability to synthesize realistic looking images of skin lesions could act as a reliever for the aforementioned problems. Generative Adversarial Networks (GANs) have been successfully used to synthesize realistically looking medical images, however limited to low resolution, whereas machine learning models for challenging tasks such as skin lesion segmentation or classification benefit from much higher resolution data. In this work, we successfully synthesize realistically looking images of skin lesions with GANs at such high resolution. Therefore, we utilize the concept of progressive growing, which we both quantitatively and qualitatively compare to other GAN architectures such as the DCGAN and the LAPGAN. Our results show that with the help of progressive growing, we can synthesize highly realistic dermoscopic images of skin lesions that even expert dermatologists find hard to distinguish from real ones.},
   author = {Christoph Baur and Shadi Albarqouni and Nassir Navab},
   doi = {10.1007/978-3-030-01201-4_28},
   isbn = {9783030012007},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {260-267},
   title = {Generating highly realistic images of skin lesions with GANs},
   volume = {11041 LNCS},
   year = {2018},
}
@article{Pollastri2019,
   abstract = {This paper presents a novel strategy that employs Generative Adversarial Networks (GANs) to augment data in the skin lesion segmentation task, which is a fundamental first step in the automated melanoma detection process. The proposed framework generates both skin lesion images and their segmentation masks, making the data augmentation process extremely straightforward. In order to thoroughly analyze how the quality and diversity of synthetic images impact the efficiency of the method, we remodel two different well known GANs: a Deep Convolutional GAN (DCGAN) and a Laplacian GAN (LAPGAN). Experimental results reveal that, by introducing such kind of synthetic data into the training process, the overall accuracy of a state-of-the-art Convolutional/Deconvolutional Neural Network for melanoma skin lesion segmentation is increased.},
   author = {Federico Pollastri and Federico Bolelli and Roberto Paredes and Costantino Grana},
   doi = {10.1007/s11042-019-7717-y},
   issn = {15737721},
   journal = {Multimedia Tools and Applications},
   keywords = {Adversarial learning,Convolutional neural networks,Deep learning,Skin lesion segmentation},
   title = {Augmenting data with GANs to segment melanoma skin lesions},
   year = {2019},
}
@article{Wang2008,
   abstract = {BACKGROUND: Studies have demonstrated differences in colors and dermoscopic structures observed with polarized dermoscopes (PDs) and nonpolarized dermoscopes (NPDs). OBJECTIVE: The objective was to evaluate whether diagnosis and diagnostic confidence changes when viewing dermoscopic images from NPDs and PDs. METHODS: A total of 100 dermatologists participated in the study. Twenty-five pigmented lesions were shown in the study, consisting of 7 seborrheic keratoses (SK), 3 basal cell carcinomas, 2 atypical nevi, 5 malignant melanomas (MM), 3 dermatofibromas, 3 blue nevi, and 2 hemangiomas. Two images of each lesion (one NPD and one PD) were included. The McNemar test and paired t-test were used for the statistical analysis. RESULTS: Ninety-one participants completed the study. Significant differences in the diagnoses were observed for the SK, atypical nevus, and MM images. Seventy-five percent and 59% of the final participants correctly diagnosed SK when presented with the NPD and PD images, respectively. For MM, 23 and 34% made the correct diagnoses with the NPD and PD images, respectively. CONCLUSIONS: Viewing lesions with NPD versus PD can affect the diagnosis and diagnostic confidence of physicians that are novices with dermoscopy. Further studies including physicians at different expertise levels and a larger sample of lesions are needed to further explore the differences. The authors have indicated no significant interest with commercial supporters. © 2008 by the American Society for Dermatologic Surgery, Inc.},
   author = {Steven Q. Wang and Stephen W. Dusza and Alon Scope and Ralph P. Braun and Alfred W. Kopf and Ashfaq A. Marghoob},
   doi = {10.1111/j.1524-4725.2008.34293.x},
   issn = {10760512},
   issue = {10},
   journal = {Dermatologic Surgery},
   pages = {1389-1395},
   title = {Differences in dermoscopic images from nonpolarized dermoscope and polarized dermoscope influence the diagnostic accuracy and confidence level: A pilot study},
   volume = {34},
   year = {2008},
}
@article{Yi2018,
   abstract = {Melanoma is a curable aggressive skin cancer if detected early. Typically, the diagnosis involves initial screening with subsequent biopsy and histopathological examination if necessary. Computer aided diagnosis offers an objective score that is independent of clinical experience and the potential to lower the workload of a dermatologist. In the recent past, success of deep learning algorithms in the field of general computer vision has motivated successful application of supervised deep learning methods in computer aided melanoma recognition. However, large quantities of labeled images are required to make further improvements on the supervised method. A good annotation generally requires clinical and histological confirmation, which requires significant effort. In an attempt to alleviate this constraint, we propose to use categorical generative adversarial network to automatically learn the feature representation of dermoscopy images in an unsupervised and semi-supervised manner. Thorough experiments on ISIC 2016 skin lesion chal- lenge demonstrate that the proposed feature learning method has achieved an average precision score of 0.424 with only 140 labeled images. Moreover, the proposed method is also capable of generating real-world like dermoscopy images.},
   author = {Xin Yi and Ekta Walia and Paul Babyn},
   title = {Unsupervised and semi-supervised learning with Categorical Generative Adversarial Networks assisted by Wasserstein distance for dermoscopy image Classification},
   url = {http://arxiv.org/abs/1804.03700},
   year = {2018},
}
@article{Arya2019,
   abstract = {As artificial intelligence and machine learning algorithms make further inroads into society, calls are increasing from multiple stakeholders for these algorithms to explain their outputs. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers, present different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 360 (http://aix360.mybluemix.net/), an open-source software toolkit featuring eight diverse and state-of-the-art explainability methods and two evaluation metrics. Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline. We also discuss enhancements to bring research innovations closer to consumers of explanations, ranging from simplified, more accessible versions of algorithms, to tutorials and an interactive web demo to introduce AI explainability to different audiences and application domains. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed.},
   author = {Vijay Arya and Rachel K. E. Bellamy and Pin-Yu Chen and Amit Dhurandhar and Michael Hind and Samuel C. Hoffman and Stephanie Houde and Q. Vera Liao and Ronny Luss and Aleksandra Mojsilović and Sami Mourad and Pablo Pedemonte and Ramya Raghavendra and John Richards and Prasanna Sattigeri and Karthikeyan Shanmugam and Moninder Singh and Kush R. Varshney and Dennis Wei and Yunfeng Zhang},
   title = {One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques},
   url = {http://arxiv.org/abs/1909.03012},
   year = {2019},
}
@article{FerrantediRuffano2018,
   abstract = {Background: Early accurate detection of all skin cancer types is essential to guide appropriate management and to improve morbidity and survival. Melanoma and cutaneous squamous cell carcinoma (cSCC) are high-risk skin cancers which have the potential to metastasise and ultimately lead to death, whereas basal cell carcinoma (BCC) is usually localised with potential to infiltrate and damage surrounding tissue. Anxiety around missing early curable cases needs to be balanced against inappropriate referral and unnecessary excision of benign lesions. Computer-assisted diagnosis (CAD) systems use artificial intelligence to analyse lesion data and arrive at a diagnosis of skin cancer. When used in unreferred settings ('primary care'), CAD may assist general practitioners (GPs) or other clinicians to more appropriately triage high-risk lesions to secondary care. Used alongside clinical and dermoscopic suspicion of malignancy, CAD may reduce unnecessary excisions without missing melanoma cases. Objectives: To determine the accuracy of CAD systems for diagnosing cutaneous invasive melanoma and atypical intraepidermal melanocytic variants, BCC or cSCC in adults, and to compare its accuracy with that of dermoscopy. Search methods: We undertook a comprehensive search of the following databases from inception up to August 2016: Cochrane Central Register of Controlled Trials (CENTRAL); MEDLINE; Embase; CINAHL; CPCI; Zetoc; Science Citation Index; US National Institutes of Health Ongoing Trials Register; NIHR Clinical Research Network Portfolio Database; and the World Health Organization International Clinical Trials Registry Platform. We studied reference lists and published systematic review articles. Selection criteria: Studies of any design that evaluated CAD alone, or in comparison with dermoscopy, in adults with lesions suspicious for melanoma or BCC or cSCC, and compared with a reference standard of either histological confirmation or clinical follow-up. Data collection and analysis: Two review authors independently extracted all data using a standardised data extraction and quality assessment form (based on QUADAS-2). We contacted authors of included studies where information related to the target condition or diagnostic threshold were missing. We estimated summary sensitivities and specificities separately by type of CAD system, using the bivariate hierarchical model. We compared CAD with dermoscopy using (a) all available CAD data (indirect comparisons), and (b) studies providing paired data for both tests (direct comparisons). We tested the contribution of human decision-making to the accuracy of CAD diagnoses in a sensitivity analysis by removing studies that gave CAD results to clinicians to guide diagnostic decision-making. Main results: We included 42 studies, 24 evaluating digital dermoscopy-based CAD systems (Derm-CAD) in 23 study cohorts with 9602 lesions (1220 melanomas, at least 83 BCCs, 9 cSCCs), providing 32 datasets for Derm-CAD and seven for dermoscopy. Eighteen studies evaluated spectroscopy-based CAD (Spectro-CAD) in 16 study cohorts with 6336 lesions (934 melanomas, 163 BCC, 49 cSCCs), providing 32 datasets for Spectro-CAD and six for dermoscopy. These consisted of 15 studies using multispectral imaging (MSI), two studies using electrical impedance spectroscopy (EIS) and one study using diffuse-reflectance spectroscopy. Studies were incompletely reported and at unclear to high risk of bias across all domains. Included studies inadequately address the review question, due to an abundance of low-quality studies, poor reporting, and recruitment of highly selected groups of participants. Across all CAD systems, we found considerable variation in the hardware and software technologies used, the types of classification algorithm employed, methods used to train the algorithms, and which lesion morphological features were extracted and analysed across all CAD systems, and even between studies evaluating CAD systems. Meta-analysis found CAD systems had high sensitivity for correct identification of cutaneous invasive melanoma and atypical intraepidermal melanocytic variants in highly selected populations, but with low and very variable specificity, particularly for Spectro-CAD systems. Pooled data from 22 studies estimated the sensitivity of Derm-CAD for the detection of melanoma as 90.1% (95% confidence interval (CI) 84.0% to 94.0%) and specificity as 74.3% (95% CI 63.6% to 82.7%). Pooled data from eight studies estimated the sensitivity of multispectral imaging CAD (MSI-CAD) as 92.9% (95% CI 83.7% to 97.1%) and specificity as 43.6% (95% CI 24.8% to 64.5%). When applied to a hypothetical population of 1000 lesions at the mean observed melanoma prevalence of 20%, Derm-CAD would miss 20 melanomas and would lead to 206 false-positive results for melanoma. MSI-CAD would miss 14 melanomas and would lead to 451 false diagnoses for melanoma. Preliminary findings suggest CAD systems are at least as sensitive as assessment of dermoscopic images for the diagnosis of invasive melanoma and atypical intraepidermal melanocytic variants. We are unable to make summary statements about the use of CAD in unreferred populations, or its accuracy in detecting keratinocyte cancers, or its use in any setting as a diagnostic aid, because of the paucity of studies. Authors' conclusions: In highly selected patient populations all CAD types demonstrate high sensitivity, and could prove useful as a back-up for specialist diagnosis to assist in minimising the risk of missing melanomas. However, the evidence base is currently too poor to understand whether CAD system outputs translate to different clinical decision-making in practice. Insufficient data are available on the use of CAD in community settings, or for the detection of keratinocyte cancers. The evidence base for individual systems is too limited to draw conclusions on which might be preferred for practice. Prospective comparative studies are required that evaluate the use of already evaluated CAD systems as diagnostic aids, by comparison to face-to-face dermoscopy, and in participant populations that are representative of those in which the test would be used in practice.},
   author = {Lavinia Ferrante di Ruffano and Yemisi Takwoingi and Jacqueline Dinnes and Naomi Chuchu and Susan E. Bayliss and Clare Davenport and Rubeta N. Matin and Kathie Godfrey and Colette O'sullivan and Abha Gulati and Sue Ann Chan and Alana Durack and Susan O'connell and Matthew D. Gardiner and Jeffrey Bamber and Jonathan J. Deeks and Hywel C. Williams},
   doi = {10.1002/14651858.CD013186},
   issn = {1469493X},
   issue = {12},
   journal = {Cochrane Database of Systematic Reviews},
   pmid = {30521691},
   title = {Computer-assisted diagnosis techniques (dermoscopy and spectroscopy-based) for diagnosing skin cancer in adults},
   year = {2018},
}
@article{Ribeiro2016,
   abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
   author = {Marco Ribeiro and Sameer Singh and Carlos Guestrin},
   doi = {10.18653/v1/n16-3020},
   journal = {ArXiv},
   pages = {97-101},
   title = {“Why Should I Trust You?”: Explaining the Predictions of Any Classifier},
   year = {2016},
}
@article{Murabayashi2019,
   abstract = {Although image-based melanoma diagnosis has achieved a sufficient level of numerical accuracy, providing objective evidence is essential to enhance the explainability and reliability of this approach. The collection of label information based on quantitative clinical indicators is very expensive, meaning that the amount of labeled data available is limited. In this paper, we propose an effective method for predicting explainable melanoma indicators defined by a 7-point checklist in a situation where only a limited number of labeled data are available. Our proposal effectively utilizes virtual adversarial training as a semi-supervised learning framework with multi-task learning. This approach gives favorable performance for only a very limited number of expensive labeled data. The proposed method improves the final accuracy of melanoma diagnosis calculated based on these predicted indices by 7.5% (making it equivalent to expert dermatologists), based on 9,124 unlabeled images with diagnosis information added to the 226 base labeled training images.},
   author = {Seiya Murabayashi and Hitoshi Iyatomi},
   journal = {IEEE International Conference on Big Data (Big Data)},
   pages = {4853-4857},
   title = {Towards Explainable Melanoma Diagnosis: Prediction of Clinical Indicators Using Semi-supervised and Multi-task Learning},
   url = {http://iyatomi-lab.info/sites/default/files/user/Murabayashi2019_IEEEBigData.pdf},
   year = {2019},
}
@article{Gilpin2019,
   abstract = {There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.},
   author = {Leilani H. Gilpin and David Bau and Ben Z. Yuan and Ayesha Bajwa and Michael Specter and Lalana Kagal},
   doi = {10.1109/DSAA.2018.00018},
   isbn = {9781538650905},
   journal = {Proceedings - 2018 IEEE 5th International Conference on Data Science and Advanced Analytics, DSAA 2018},
   keywords = {Deep learning and deep analytics,Fairness and transparency in data science,Machine learning theories,Models and systems},
   pages = {80-89},
   title = {Explaining explanations: An overview of interpretability of machine learning},
   year = {2019},
}
@inproceedings{Vasefi2017,
   author = {Fartash Vasefi and Nicholas B. MacKinnon and Nicholas Booth and Daniel L. Farkas},
   doi = {10.1117/12.2261501},
   pages = {51},
   title = {Improved heuristics for early melanoma detection using multimode hyperspectral dermoscopy (Conference Presentation)},
   year = {2017},
}
@article{Tjoa2019,
   abstract = {Recently, artificial intelligence, especially machine learning has demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning. Along with research progress, machine learning has encroached into many different fields and disciplines. Some of them, such as the medical field, require high level of accountability, and thus transparency, which means we need to be able to explain machine decisions, predictions and justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the black-box nature of the deep learning is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them, with the intention of providing alternative perspective that is hopefully more tractable for future adoption of interpretability standard. We explore further into interpretability in the medical field, illustrating the complexity of interpretability issue.},
   author = {Erico Tjoa and Cuntai Guan Fellow},
   doi = {10.1109/tnnls.2020.3027314},
   issn = {23318422},
   journal = {arXiv},
   title = {A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI},
   url = {http://arxiv.org/abs/1907.07374},
   year = {2019},
}
@article{Walters-Davies2015,
   author = {Rhiannon Walters-Davies},
   doi = {10.1211/cp.2013.11129534},
   journal = {Clinical Pharmacist},
   title = {Skin cancer: Types, diagnosis and prevention},
   year = {2015},
}
@article{Carpenter2018,
   abstract = {Objective: Optical spectroscopy offers a noninvasive alternative to biopsy as a first-line screening tool for suspicious skin lesions. This study sought to define several optical parameters across malignant and benign tissue types. Study Design: Prospective pilot trial utilizing the Zenalux IM1 optical spectroscopy device from April 2016 to February 2017. For each skin lesion, provider pre-biopsy probability of malignancy was compared to histolopathologic diagnosis. Optical data were characterized across basal cell carcinoma (BCC; n = 9), squamous cell carcinoma (SCC; n = 5), actinic keratosis (AK; n = 4), scar tissue (n = 6), nevus (n = 2), and neurofibroma (NF; n = 1). Across all patients, agreement was determined between control measurements collected adjacent to the lesion and from the upper extremity. Methods: Prospective single center pilot study. The optical properties of 27 cutaneous lesions were collected from 18 adult patients presenting to Otolaryngology and Dermatology clinics with suspicious skin lesions warranting biopsy. Spectroscopy measurements were recorded for each lesion: two at the lesion site, two at an adjacent site (internal control), and one at the central medial upper extremity (arm control). Variables of interest included absolute oxygenated hemoglobin (Hb), Hb saturation, total Hb concentration, and Eumelanin concentration. For each lesion, internal control averages were subtracted from lesion averages to provide delta parameter values, and lesion averages were divided by internal control averages to provide ratio parameter values. Results: Mean percent difference between pre-biopsy probability of malignancy and histology was 29%, with a difference of 75% or greater seen in 5 of 25 lesions. Mean values for BCC, SCC, AK, and scar tissue varied most between extracted mean reduced scatter estimate maacm−) delta values (BCC: −2.2 ± 3.8; SCC: −3.9 ± 2.0; AK: −3.3 ± 4.2, Scar: −1.7 ± 1.2) and total Hb (µM) ratio (BCC: 2.0 ± 3.3; SCC: 3.0 ± 1.3; AK: 1.1 ± 0.6; Scar: 1.4 ± 1.1). Agreement between local and arm controls was poor. Conclusion: This pilot trial utilizes optical spectroscopy as a noninvasive method for determining cutaneous lesion histology. Effect sizes observed across optical parameters for benign and malignant tissue types will guide larger prospective studies that may ultimately lead to prediction of lesional histology without need for invasive biopsy. Lasers Surg. Med. 50:246–252, 2018. © 2018 Wiley Periodicals, Inc.},
   author = {David J. Carpenter and Mirabelle B. Sajisevi and Nikita Chapurin and Clifford Scott Brown and Tracy Cheng and Gregory M. Palmer and Daniel S. Stevenson and Caroline L. Rao and Russell P. Hall and Charles R. Woodard},
   doi = {10.1002/lsm.22786},
   issn = {10969101},
   issue = {3},
   journal = {Lasers in Surgery and Medicine},
   keywords = {optical spectroscopy,skin cancer},
   pages = {246-252},
   title = {Noninvasive optical spectroscopy for identification of non-melanoma skin cancer: Pilot study},
   volume = {50},
   url = {http://www.embase.com/search/results?subaction=viewrecord&from=export&id=L621424350%0Ahttp://dx.doi.org/10.1002/lsm.22786},
   year = {2018},
}
@article{Jones2019,
   abstract = {Objective Most skin lesions first present in primary care, where distinguishing rare melanomas from benign lesions can be challenging. Dermoscopy improves diagnostic accuracy among specialists and is promoted for use by primary care physicians (PCPs). However, when used by untrained clinicians, accuracy may be no better than visual inspection. This study aimed to undertake a systematic review of literature reporting use of dermoscopy to triage suspicious skin lesions in primary care settings, and challenges for implementation. Design A systematic literature review and narrative synthesis. Data sources We searched MEDLINE, Cochrane Central, EMBASE, Cumulative Index to Nursing and Allied Health Literature, and SCOPUS bibliographic databases from 1 January 1990 to 31 December 2017, without language restrictions. Inclusion criteria Studies including assessment of dermoscopy accuracy, acceptability to patients and PCPs, training requirements, and cost-effectiveness of dermoscopy modes in primary care, including trials, diagnostic accuracy and acceptability studies. Results 23 studies met the review criteria, representing 49 769 lesions and 3708 PCPs, all from high-income countries. There was a paucity of studies set truly in primary care and the outcomes measured were diverse. The heterogeneity therefore made meta-analysis unfeasible; the data were synthesised through narrative review. Dermoscopy, with appropriate training, was associated with improved diagnostic accuracy for melanoma and benign lesions, and reduced unnecessary excisions and referrals. Teledermoscopy-based referral systems improved triage accuracy. Only three studies examined cost-effectiveness; hence, there was insufficient evidence to draw conclusions. Costs, training and time requirements were considered important implementation barriers. Patient satisfaction was seldom assessed. Computer-aided dermoscopy and other technological advances have not yet been tested in primary care. Conclusions Dermoscopy could help PCPs triage suspicious lesions for biopsy, urgent referral or reassurance. However, it will be important to establish further evidence on minimum training requirements to reach competence, as well as the cost-effectiveness and patient acceptability of implementing dermoscopy in primary care. Trial registration number CRD42018091395.},
   author = {O. T. Jones and L. C. Jurascheck and M. A. Van Melle and S. Hickman and N. P. Burrows and P. N. Hall and J. Emery and F. M. Walter},
   doi = {10.1136/bmjopen-2018-027529},
   issn = {20446055},
   issue = {8},
   journal = {BMJ Open},
   keywords = {dermoscopy,melanoma,primary care,skin cancer,systematic review},
   title = {Dermoscopy for melanoma detection and triage in primary care: A systematic review},
   volume = {9},
   year = {2019},
}
@article{Lundervold2019,
   abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artificial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding field we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI. Our aim is threefold: (i)give a brief introduction to deep learning with pointers to core references; (ii)indicate how deep learning has been applied to the entire MRI processing chain, from acquisition to image retrieval, from segmentation to disease prediction; (iii)provide a starting point for people interested in experimenting and perhaps contributing to the field of deep learning for medical imaging by pointing out good educational resources, state-of-the-art open-source code, and interesting sources of data and problems related medical imaging.},
   author = {Alexander Selvikvåg Lundervold and Arvid Lundervold},
   doi = {10.1016/j.zemedi.2018.11.002},
   issn = {18764436},
   issue = {2},
   journal = {Zeitschrift fur Medizinische Physik},
   keywords = {Deep learning,MRI,Machine learning,Medical imaging},
   pages = {102-127},
   title = {An overview of deep learning in medical imaging focusing on MRI},
   volume = {29},
   year = {2019},
}
@article{Rigel2010,
   abstract = {Early detection of malignant melanoma remains the key factor in lowering mortality from this cancer. Recognizing the importance of this issue 25 years ago, our group at New York University published in CA: A Cancer Journal for Clinicians the mnemonic "ABCD" to facilitate the early diagnosis of melanoma. Studies have demonstrated the usefulness of this paradigm in enhancing early melanoma diagnosis as a part of clinical examinations, mass screenings, and public education programs. Approaches to melanoma diagnosis have dynamically evolved during the ensuing quarter century. In the 1990s, dermoscopy enabled the recognition of new subsurface features to differentiate between malignant and benign pigmented lesions. During the last decade, new computer-based technologies have improved diagnostic sensitivity and specificity and may result in optimizing lesion selection for biopsy and pathology review. Despite all of the advances in melanoma diagnosis, timely recognition, detection, and rapid treatment of melanoma remain critical. Although pathologic examination remains the gold standard for diagnosis, this cancer has the potential to be diagnosed through noninvasive approaches because of its cutaneous location. From the development of the ABCDs through current attempts that use complex computer algorithms and genetic markers, a clinician's ability to detect melanoma in its earliest form has been augmented. However, a "good clinical eye" is still fundamental to selecting the lesions for evaluation among the sea of those that are prevalent. As current approaches are refined and new techniques are developed, the improved ability to diagnose this cancer will hopefully enhance reaching the goal of reducing melanoma mortality.},
   author = {D. S. Rigel and J. Russak and R. Friedman},
   doi = {10.3322/caac.20074},
   issn = {0007-9235},
   issue = {5},
   journal = {CA: A Cancer Journal for Clinicians},
   pages = {301-316},
   title = {The Evolution of Melanoma Diagnosis: 25 Years Beyond the ABCDs},
   volume = {60},
   year = {2010},
}
@article{Gessert2019,
   abstract = {The initial assessment of skin lesions is typically based on dermoscopic images. As this is a difficult and time-consuming task, machine learning methods using dermoscopic images have been proposed to assist human experts. Other approaches have studied electrical impedance spectroscopy (EIS) as a basis for clinical decision support systems. Both methods represent different ways of measuring skin lesion properties as dermoscopy relies on visible light and EIS uses electric currents. Thus, the two methods might carry complementary features for lesion classification. Therefore, we propose joint deep learning models considering both EIS and dermoscopy for melanoma detection. For this purpose, we first study machine learning methods for EIS that incorporate domain knowledge and previously used heuristics into the design process. As a result, we propose a recurrent model with state-max-pooling which automatically learns the relevance of different EIS measurements. Second, we combine this new model with different convolutional neural networks that process dermoscopic images. We study ensembling approaches and also propose a cross-attention module guiding information exchange between the EIS and dermoscopy model. In general, combinations of EIS and dermoscopy clearly outperform models that only use either EIS or dermoscopy. We show that our attention-based, combined model outperforms other models with specificities of 34.4% (CI 31.3-38.4), 34.7% (CI 31.0-38.8) and 53.7% (CI 50.1-57.6) for dermoscopy, EIS and the combined model, respectively, at a clinically relevant sensitivity of 98%.},
   author = {Nils Gessert and Marcel Bengs and Alexander Schlaefer},
   doi = {10.1117/12.2548974},
   journal = {ArXiv},
   pages = {37},
   title = {Melanoma detection with electrical impedance spectroscopy and dermoscopy using joint deep learning models},
   url = {http://arxiv.org/abs/1911.02322},
   year = {2020},
}
@article{Gupta2016,
   abstract = {Background: Though people of color (POC) are less likely to become afflicted with skin cancer, they are much more likely to die from it due to delay in detection or presentation. Very often, skin cancer is diagnosed at a more advanced stage in POC, making treatment difficult.The purpose of this research was to improve awareness regarding skin cancers in people of color by providing recommendations to clinicians and the general public for early detection and photo protection preventive measures. Methods: Data on different types of skin cancers were presented to POC. Due to limited research, there are few resources providing insights for evaluating darkly pigmented lesions in POC. Diagnostic features for different types of skin cancers were recorded and various possible risk factors were considered. Results: This study provided directions for the prevention and early detection of skin cancer in POC based on a comprehensive review of available data. Conclusions: The increased morbidity and mortality rate associated with skin cancer in POC is due to lack of awareness, diagnosis at a more advanced stage and socioeconomic barriers hindering access to care. Raising public health concerns for skin cancer prevention strategies for all people, regardless of ethnic background and socioeconomic status, is the key to timely diagnosis and treatment.},
   author = {Alpana K. Gupta and Mausumi Bharadwaj and Ravi Mehrotra},
   doi = {10.22034/APJCP.2016.17.12.6157},
   issn = {2476762X},
   issue = {12},
   journal = {Asian Pacific Journal of Cancer Prevention},
   keywords = {Skin Cancer,people of color,risk and prevention,types},
   pages = {6157-6164},
   pmid = {28125871},
   title = {Skin cancer concerns in people of color: Risk factors and prevention},
   volume = {17},
   year = {2016},
}
@article{Zhuang2019,
   abstract = {Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. As the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Different from previous surveys, this survey paper reviews over forty representative transfer learning approaches from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, twenty representative transfer learning models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Office-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.},
   author = {Fuzhen Zhuang and Zhiyuan Qi and Keyu Duan and Dongbo Xi and Yongchun Zhu and Hengshu Zhu and Hui Xiong and Qing He},
   title = {A Comprehensive Survey on Transfer Learning},
   url = {Transfer},
   year = {2019},
}
@article{A.2014,
   abstract = {RATIONALE: Malignant melanoma (MM) is the cutaneous neoplasia with the greatest mortality rates and one of the malignancies with the highest potential of dissemination. The prognosis of patients with metastatic MM is grim, with a 5-years survival rate between 5-19%, and is dictated by the location and the number of metastases.
OBJECTIVE: We aimed to estimate the survival of patients with metastatic MM from our study and find out if the metastasis' location influences survival.
METHODS AND RESULTS: Between 2008 and 2013, 155 patients with cutaneous MM were diagnosed in our clinic. All the patients were staged according to 2009 AJCC staging system. The median follow-up period was of 24 months. Survival was calculated by using the Kaplan-Meier method with a confidence level of 95%. 40.5% of the patients developed metastases in different organs, especially the brain. 80.6% of those with metastases died during the study. The median overall survival, estimated for the entire group of patients who developed metastases, was of 5.3 months.
DISCUSSION: The influence of metastases distribution on the overall survival was examined and it was noticed that there were statistically significant differences between the risks of death of various groups of patients, depending on metastasis topography. Thus, the death probability of a patient with brain metastases is twice that of a patient with digestive metastasis, about 7 times higher than that of a patient with lung metastasis (p=0.0004) and 12 times higher than the death risk of a patient with extra-regional lymph nodes or subcutaneous metastasis (p=0.0000).},
   author = {A. Sandru and S. Voinea and E. Panaitescu and A. Blidaru},
   issn = {18443117},
   issue = {4},
   journal = {Journal of medicine and life},
   keywords = {malignant melanoma,metastasis distribution,survival rates},
   pages = {572-576},
   pmid = {25713625},
   title = {Survival rates of patients with metastatic malignant melanoma},
   volume = {7},
   url = {http://openurl.ebscohost.com/linksvc/linking.aspx?authtype=athens&genre=article&issn=1844-122X&volume=7&issue=4&spage=572%0Ahttp://gateway.proquest.com/openurl?ctx_ver=Z39.88-2004&res_id=xri:pqm&req_dat=xri:pqil:pq_clntid=48094&rft_val_fmt=ori/fmt:kev:mtx},
   year = {2014},
}
@inproceedings{Simonyan2015,
   abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
   author = {Karen Simonyan and Andrew Zisserman},
   journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
   title = {Very deep convolutional networks for large-scale image recognition},
   year = {2015},
}
@article{Argenziano2001,
   abstract = {The clinical use of dermoscopy has uncovered a new and fascinating morphological dimension of pigmented skin lesions. Dermoscopy is a non-invasive diagnostic technique that links clinical dermatology and dermatopathology by enabling the visualisation of morphological features not seen by the naked eye. Close examination of pigmented skin lesions in this way increases the effectiveness of clinical diagnostic tools by providing new morphological criteria for distinguishing melanoma from other melanocytic and non-melanocytic pigmented skin lesions.In the past, dermoscopy has been known by various names, including skin surface microscopy, epiluminescence microscopy, incident light microscopy, dermatoscopy, and videodermatoscopy. However, the term 'dermoscopy', first used by Friedman and colleagues in 1991 1, is the most widely used. © 2001 Elsevier Science Ltd.},
   author = {Giuseppe Argenziano and H. Peter Soyer},
   doi = {10.1016/S1470-2045(00)00422-8},
   issn = {14702045},
   issue = {7},
   journal = {Lancet Oncology},
   pages = {443-449},
   pmid = {11905739},
   title = {Dermoscopy of pigmented skin lesions - a valuable tool for early diagnosis of melanoma},
   volume = {2},
   year = {2001},
}
@article{Dalila2017,
   abstract = {The incidence ofmalignant melanoma has been increasing worldwide. An efficient non-invasive computer-aided diagnosis (CAD) is seen as a solution to make identification process faster, and accessible to a large population. Such automated system relies on three things: reliable lesion segmentation, pertinent features’ extraction and good lesion classifier. In this paper, we propose an automated system that uses an Ant colony based segmentation algorithm, takes into consideration three types of features to describe malignant lesion:geometrical properties, textureand relative colors from which pertinent ones are selected, and uses two classifiers K-Nearest Neighbor (KNN) and Artificial Neural Network (ANN). The objective of this paper is to test the efficiency of the proposed segmentation algorithm, extract most pertinent features that describe melanomas and compare the two classifiers. Our automated system is tested on 172 dermoscopic images where 88 are malignant melanomas and 84 benign lesions. The results of the proposed segmentation algorithm are encouraging as they gave promising results. 12 features seem to be sufficient to detect malignant melanoma. Moreover, ANN gives better results than KNN.},
   author = {Fekrache Dalila and Ameur Zohra and Kasmi Reda and Cherifi Hocine},
   doi = {10.1016/j.ijleo.2017.04.084},
   issn = {00304026},
   journal = {Optik},
   keywords = {Ant colony,Computer-aided diagnosis,Dermoscopy,Feature extraction,K-Nearest Neighbor,Melanoma,Neural network,Segmentation},
   pages = {749-761},
   title = {Segmentation and classification of melanoma and benign skin lesions},
   volume = {140},
   year = {2017},
}
@article{Masood2013,
   abstract = {Accurate segmentation is an important and challenging task in any computer vision system. It also plays a vital role in computerized analysis of skin lesion images. This paper presents a new segmentation method that combines the advantages of fuzzy C mean algorithm, thresholding and level set method. 3-class Fuzzy C mean thresholding is applied to initialize level set automatically and also for estimating controlling parameters for level set evolution. Parameters for performance evaluation are presented and segmentation results are compared with some other state-of-the-art segmenta-tion methods. Increased true detection rate and reduced false positive and false negative errors confirm the effectiveness of proposed method for skin cancer detection.},
   author = {Ammara Masood and Adel Ali Al-Jumaily},
   doi = {10.4236/jsip.2013.43b012},
   issn = {2159-4465},
   issue = {03},
   journal = {Journal of Signal and Information Processing},
   pages = {66-71},
   title = {Fuzzy C Mean Thresholding based Level Set for Automated Segmentation of Skin Lesions},
   volume = {04},
   year = {2013},
}
@article{Thiers2009,
   abstract = {Background: Dermoscopy is a noninvasive technique that enables the clinician to perform direct microscopic examination of diagnostic features, not seen by the naked eye, in pigmented skin lesions. Diagnostic accuracy of dermoscopy has previously been assessed in meta-analyses including studies performed in experimental and clinical settings. Objectives: To assess the diagnostic accuracy of dermoscopy for the diagnosis of melanoma compared with naked eye examination by performing a meta-analysis exclusively on studies performed in a clinical setting. Methods: We searched for publications from 1987 to January 2008 and found nine eligible studies. The selected studies compare diagnostic accuracy of dermoscopy with naked eye examination using a valid reference test on consecutive patients with a defined clinical presentation, performed in a clinical setting. Hierarchical summary receiver operator curve analysis was used to estimate the relative diagnostic accuracy for clinical examination with, and without, the use of dermoscopy. Results: We found the relative diagnostic odds ratio for melanoma, for dermoscopy compared with naked eye examination, to be 15.6 [95% confidence interval (CI) 2.9-83.7, P = 0.016]; removal of two outlier studies changed this to 9.0 (95% CI 1.5-54.6, P = 0.03). Conclusions: Dermoscopy is more accurate than naked eye examination for the diagnosis of cutaneous melanoma in suspicious skin lesions when performed in the clinical setting. (copyright) 2008 Australian Cancer Network.},
   author = {B.H. Thiers},
   doi = {10.1016/s0093-3619(08)79154-8},
   issn = {00933619},
   journal = {Yearbook of Dermatology and Dermatologic Surgery},
   pages = {378-379},
   title = {Dermoscopy compared with naked eye examination for the diagnosis of primary melanoma: a meta-analysis of studies performed in a clinical setting},
   volume = {2009},
   year = {2009},
}
@article{Tschandl2018,
   abstract = {Training of neural networks for automated diagnosis of pigmented skin lesions is hampered by the small size and lack of diversity of available datasets of dermatoscopic images. We tackle this problem by releasing the HAM10000 (“Human Against Machine with 10000 training images”) dataset. We collected dermatoscopic images from different populations acquired and stored by different modalities. Given this diversity we had to apply different acquisition and cleaning methods and developed semi-automatic workflows utilizing specifically trained neural networks. The final dataset consists of 10015 dermatoscopic images which are released as a training set for academic machine learning purposes and are publicly available through the ISIC archive. This benchmark dataset can be used for machine learning and for comparisons with human experts. Cases include a representative collection of all important diagnostic categories in the realm of pigmented lesions. More than 50% of lesions have been confirmed by pathology, while the ground truth for the rest of the cases was either follow-up, expert consensus, or confirmation by in-vivo confocal microscopy.},
   author = {Philipp Tschandl and Cliff Rosendahl and Kittler Hararld},
   journal = {Sci Data 5},
   title = {The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions},
   url = {https://doi.org/10.1038/sdata.2018.161},
   year = {2018},
}
@article{Codella2018,
   abstract = {This article describes the design, implementation, and results of the latest installment of the dermoscopic image analysis benchmark challenge. The goal is to support research and development of algorithms for automated diagnosis of melanoma, the most lethal skin cancer. The challenge was divided into 3 tasks: lesion segmentation, feature detection, and disease classification. Participation involved 593 registrations, 81 pre-submissions, 46 finalized submissions (including a 4-page manuscript), and approximately 50 attendees, making this the largest standardized and comparative study in this field to date. While the official challenge duration and ranking of participants has concluded, the dataset snapshots remain available for further research and development.},
   author = {Noel C.F. Codella and David Gutman and M. Emre Celebi and Brian Helba and Michael A. Marchetti and Stephen W. Dusza and Aadi Kalloo and Konstantinos Liopyris and Nabin Mishra and Harald Kittler and Allan Halpern},
   doi = {10.1109/ISBI.2018.8363547},
   isbn = {9781538636367},
   issn = {19458452},
   journal = {Proceedings - International Symposium on Biomedical Imaging},
   keywords = {Challenge,Dataset,Deep learning,Dermatology,Dermoscopy,Melanoma,Skin cancer},
   pages = {168-172},
   title = {Skin lesion analysis toward melanoma detection: A challenge at the 2017 International symposium on biomedical imaging (ISBI), hosted by the international skin imaging collaboration (ISIC)},
   volume = {2018-April},
   year = {2018},
}
@article{Giotis2015,
   abstract = {Melanoma is one of the most aggressive types of skin cancer and in many cases it is difficult to differentiate from benign naevi. In this contribution we present a decision support (expert) system, which we call MED-NODE, able to assist physicians with this challenging task. The proposed system makes use of non-dermoscopic digital images of lesions from which it automatically extracts the lesion regions and then computes descriptors regarding the color and texture. In addition, a set of visual attributes is provided by the examining physician. The automatically extracted descriptors and the attributes provided by the physician are separately used for automatic prediction. Final classification is achieved by a majority vote of all predictions. The proposed system achieves high diagnostic accuracy results (81%) and performs comparably to state-of-the-art methods that are using dermoscopic images, though such images contain more detailed information and are subject to less noise and illumination effects. The simple input requirements and the robustness of its descriptors allow MED-NODE to be an effective tool within the diagnostic process for melanoma. In addition, the modular nature of the system allows for it to be easily extended.},
   author = {Ioannis Giotis and Nynke Molders and Sander Land and Michael Biehl and Marcel F. Jonkman and Nicolai Petkov},
   doi = {10.1016/j.eswa.2015.04.034},
   issn = {09574174},
   issue = {19},
   journal = {Expert Systems with Applications},
   keywords = {Classification,Computer-assisted diagnosis,Dermatology,Medical imaging,Melanoma},
   pages = {6578-6585},
   title = {MED-NODE: A computer-assisted melanoma diagnosis system using non-dermoscopic images},
   volume = {42},
   year = {2015},
}
@article{Glaister2014,
   abstract = {Melanoma is the deadliest form of skin cancer. Incidence rates of melanoma have been increasing, especially among non-Hispanic white males and females, but survival rates are high if detected early. Due to the costs for dermatologists to screen every patient, there is a need for an automated system to assess a patient's risk of melanoma using images of their skin lesions captured using a standard digital camera. One challenge in implementing such a system is locating the skin lesion in the digital image. A novel texture-based skin lesion segmentation algorithm is proposed. A set of representative texture distributions are learned from an illumination-corrected photograph and a texture distinctiveness metric is calculated for each distribution. Next, regions in the image are classified as normal skin or lesion based on the occurrence of representative texture distributions. The proposed segmentation framework is tested by comparing lesion segmentation results and melanoma classification results to results using other state-of-art algorithms. The proposed framework has higher segmentation accuracy compared to all other tested algorithms. © 1964-2012 IEEE.},
   author = {Jeffrey Glaister and Alexander Wong and David A. Clausi},
   doi = {10.1109/TBME.2013.2297622},
   issn = {15582531},
   issue = {4},
   journal = {IEEE Transactions on Biomedical Engineering},
   keywords = {Melanoma,segmentation,skin cancer,texture},
   pages = {1220-1230},
   title = {Segmentation of skin lesions from digital images using joint statistical texture distinctiveness},
   volume = {61},
   year = {2014},
}
@article{M.A.2020,
   abstract = {Background: Computer vision has promise in image-based cutaneous melanoma diagnosis but clinical utility is uncertain. Objective: To determine if computer algorithms from an international melanoma detection challenge can improve dermatologists' accuracy in diagnosing melanoma. Methods: In this cross-sectional study, we used 150 dermoscopy images (50 melanomas, 50 nevi, 50 seborrheic keratoses) from the test dataset of a melanoma detection challenge, along with algorithm results from 23 teams. Eight dermatologists and 9 dermatology residents classified dermoscopic lesion images in an online reader study and provided their confidence level. Results: The top-ranked computer algorithm had an area under the receiver operating characteristic curve of 0.87, which was higher than that of the dermatologists (0.74) and residents (0.66) (P < .001 for all comparisons). At the dermatologists' overall sensitivity in classification of 76.0%, the algorithm had a superior specificity (85.0% vs. 72.6%, P = .001). Imputation of computer algorithm classifications into dermatologist evaluations with low confidence ratings (26.6% of evaluations) increased dermatologist sensitivity from 76.0% to 80.8% and specificity from 72.6% to 72.8%. Limitations: Artificial study setting lacking the full spectrum of skin lesions as well as clinical metadata. Conclusion: Accumulating evidence suggests that deep neural networks can classify skin images of melanoma and its benign mimickers with high accuracy and potentially improve human performance.},
   author = {Marchetti M.A. and Liopyris K. and Dusza S.W. and Codella N.C.F. and Gutman D.A. and Helba B. and Kalloo A. and Halpern A.C. and Soyer H.P. and Curiel-Lewandrowski C. and Caffery L. and Malvehy J.},
   doi = {10.1016/j.jaad.2019.07.016 LK - http://elinks.library.upenn.edu/sfx_local?sid=EMBASE&issn=10976787&id=doi:10.1016%2Fj.jaad.2019.07.016&atitle=Computer+algorithms+show+potential+for+improving+dermatologists%27+accuracy+to+diagnose+cutaneous+melanoma%3A+Results+of+the+International+Skin+Imaging+Collaboration+2017&stitle=J.+Am.+Acad.+Dermatol.&title=Journal+of+the+American+Academy+of+Dermatology&volume=&issue=&spage=&epage=&aulast=Marchetti&aufirst=Michael+A.&auinit=M.A.&aufull=Marchetti+M.A.&code},
   issn = {1097-6787},
   journal = {Journal of the American Academy of Dermatology},
   keywords = {adult,algorithm,article,clinical article,computer vision,controlled study,cross-sectional study,cutaneous melanoma,deep learning,deep neural network,dermatologist,diagnostic test accuracy study,epiluminescence microscopy,female,human,male,melanoma,metadata,nevus,receiver operating characteristic,resident,seborrheic keratosis,sensitivity and specificity,skin cancer,skin defect},
   title = {Computer algorithms show potential for improving dermatologists' accuracy to diagnose cutaneous melanoma: Results of the International Skin Imaging Collaboration 2017},
   url = {http://www.embase.com/search/results?subaction=viewrecord&from=export&id=L2004600958%0Ahttp://dx.doi.org/10.1016/j.jaad.2019.07.016},
   year = {2020},
}
@article{Erkol2005,
   abstract = {Background: Malignant melanoma has a good prognosis if treated early. Dermoscopy images of pigmented lesions are most commonly taken at × 10 magnification under lighting at a low angle of incidence while the skin is immersed in oil under a glass plate. Accurate skin lesion segmentation from the background skin is important because some of the features anticipated to be used for diagnosis deal with shape of the lesion and others deal with the color of the lesion compared with the color of the surrounding skin. Methods: In this research, gradient vector flow (GVF) snakes are investigated to find the border of skin lesions in dermoscopy images. An automatic initialization method is introduced to make the skin lesion border determination process fully automated. Results: Skin lesion segmentation results are presented for 70 benign and 30 melanoma skin lesion images for the GVF-based method and a color histogram analysis technique. The average errors obtained by the GVF-based method are lower for both the benign and melanoma image sets than for the color histogram analysis technique based on comparison with manually segmented lesions determined by a dermatologist. Conclusions: The experimental results for the GVF-based method demonstrate promise as an automated technique for skin lesion segmentation in dermoscopy images. © Blackwell Munksgaard, 2005.},
   author = {Bulent Erkol and Randy H. Moss and R. Joe Stanley and William V. Stoecker and Erik Hvatum},
   doi = {10.1111/j.1600-0846.2005.00092.x},
   issn = {0909752X},
   issue = {1},
   journal = {Skin Research and Technology},
   keywords = {Active contours,Boundary,Dermoscopy,Gradient vector flow snakes,Image processing,Melanoma},
   pages = {17-26},
   title = {Automatic lesion boundary detection in dermoscopy images using gradient vector flow snakes},
   volume = {11},
   year = {2005},
}
@article{Prathiba2019,
   abstract = {Automated melanoma recognition using image processing technique from the available dermoscopic images in deep learning is difficult task because of the contrast and variation of melanoma in skin. It is mainly a non-invasive method so that it cannot contact with skin more forcefully. To overcome these disadvantages this research work proposes a method using very deep convolutional neural networks (CNNs). For more accurate classification in this method we are using FCRN and CNN with the effective training limited data. Initially, Performance of Segmentation is done using residual networks using a image from the dataset followed by Classification by neural networks to check the abnormalities in skin. In this kind of classification technique the network has more specified features from the segmented portion alone. The proposed technique is mainly evaluated on datasets and experimental results that would show the performance in histogram and PSNR ratio.},
   author = {M. Prathiba and Deepa Jose and R. Saranya and Nandhinidevi},
   doi = {10.1088/1757-899X/561/1/012107},
   issn = {1757899X},
   issue = {1},
   journal = {IOP Conference Series: Materials Science and Engineering},
   title = {Automated Melanoma Recognition in Dermoscopy Images via Very Deep Residual Networks},
   volume = {561},
   year = {2019},
}
@article{Suer2011,
   abstract = {Background: Dermoscopy is one of the major imaging modalities used in the diagnosis of melanoma and other pigmented skin lesions. In current practice, dermatologists determine lesion area by manually drawing lesion borders. Therefore, automated assessment tools for dermoscopy images have become an important research field mainly because of inter- and intra-observer variations in human interpretation. One of the most important steps in dermoscopy image analysis is automated detection of lesion borders. To our knowledge, in our 2010 study we achieved one of the highest accuracy rates in the automated lesion border detection field by using modified density based clustering algorithm. In the previous study, we proposed a novel method which removes redundant computations in well-known spatial density based clustering algorithm, DBSCAN; thus, in turn it speeds up clustering process considerably.Findings: Our previous study was heavily dependent on the pre-processing step which creates a binary image from original image. In this study, we embed a new distance measure to the existing algorithm. This provides twofold benefits. First, since new approach removes pre-processing step, it directly works on color images instead of binary ones. Thus, very important color information is not lost. Second, accuracy of delineated lesion borders is improved on 75% of 100 dermoscopy image dataset.Conclusion: Previous and improved methods are tested within the same dermoscopy dataset along with the same set of dermatologist drawn ground truth images. Results revealed that the improved method directly works on color images without any pre-processing and generates more accurate results than existing method. © 2011 Suer et al; licensee BioMed Central Ltd.},
   author = {Sait Suer and Sinan Kockara and Mutlu Mete},
   doi = {10.1186/1471-2105-12-S10-S12},
   issn = {14712105},
   issue = {SUPPL. 10},
   journal = {BMC Bioinformatics},
   title = {An improved border detection in dermoscopy images for density based clustering},
   volume = {12},
   year = {2011},
}
@article{Yuan2017,
   abstract = {Automatic skin lesion segmentation in dermoscopic images is a challenging task due to the low contrast between lesion and the surrounding skin, the irregular and fuzzy lesion borders, the existence of various artifacts, and various imaging acquisition conditions. In this paper, we present a fully automatic method for skin lesion segmentation by leveraging 19-layer deep convolutional neural networks that is trained end-to-end and does not rely on prior knowledge of the data. We propose a set of strategies to ensure effective and efficient learning with limited training data. Furthermore, we design a novel loss function based on Jaccard distance to eliminate the need of sample re-weighting, a typical procedure when using cross entropy as the loss function for image segmentation due to the strong imbalance between the number of foreground and background pixels. We evaluated the effectiveness, efficiency, as well as the generalization capability of the proposed framework on two publicly available databases. One is from ISBI 2016 skin lesion analysis towards melanoma detection challenge, and the other is the PH2 database. Experimental results showed that the proposed method outperformed other state-of-the-art algorithms on these two databases. Our method is general enough and only needs minimum pre- and post-processing, which allows its adoption in a variety of medical image segmentation tasks.},
   author = {Yading Yuan and Ming Chao and Yeh Chi Lo},
   doi = {10.1109/TMI.2017.2695227},
   issn = {1558254X},
   issue = {9},
   journal = {IEEE Transactions on Medical Imaging},
   keywords = {Deep learning,dermoscopy,fully convolutional neural networks,image segmentation,jaccard distance,melanoma},
   pages = {1876-1886},
   title = {Automatic Skin Lesion Segmentation Using Deep Fully Convolutional Networks with Jaccard Distance},
   volume = {36},
   year = {2017},
}
@article{Krizhevsky2012,
   abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
   author = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
   doi = {10.1145/3065386},
   isbn = {9781627480031},
   issn = {15577317},
   issue = {6},
   journal = {Communications of the ACM},
   pages = {84-90},
   title = {ImageNet classification with deep convolutional neural networks},
   volume = {60},
   year = {2017},
}
@article{Szegedy2015,
   abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
   author = {Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
   doi = {10.1109/CVPR.2015.7298594},
   isbn = {9781467369640},
   issn = {10636919},
   journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   pages = {1-9},
   title = {Going deeper with convolutions},
   volume = {07-12-June},
   year = {2015},
}
@article{Yuan2017a,
   abstract = {Automatic skin lesion segmentation on dermoscopic images is an essential step in computer-aided diagnosis of melanoma. However, this task is challenging due to significant variations of lesion appearances across different patients. This challenge is further exacerbated when dealing with a large amount of image data. In this paper, we extended our previous work by developing a deeper network architecture with smaller kernels to enhance its discriminant capacity. In addition, we explicitly included color information from multiple color spaces to facilitate network training and thus to further improve the segmentation performance. We participated and extensively evaluated our method on the ISBI 2017 skin lesion segmentation challenge. By training with the 2000 challenge training images, our method achieved an average Jaccard Index of 0.765 on the 600 challenge testing images, which ranked itself in the first place among 21 final submissions in the challenge.},
   author = {Yading Yuan and Yeh Chi Lo},
   doi = {10.1109/JBHI.2017.2787487},
   issn = {21682194},
   issue = {2},
   journal = {IEEE Journal of Biomedical and Health Informatics},
   keywords = {Dermoscopic images,deep learning,fully convolutional neural networks,image segmentation,jaccard distance,melanoma},
   pages = {519-526},
   pmid = {29990146},
   title = {Improving Dermoscopic Image Segmentation With Enhanced Convolutional-Deconvolutional Networks},
   volume = {23},
   url = {http://arxiv.org/abs/1703.05165%0Ahttp://dx.doi.org/10.1109/JBHI.2017.2787487},
   year = {2019},
}
@article{Goyal2017,
   author = {Manu Goyal and Amanda Oakley and Priyanka Bansal and Darren Dancey and Moi Hoon Yap and Senior Member},
   issue = {X},
   pages = {1-7},
   title = {Skin Lesion Segmentation in Dermoscopic Images with Ensemble Deep Learning Methods},
   volume = {XX},
   year = {2017},
}
@article{Zhou2008,
   abstract = {Dermoscopy is a technique used to better visualize pigmented skin lesion and aid the clinician in determining if a lesion is benign or malignant. Automated segmentation of dermoscopy images is an important step for computer-aided diagnosis of melanoma. In this paper, we investigate how to use the spatial constraints present in pigmented lesions to improve the segmentation of dermoscopy images. We present an unsupervised segmentation algorithm that embeds these constraints into the feature space. The algorithm groups image pixels with homogeneous properties, and merges the pixel groups into a few super-regions. The optimal lesionskin boundary is chosen from the set of all region boundaries, where the optimality is determined from the color and texture properties of the regions. We test our method on 67 dermoscopy images and compare the automatically generated segmentation with dermatologist-determined segmentation. The results demonstrate the advantage of incorporating domain-specific constraints into the segmentation process. ©2008 IEEE.},
   author = {Howard Zhou and Mei Chen and Le Zou and Richard Gass and Laura Ferris and Laura Drogowski and James M. Rehg},
   doi = {10.1109/ISBI.2008.4541117},
   isbn = {9781424420032},
   journal = {2008 5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro, Proceedings, ISBI},
   keywords = {Computer-assisted image interpretation,Coordinate system,Dermoscopy,Pigmented skin lesion,Segmentation},
   pages = {800-803},
   title = {Spatially constrained segmentation of dermoscopy images},
   year = {2008},
}
@article{Beuren2012,
   abstract = {This paper presents a segmentation approach of melanoma by color morphology. The images of melanoma are filtered by morphological tools using a lexicographic order onto HSI color space. A thresholding technique is applied to segment the melanoma Region of Interest (ROI). Binary morphological techniques are used to filter the ROI. The approach was tested on two benign and malignant image databases, both containing 100 images, and the results were compared to ground-truth segmentation and Fuzzy CMeans one. By performing twelve metrics, the results have shown the promising aspects of this approach to segment benign and malignant lesions. © 2012 Institute of Telecommunica.},
   author = {Arlete T. Beuren and Rodrigo J.G. Pinheiro and Jacques Facon},
   isbn = {9783200023284},
   journal = {2012 19th International Conference on Systems, Signals and Image Processing, IWSSIP 2012},
   keywords = {Ground-truth,Mathematical Morphology,Melanoma,Segmentation},
   pages = {284-287},
   title = {Color approach of melanoma lesion segmentation},
   year = {2012},
}
@article{O.2015,
   abstract = {Melanoma spreads through metastasis, and therefore, it has been proved to be very fatal. Statistical evidence has revealed that the majority of deaths resulting from skin cancer are as a result of melanoma. Further investigations have shown that the survival rates in patients depend on the stage of the cancer; early detection and intervention of melanoma implicate higher chances of cure. Clinical diagnosis and prognosis of melanoma are challenging, since the processes are prone to misdiagnosis and inaccuracies due to doctors' subjectivity. Malignant melanomas are asymmetrical, have irregular borders, notched edges, and color variations, so analyzing the shape, color, and texture of the skin lesion is important for the early detection and prevention of melanoma. This paper proposes the two major components of a noninvasive real-time automated skin lesion analysis system for the early detection and prevention of melanoma. The first component is a real-time alert to help users prevent skinburn caused by sunlight; a novel equation to compute the time for skin to burn is thereby introduced. The second component is an automated image analysis module, which contains image acquisition, hair detection and exclusion, lesion segmentation, feature extraction, and classification. The proposed system uses PH2 Dermoscopy image database from Pedro Hispano Hospital for the development and testing purposes. The image database contains a total of 200 dermoscopy images of lesions, including benign, atypical, and melanoma cases. The experimental results show that the proposed system is efficient, achieving classification of the benign, atypical, and melanoma images with accuracy of 96.3%, 95.7%, and 97.5%, respectively.},
   author = {Abuzaghleh O. and Barkana B.D. and Faezipour M.},
   doi = {10.1109/JTEHM.2015.2419612 LK  - http://limo.libis.be/resolver?&sid=EMBASE&issn=21682372&id=doi:10.1109%2FJTEHM.2015.2419612&atitle=Noninvasive+real-time+automated+skin+lesion+analysis+system+for+melanoma+early+detection+and+prevention&stitle=IEEE+J.+Transl.+Eng.+Health+Med.&title=IEEE+Journal+of+Translational+Engineering+in+Health+and+Medicine&volume=3&issue=&spage=&epage=&aulast=Abuzaghleh&aufirst=Omar&auinit=O.&aufull=Abuzaghleh+O.&coden=&isbn=&pages=-&date=2015&auinit1=O&auinitm=},
   issn = {2168-2372},
   journal = {IEEE Journal of Translational Engineering in Health and Medicine},
   keywords = {Fourier transformation,Internet,article,automation,cancer classification,cancer prevention,classification algorithm,data base,dermatological equipment,dermoscope,diagnostic accuracy,diagnostic imaging,early diagnosis,epiluminescence microscopy,hair,human,image analysis,image processing,melanoma,microscope,mobile application,mobile phone,non invasive procedure,noninvasive real time automated skin lesion analys,sunburn,sunlight},
   title = {Noninvasive real-time automated skin lesion analysis system for melanoma early detection and prevention},
   volume = {3},
   url = {http://www.embase.com/search/results?subaction=viewrecord&from=export&id=L603867553%0Ahttp://dx.doi.org/10.1109/JTEHM.2015.2419612},
   year = {2015},
}
@article{Jafari2016,
   abstract = {Melanoma is the most aggressive form of skin cancer and is on rise. There exists a research trend for computerized analysis of suspicious skin lesions for malignancy using images captured by digital cameras. Analysis of these images is usually challenging due to existence of disturbing factors such as illumination variations and light reflections from skin surface. One important stage in diagnosis of melanoma is segmentation of lesion region from normal skin. In this paper, a method for accurate extraction of lesion region is proposed that is based on deep learning approaches. The input image, after being preprocessed to reduce noisy artifacts, is applied to a deep convolutional neural network (CNN). The CNN combines local and global contextual information and outputs a label for each pixel, producing a segmentation mask that shows the lesion region. This mask will be further refined by some post processing operations. The experimental results show that our proposed method can outperform the existing state-of-the-art algorithms in terms of segmentation accuracy.},
   author = {M. H. Jafari and N. Karimi and E. Nasr-Esfahani and S. Samavi and S. M.R. Soroushmehr and K. Ward and K. Najarian},
   doi = {10.1109/ICPR.2016.7899656},
   isbn = {9781509048472},
   issn = {10514651},
   journal = {Proceedings - International Conference on Pattern Recognition},
   keywords = {Convolutional neural network,Deep learning,Medical image segmentation,Melanoma,Skin cancer},
   pages = {337-342},
   title = {Skin lesion segmentation in clinical images using deep learning},
   volume = {0},
   year = {2016},
}
@article{Pennisi2016,
   abstract = {Developing automatic diagnostic tools for the early detection of skin cancer lesions in dermoscopic images can help to reduce melanoma-induced mortality. Image segmentation is a key step in the automated skin lesion diagnosis pipeline. In this paper, a fast and fully-automatic algorithm for skin lesion segmentation in dermoscopic images is presented. Delaunay Triangulation is used to extract a binary mask of the lesion region, without the need of any training stage. A quantitative experimental evaluation has been conducted on a publicly available database, by taking into account six well-known state-of-the-art segmentation methods for comparison. The results of the experimental analysis demonstrate that the proposed approach is highly accurate when dealing with benign lesions, while the segmentation accuracy significantly decreases when melanoma images are processed. This behavior led us to consider geometrical and color features extracted from the binary masks generated by our algorithm for classification, achieving promising results for melanoma detection.},
   author = {Andrea Pennisi and Domenico D. Bloisi and Daniele Nardi and Anna Rita Giampetruzzi and Chiara Mondino and Antonio Facchiano},
   doi = {10.1016/j.compmedimag.2016.05.002},
   issn = {18790771},
   journal = {Computerized Medical Imaging and Graphics},
   keywords = {Automatic segmentation,Border detection,Dermoscopy images,Melanoma detection},
   pages = {89-103},
   title = {Skin lesion image segmentation using Delaunay Triangulation for melanoma detection},
   volume = {52},
   year = {2016},
}
@article{Cavalcanti2010,
   abstract = {Several pigmented skin lesion segmentation methods have been proposed for dermoscopy images, however skin lesion segmentation on macroscopic images have not received much attention. Despite the fact that dermoscopy is a very specialized technique, in some practical situations, patients do not have a fast access to an specialist. In this situations, pre-screening systems can be used to evaluate a suspect skin lesion by a non-specialist, and lesion segmentation is very important for the success of such systems. This paper proposes a new method for segmenting pigmented skin lesions on macroscopic images acquired with standard cameras. Our method is simpler than comparable methods proposed for dermoscopy, and our experiments based on publicly available datasets of pigmented skin lesion images show promising results. Our approach can achieve an average segmentation error of 24.85%, which is better than the accuracy of comparable methods available in the literature (even for illumination corrected images). © 2010 IEEE.},
   author = {Pablo G. Cavalcanti and Yessenia Yari and Jacob Scharcanski},
   doi = {10.1109/IVCNZ.2010.6148845},
   isbn = {9781424496303},
   issn = {21512191},
   journal = {International Conference Image and Vision Computing New Zealand},
   keywords = {Dermatological Images,Image Segmentation,Melanoma},
   title = {Pigmented skin lesion segmentation on macroscopic images},
   year = {2010},
}
@article{Monaco2019,
   author = {Domenico Monaco},
   journal = {ArXiv},
   pages = {1-5},
   title = {What is the Explainable-AI and Why is Important},
   year = {2019},
}
